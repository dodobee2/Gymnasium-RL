{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cartpole CV로 받기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stable-baselines3[extra]\n",
      "  Using cached stable_baselines3-2.3.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: gymnasium<0.30,>=0.28.1 in c:\\users\\lahee\\anaconda3\\envs\\gym-env\\lib\\site-packages (from stable-baselines3[extra]) (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\lahee\\anaconda3\\envs\\gym-env\\lib\\site-packages (from stable-baselines3[extra]) (1.24.4)\n",
      "Collecting torch>=1.13 (from stable-baselines3[extra])\n",
      "  Using cached torch-2.4.0-cp38-cp38-win_amd64.whl.metadata (27 kB)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\lahee\\anaconda3\\envs\\gym-env\\lib\\site-packages (from stable-baselines3[extra]) (3.0.0)\n",
      "Collecting pandas (from stable-baselines3[extra])\n",
      "  Using cached pandas-2.0.3-cp38-cp38-win_amd64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\lahee\\anaconda3\\envs\\gym-env\\lib\\site-packages (from stable-baselines3[extra]) (3.7.5)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\lahee\\anaconda3\\envs\\gym-env\\lib\\site-packages (from stable-baselines3[extra]) (4.10.0.84)\n",
      "Requirement already satisfied: pygame in c:\\users\\lahee\\anaconda3\\envs\\gym-env\\lib\\site-packages (from stable-baselines3[extra]) (2.1.0)\n",
      "Collecting tensorboard>=2.9.1 (from stable-baselines3[extra])\n",
      "  Using cached tensorboard-2.14.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: psutil in c:\\users\\lahee\\anaconda3\\envs\\gym-env\\lib\\site-packages (from stable-baselines3[extra]) (6.0.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\lahee\\anaconda3\\envs\\gym-env\\lib\\site-packages (from stable-baselines3[extra]) (4.66.4)\n",
      "Collecting rich (from stable-baselines3[extra])\n",
      "  Using cached rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting shimmy~=1.3.0 (from shimmy[atari]~=1.3.0; extra == \"extra\"->stable-baselines3[extra])\n",
      "  Using cached Shimmy-1.3.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: pillow in c:\\users\\lahee\\anaconda3\\envs\\gym-env\\lib\\site-packages (from stable-baselines3[extra]) (10.4.0)\n",
      "Collecting autorom~=0.6.1 (from autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra])\n",
      "  Using cached AutoROM-0.6.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting click (from autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra])\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting requests (from autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra])\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\lahee\\anaconda3\\envs\\gym-env\\lib\\site-packages (from autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (6.4.0)\n",
      "Collecting AutoROM.accept-rom-license (from autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra])\n",
      "  Using cached AutoROM.accept_rom_license-0.6.1-py3-none-any.whl\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\lahee\\anaconda3\\envs\\gym-env\\lib\\site-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra]) (4.12.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\lahee\\anaconda3\\envs\\gym-env\\lib\\site-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra]) (0.0.4)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in c:\\users\\lahee\\anaconda3\\envs\\gym-env\\lib\\site-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra]) (8.0.0)\n",
      "Collecting ale-py~=0.8.1 (from shimmy[atari]~=1.3.0; extra == \"extra\"->stable-baselines3[extra])\n",
      "  Using cached ale_py-0.8.1-cp38-cp38-win_amd64.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\lahee\\anaconda3\\envs\\gym-env\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.1.0)\n",
      "Collecting grpcio>=1.48.2 (from tensorboard>=2.9.1->stable-baselines3[extra])\n",
      "  Using cached grpcio-1.65.1-cp38-cp38-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard>=2.9.1->stable-baselines3[extra])\n",
      "  Using cached google_auth-2.32.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard>=2.9.1->stable-baselines3[extra])\n",
      "  Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard>=2.9.1->stable-baselines3[extra])\n",
      "  Using cached Markdown-3.6-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting protobuf>=3.19.6 (from tensorboard>=2.9.1->stable-baselines3[extra])\n",
      "  Using cached protobuf-5.27.2-cp38-cp38-win_amd64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\lahee\\anaconda3\\envs\\gym-env\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (69.5.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\lahee\\anaconda3\\envs\\gym-env\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard>=2.9.1->stable-baselines3[extra])\n",
      "  Using cached werkzeug-3.0.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\lahee\\anaconda3\\envs\\gym-env\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.43.0)\n",
      "Collecting filelock (from torch>=1.13->stable-baselines3[extra])\n",
      "  Using cached filelock-3.15.4-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: sympy in c:\\users\\lahee\\anaconda3\\envs\\gym-env\\lib\\site-packages (from torch>=1.13->stable-baselines3[extra]) (1.13.1)\n",
      "Collecting networkx (from torch>=1.13->stable-baselines3[extra])\n",
      "  Using cached networkx-3.1-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting jinja2 (from torch>=1.13->stable-baselines3[extra])\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting fsspec (from torch>=1.13->stable-baselines3[extra])\n",
      "  Using cached fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\lahee\\anaconda3\\envs\\gym-env\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\lahee\\anaconda3\\envs\\gym-env\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\lahee\\anaconda3\\envs\\gym-env\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\lahee\\anaconda3\\envs\\gym-env\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lahee\\anaconda3\\envs\\gym-env\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\lahee\\anaconda3\\envs\\gym-env\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\lahee\\anaconda3\\envs\\gym-env\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lahee\\anaconda3\\envs\\gym-env\\lib\\site-packages (from pandas->stable-baselines3[extra]) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\lahee\\anaconda3\\envs\\gym-env\\lib\\site-packages (from pandas->stable-baselines3[extra]) (2024.1)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->stable-baselines3[extra])\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\lahee\\anaconda3\\envs\\gym-env\\lib\\site-packages (from rich->stable-baselines3[extra]) (2.18.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\lahee\\anaconda3\\envs\\gym-env\\lib\\site-packages (from tqdm->stable-baselines3[extra]) (0.4.6)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra])\n",
      "  Using cached cachetools-5.4.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra])\n",
      "  Using cached pyasn1_modules-0.4.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra])\n",
      "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.9.1->stable-baselines3[extra])\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\lahee\\anaconda3\\envs\\gym-env\\lib\\site-packages (from importlib-metadata>=4.8.0->gymnasium<0.30,>=0.28.1->stable-baselines3[extra]) (3.19.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra])\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lahee\\anaconda3\\envs\\gym-env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3[extra]) (1.16.0)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra])\n",
      "  Using cached charset_normalizer-3.3.2-cp38-cp38-win_amd64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra])\n",
      "  Using cached idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lahee\\anaconda3\\envs\\gym-env\\lib\\site-packages (from requests->autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (2.2.2)\n",
      "Collecting certifi>=2017.4.17 (from requests->autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra])\n",
      "  Using cached certifi-2024.7.4-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra])\n",
      "  Using cached MarkupSafe-2.1.5-cp38-cp38-win_amd64.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\lahee\\anaconda3\\envs\\gym-env\\lib\\site-packages (from sympy->torch>=1.13->stable-baselines3[extra]) (1.3.0)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra])\n",
      "  Using cached pyasn1-0.6.0-py2.py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.9.1->stable-baselines3[extra])\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Using cached AutoROM-0.6.1-py3-none-any.whl (9.4 kB)\n",
      "Using cached Shimmy-1.3.0-py3-none-any.whl (37 kB)\n",
      "Using cached tensorboard-2.14.0-py3-none-any.whl (5.5 MB)\n",
      "Using cached torch-2.4.0-cp38-cp38-win_amd64.whl (198.1 MB)\n",
      "Using cached pandas-2.0.3-cp38-cp38-win_amd64.whl (10.8 MB)\n",
      "Using cached rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "Using cached stable_baselines3-2.3.2-py3-none-any.whl (182 kB)\n",
      "Using cached ale_py-0.8.1-cp38-cp38-win_amd64.whl (952 kB)\n",
      "Using cached google_auth-2.32.0-py2.py3-none-any.whl (195 kB)\n",
      "Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Using cached grpcio-1.65.1-cp38-cp38-win_amd64.whl (4.1 MB)\n",
      "Using cached Markdown-3.6-py3-none-any.whl (105 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached protobuf-5.27.2-cp38-cp38-win_amd64.whl (426 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached werkzeug-3.0.3-py3-none-any.whl (227 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Using cached filelock-3.15.4-py3-none-any.whl (16 kB)\n",
      "Using cached fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Using cached networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "Using cached cachetools-5.4.0-py3-none-any.whl (9.5 kB)\n",
      "Using cached certifi-2024.7.4-py3-none-any.whl (162 kB)\n",
      "Using cached charset_normalizer-3.3.2-cp38-cp38-win_amd64.whl (99 kB)\n",
      "Using cached idna-3.7-py3-none-any.whl (66 kB)\n",
      "Using cached MarkupSafe-2.1.5-cp38-cp38-win_amd64.whl (17 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Using cached pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\n",
      "Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Using cached pyasn1-0.6.0-py2.py3-none-any.whl (85 kB)\n",
      "Installing collected packages: pyasn1, protobuf, oauthlib, networkx, mdurl, MarkupSafe, idna, grpcio, fsspec, filelock, click, charset-normalizer, certifi, cachetools, werkzeug, rsa, requests, pyasn1-modules, pandas, markdown-it-py, markdown, jinja2, ale-py, torch, shimmy, rich, requests-oauthlib, google-auth, AutoROM.accept-rom-license, autorom, stable-baselines3, google-auth-oauthlib, tensorboard\n",
      "Successfully installed AutoROM.accept-rom-license-0.6.1 MarkupSafe-2.1.5 ale-py-0.8.1 autorom-0.6.1 cachetools-5.4.0 certifi-2024.7.4 charset-normalizer-3.3.2 click-8.1.7 filelock-3.15.4 fsspec-2024.6.1 google-auth-2.32.0 google-auth-oauthlib-1.0.0 grpcio-1.65.1 idna-3.7 jinja2-3.1.4 markdown-3.6 markdown-it-py-3.0.0 mdurl-0.1.2 networkx-3.1 oauthlib-3.2.2 pandas-2.0.3 protobuf-5.27.2 pyasn1-0.6.0 pyasn1-modules-0.4.0 requests-2.32.3 requests-oauthlib-2.0.0 rich-13.7.1 rsa-4.9 shimmy-1.3.0 stable-baselines3-2.3.2 tensorboard-2.14.0 torch-2.4.0 werkzeug-3.0.3\n"
     ]
    }
   ],
   "source": [
    "#!pip install gymnasium\n",
    "#!pip install opencv-python\n",
    "!pip install stable-baselines3[extra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgymnasium\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgym\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstable_baselines3\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PPO\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import cv2\n",
    "import numpy as np\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import BaseCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. CartPole 환경 생성 및 OpenCV를 통한 실시간 화면 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:973: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected number of values returned from env.step()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     28\u001b[0m frame \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mrender()\n\u001b[1;32m---> 29\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCartPole\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:973: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v1',render_mode='human')\n",
    "\n",
    "class RenderCallback(BaseCallback):\n",
    "    def __init__(self, verbose=0):\n",
    "        super(RenderCallback, self).__init__(verbose)\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        frame = self.training_env.render()\n",
    "        cv2.imshow('CartPole', frame)\n",
    "        cv2.waitKey(1)\n",
    "        return True\n",
    "\n",
    "obs, info = env.reset()\n",
    "done = False\n",
    "\n",
    "while not done:\n",
    "    action = env.action_space.sample()\n",
    "    result = env.step(action)\n",
    "    \n",
    "    if len(result) == 4:\n",
    "        obs, reward, done, info = result\n",
    "    elif len(result) == 5:\n",
    "        obs, reward, done, truncated, info = result\n",
    "        done = done or truncated\n",
    "    else:\n",
    "        raise ValueError(\"Unexpected number of values returned from env.step()\")\n",
    "\n",
    "    frame = env.render()\n",
    "    cv2.imshow('CartPole', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "env.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 반혼 개수 수정 코드\n",
    "\n",
    "env = gym.make('CartPole-v1', render_mode='rgb_array')\n",
    "\n",
    "class RenderCallback(BaseCallback):\n",
    "    def __init__(self, verbose=0):\n",
    "        super(RenderCallback, self).__init__(verbose)\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        frame = self.training_env.render()\n",
    "        if frame is not None and frame.size > 0:\n",
    "            cv2.imshow('CartPole', frame)\n",
    "            cv2.waitKey(1)\n",
    "        return True\n",
    "\n",
    "obs, info = env.reset()\n",
    "done = False\n",
    "\n",
    "while not done:\n",
    "    action = env.action_space.sample()\n",
    "    result = env.step(action)\n",
    "    \n",
    "    if len(result) == 4:\n",
    "        obs, reward, done, info = result\n",
    "    elif len(result) == 5:\n",
    "        obs, reward, done, truncated, info = result\n",
    "        done = done or truncated\n",
    "    else:\n",
    "        raise ValueError(\"Unexpected number of values returned from env.step()\")\n",
    "\n",
    "    frame = env.render()\n",
    "    if frame is not None and frame.size > 0:\n",
    "        cv2.imshow('CartPole', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 22.4     |\n",
      "|    ep_rew_mean     | 22.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 253      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 8        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m PPO(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMlpPolicy\u001b[39m\u001b[38;5;124m'\u001b[39m, env, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      5\u001b[0m callback \u001b[38;5;241m=\u001b[39m RenderCallback()\n\u001b[1;32m----> 7\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m obs \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\lahee\\anaconda3\\envs\\gym-env\\lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:315\u001b[0m, in \u001b[0;36mPPO.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    307\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[0;32m    308\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    313\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    314\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfPPO:\n\u001b[1;32m--> 315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lahee\\anaconda3\\envs\\gym-env\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:300\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[1;32m--> 300\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_rollout_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m continue_training:\n\u001b[0;32m    303\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lahee\\anaconda3\\envs\\gym-env\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:201\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[1;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# Give access to local variables\u001b[39;00m\n\u001b[0;32m    200\u001b[0m callback\u001b[38;5;241m.\u001b[39mupdate_locals(\u001b[38;5;28mlocals\u001b[39m())\n\u001b[1;32m--> 201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mcallback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_info_buffer(infos, dones)\n",
      "File \u001b[1;32mc:\\Users\\lahee\\anaconda3\\envs\\gym-env\\lib\\site-packages\\stable_baselines3\\common\\callbacks.py:114\u001b[0m, in \u001b[0;36mBaseCallback.on_step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_calls \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mnum_timesteps\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_on_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 16\u001b[0m, in \u001b[0;36mRenderCallback._on_step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_on_step\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m---> 16\u001b[0m     frame \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m frame \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m frame\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     18\u001b[0m         cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCartPole\u001b[39m\u001b[38;5;124m'\u001b[39m, frame)\n",
      "File \u001b[1;32mc:\\Users\\lahee\\anaconda3\\envs\\gym-env\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:103\u001b[0m, in \u001b[0;36mDummyVecEnv.render\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrender\u001b[39m(\u001b[38;5;28mself\u001b[39m, mode: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[np\u001b[38;5;241m.\u001b[39mndarray]:\n\u001b[0;32m     97\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;124;03m    Gym environment rendering. If there are multiple environments then\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;124;03m    they are tiled together in one image via ``BaseVecEnv.render()``.\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \n\u001b[0;32m    101\u001b[0m \u001b[38;5;124;03m    :param mode: The rendering type.\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lahee\\anaconda3\\envs\\gym-env\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:255\u001b[0m, in \u001b[0;36mVecEnv.render\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrgb_array\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;66;03m# call the render method of the environments\u001b[39;00m\n\u001b[1;32m--> 255\u001b[0m     images \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m     \u001b[38;5;66;03m# Create a big image by tiling images from subprocesses\u001b[39;00m\n\u001b[0;32m    257\u001b[0m     bigimg \u001b[38;5;241m=\u001b[39m tile_images(images)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lahee\\anaconda3\\envs\\gym-env\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:94\u001b[0m, in \u001b[0;36mDummyVecEnv.get_images\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     90\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m     91\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe render mode is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but this method assumes it is `rgb_array` to obtain images.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     92\u001b[0m     )\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvs]\n\u001b[1;32m---> 94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [env\u001b[38;5;241m.\u001b[39mrender() \u001b[38;5;28;01mfor\u001b[39;00m env \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvs]\n",
      "File \u001b[1;32mc:\\Users\\lahee\\anaconda3\\envs\\gym-env\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:94\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     90\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m     91\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe render mode is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but this method assumes it is `rgb_array` to obtain images.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     92\u001b[0m     )\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvs]\n\u001b[1;32m---> 94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m env \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvs]\n",
      "File \u001b[1;32mc:\\Users\\lahee\\anaconda3\\envs\\gym-env\\lib\\site-packages\\gymnasium\\core.py:471\u001b[0m, in \u001b[0;36mWrapper.render\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrender\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m RenderFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[RenderFrame] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    470\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Uses the :meth:`render` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 471\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lahee\\anaconda3\\envs\\gym-env\\lib\\site-packages\\gymnasium\\core.py:471\u001b[0m, in \u001b[0;36mWrapper.render\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrender\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m RenderFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[RenderFrame] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    470\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Uses the :meth:`render` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 471\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lahee\\anaconda3\\envs\\gym-env\\lib\\site-packages\\gymnasium\\wrappers\\order_enforcing.py:70\u001b[0m, in \u001b[0;36mOrderEnforcing.render\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_disable_render_order_enforcing \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\n\u001b[0;32m     67\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call `env.render()` before calling `env.reset()`, if this is a intended action, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     68\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset `disable_render_order_enforcing=True` on the OrderEnforcer wrapper.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     69\u001b[0m     )\n\u001b[1;32m---> 70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lahee\\anaconda3\\envs\\gym-env\\lib\\site-packages\\gymnasium\\wrappers\\env_checker.py:67\u001b[0m, in \u001b[0;36mPassiveEnvChecker.render\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_render_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lahee\\anaconda3\\envs\\gym-env\\lib\\site-packages\\gymnasium\\envs\\classic_control\\cartpole.py:298\u001b[0m, in \u001b[0;36mCartPoleEnv.render\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    288\u001b[0m gfxdraw\u001b[38;5;241m.\u001b[39mfilled_circle(\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurf,\n\u001b[0;32m    290\u001b[0m     \u001b[38;5;28mint\u001b[39m(cartx),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    293\u001b[0m     (\u001b[38;5;241m129\u001b[39m, \u001b[38;5;241m132\u001b[39m, \u001b[38;5;241m203\u001b[39m),\n\u001b[0;32m    294\u001b[0m )\n\u001b[0;32m    296\u001b[0m gfxdraw\u001b[38;5;241m.\u001b[39mhline(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurf, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscreen_width, carty, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m--> 298\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurf \u001b[38;5;241m=\u001b[39m \u001b[43mpygame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflip\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msurf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscreen\u001b[38;5;241m.\u001b[39mblit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurf, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# PPO 모델 학습 및 평가\n",
    "env = make_vec_env('CartPole-v1', n_envs=1)\n",
    "\n",
    "model = PPO('MlpPolicy', env, verbose=1)\n",
    "callback = RenderCallback()\n",
    "\n",
    "model.learn(total_timesteps=10000, callback=callback)\n",
    "\n",
    "obs = env.reset()\n",
    "\n",
    "for i in range(1000):\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    frame = env.render(mode='rgb_array')\n",
    "    cv2.imshow('CartPole', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cartpole 비교 시각화 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training PPO...\n",
      "Using cpu device\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 21.4     |\n",
      "|    ep_rew_mean     | 21.4     |\n",
      "| time/              |          |\n",
      "|    fps             | 159      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 12       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 27.7        |\n",
      "|    ep_rew_mean          | 27.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010881359 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.685      |\n",
      "|    explained_variance   | -0.00288    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.1         |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    value_loss           | 49.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 35.7        |\n",
      "|    ep_rew_mean          | 35.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 156         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008464705 |\n",
      "|    clip_fraction        | 0.0462      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.671      |\n",
      "|    explained_variance   | 0.109       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13.1        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    value_loss           | 38.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 48          |\n",
      "|    ep_rew_mean          | 48          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 53          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008878136 |\n",
      "|    clip_fraction        | 0.0732      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.64       |\n",
      "|    explained_variance   | 0.216       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20.9        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    value_loss           | 56.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 59.6         |\n",
      "|    ep_rew_mean          | 59.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 155          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 65           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075143664 |\n",
      "|    clip_fraction        | 0.0711       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.608       |\n",
      "|    explained_variance   | 0.273        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 27.8         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0165      |\n",
      "|    value_loss           | 62.6         |\n",
      "------------------------------------------\n",
      "Evaluating PPO...\n",
      "Training A2C...\n",
      "Using cpu device\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 25.1     |\n",
      "|    ep_rew_mean        | 25.1     |\n",
      "| time/                 |          |\n",
      "|    fps                | 155      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.688   |\n",
      "|    explained_variance | -0.428   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 2.04     |\n",
      "|    value_loss         | 13       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 30.8     |\n",
      "|    ep_rew_mean        | 30.8     |\n",
      "| time/                 |          |\n",
      "|    fps                | 155      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.596   |\n",
      "|    explained_variance | -0.0187  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 0.883    |\n",
      "|    value_loss         | 4.62     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 36.6     |\n",
      "|    ep_rew_mean        | 36.6     |\n",
      "| time/                 |          |\n",
      "|    fps                | 156      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.584   |\n",
      "|    explained_variance | 0.0609   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 0.819    |\n",
      "|    value_loss         | 6.67     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 41.7     |\n",
      "|    ep_rew_mean        | 41.7     |\n",
      "| time/                 |          |\n",
      "|    fps                | 157      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.484   |\n",
      "|    explained_variance | 0.111    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 1.72     |\n",
      "|    value_loss         | 5.54     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 49       |\n",
      "|    ep_rew_mean        | 49       |\n",
      "| time/                 |          |\n",
      "|    fps                | 158      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.407   |\n",
      "|    explained_variance | 0.0161   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 2.39     |\n",
      "|    value_loss         | 5.1      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 56.2     |\n",
      "|    ep_rew_mean        | 56.2     |\n",
      "| time/                 |          |\n",
      "|    fps                | 158      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.601   |\n",
      "|    explained_variance | 0.000743 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 1.15     |\n",
      "|    value_loss         | 4.48     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 57.6     |\n",
      "|    ep_rew_mean        | 57.6     |\n",
      "| time/                 |          |\n",
      "|    fps                | 159      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 22       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.518   |\n",
      "|    explained_variance | 0.000261 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 1.11     |\n",
      "|    value_loss         | 3.89     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 71        |\n",
      "|    ep_rew_mean        | 71        |\n",
      "| time/                 |           |\n",
      "|    fps                | 158       |\n",
      "|    iterations         | 800       |\n",
      "|    time_elapsed       | 25        |\n",
      "|    total_timesteps    | 4000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.625    |\n",
      "|    explained_variance | -0.000785 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 799       |\n",
      "|    policy_loss        | 0.79      |\n",
      "|    value_loss         | 3.34      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 74       |\n",
      "|    ep_rew_mean        | 74       |\n",
      "| time/                 |          |\n",
      "|    fps                | 159      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.561   |\n",
      "|    explained_variance | -0.00186 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 0.504    |\n",
      "|    value_loss         | 2.85     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 77.5      |\n",
      "|    ep_rew_mean        | 77.5      |\n",
      "| time/                 |           |\n",
      "|    fps                | 159       |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 31        |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.629    |\n",
      "|    explained_variance | -0.000655 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | 0.64      |\n",
      "|    value_loss         | 2.4       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 84.5     |\n",
      "|    ep_rew_mean        | 84.5     |\n",
      "| time/                 |          |\n",
      "|    fps                | 160      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 34       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.389   |\n",
      "|    explained_variance | 0.00183  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 1.27     |\n",
      "|    value_loss         | 1.97     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 89.1      |\n",
      "|    ep_rew_mean        | 89.1      |\n",
      "| time/                 |           |\n",
      "|    fps                | 159       |\n",
      "|    iterations         | 1200      |\n",
      "|    time_elapsed       | 37        |\n",
      "|    total_timesteps    | 6000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.593    |\n",
      "|    explained_variance | -0.000856 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1199      |\n",
      "|    policy_loss        | 0.391     |\n",
      "|    value_loss         | 1.6       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 92.6      |\n",
      "|    ep_rew_mean        | 92.6      |\n",
      "| time/                 |           |\n",
      "|    fps                | 158       |\n",
      "|    iterations         | 1300      |\n",
      "|    time_elapsed       | 40        |\n",
      "|    total_timesteps    | 6500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.619    |\n",
      "|    explained_variance | -0.000489 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1299      |\n",
      "|    policy_loss        | 0.441     |\n",
      "|    value_loss         | 1.27      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95.4      |\n",
      "|    ep_rew_mean        | 95.4      |\n",
      "| time/                 |           |\n",
      "|    fps                | 159       |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 43        |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.623    |\n",
      "|    explained_variance | -9.78e-06 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | 0.522     |\n",
      "|    value_loss         | 0.972     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 99.6     |\n",
      "|    ep_rew_mean        | 99.6     |\n",
      "| time/                 |          |\n",
      "|    fps                | 159      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 47       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.562   |\n",
      "|    explained_variance | 0.000195 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 0.305    |\n",
      "|    value_loss         | 0.711    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 98.5      |\n",
      "|    ep_rew_mean        | 98.5      |\n",
      "| time/                 |           |\n",
      "|    fps                | 158       |\n",
      "|    iterations         | 1600      |\n",
      "|    time_elapsed       | 50        |\n",
      "|    total_timesteps    | 8000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.457    |\n",
      "|    explained_variance | -0.000301 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1599      |\n",
      "|    policy_loss        | 0.397     |\n",
      "|    value_loss         | 0.507     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 100      |\n",
      "|    ep_rew_mean        | 100      |\n",
      "| time/                 |          |\n",
      "|    fps                | 158      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.383   |\n",
      "|    explained_variance | 6.25e-05 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 0.515    |\n",
      "|    value_loss         | 0.327    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 101      |\n",
      "|    ep_rew_mean        | 101      |\n",
      "| time/                 |          |\n",
      "|    fps                | 159      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 56       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.405   |\n",
      "|    explained_variance | 2.4e-05  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 0.139    |\n",
      "|    value_loss         | 0.192    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 102      |\n",
      "|    ep_rew_mean        | 102      |\n",
      "| time/                 |          |\n",
      "|    fps                | 159      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 59       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.417   |\n",
      "|    explained_variance | 3.09e-05 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 0.205    |\n",
      "|    value_loss         | 0.0913   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 103      |\n",
      "|    ep_rew_mean        | 103      |\n",
      "| time/                 |          |\n",
      "|    fps                | 159      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 62       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.344   |\n",
      "|    explained_variance | -0.00037 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 0.0234   |\n",
      "|    value_loss         | 0.0273   |\n",
      "------------------------------------\n",
      "Evaluating A2C...\n",
      "Training DQN...\n",
      "Using cpu device\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.5     |\n",
      "|    ep_rew_mean      | 14.5     |\n",
      "|    exploration_rate | 0.945    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 217      |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 58       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.5     |\n",
      "|    ep_rew_mean      | 18.5     |\n",
      "|    exploration_rate | 0.859    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 205      |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 148      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.529    |\n",
      "|    n_updates        | 11       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.8     |\n",
      "|    ep_rew_mean      | 21.8     |\n",
      "|    exploration_rate | 0.752    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 199      |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 261      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.491    |\n",
      "|    n_updates        | 40       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.1     |\n",
      "|    ep_rew_mean      | 20.1     |\n",
      "|    exploration_rate | 0.694    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 198      |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 322      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.431    |\n",
      "|    n_updates        | 55       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.6     |\n",
      "|    ep_rew_mean      | 18.6     |\n",
      "|    exploration_rate | 0.648    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 194      |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 371      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.43     |\n",
      "|    n_updates        | 67       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.7     |\n",
      "|    ep_rew_mean      | 17.7     |\n",
      "|    exploration_rate | 0.596    |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 194      |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 425      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.398    |\n",
      "|    n_updates        | 81       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.3     |\n",
      "|    ep_rew_mean      | 17.3     |\n",
      "|    exploration_rate | 0.54     |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 192      |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 484      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.358    |\n",
      "|    n_updates        | 95       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.9     |\n",
      "|    ep_rew_mean      | 16.9     |\n",
      "|    exploration_rate | 0.487    |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 191      |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 540      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.318    |\n",
      "|    n_updates        | 109      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.4     |\n",
      "|    ep_rew_mean      | 16.4     |\n",
      "|    exploration_rate | 0.438    |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 190      |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 592      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.301    |\n",
      "|    n_updates        | 122      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.9     |\n",
      "|    ep_rew_mean      | 15.9     |\n",
      "|    exploration_rate | 0.396    |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 189      |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 636      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.222    |\n",
      "|    n_updates        | 133      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.5     |\n",
      "|    ep_rew_mean      | 15.5     |\n",
      "|    exploration_rate | 0.353    |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 188      |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 681      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.211    |\n",
      "|    n_updates        | 145      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 15.1     |\n",
      "|    ep_rew_mean      | 15.1     |\n",
      "|    exploration_rate | 0.312    |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 186      |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 724      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.224    |\n",
      "|    n_updates        | 155      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.7     |\n",
      "|    ep_rew_mean      | 14.7     |\n",
      "|    exploration_rate | 0.274    |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 185      |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 764      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.196    |\n",
      "|    n_updates        | 165      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.5     |\n",
      "|    ep_rew_mean      | 14.5     |\n",
      "|    exploration_rate | 0.231    |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 185      |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 810      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.148    |\n",
      "|    n_updates        | 177      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14.2     |\n",
      "|    ep_rew_mean      | 14.2     |\n",
      "|    exploration_rate | 0.188    |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 183      |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 855      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.14     |\n",
      "|    n_updates        | 188      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 14       |\n",
      "|    ep_rew_mean      | 14       |\n",
      "|    exploration_rate | 0.151    |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 181      |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 894      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.135    |\n",
      "|    n_updates        | 198      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.7     |\n",
      "|    ep_rew_mean      | 13.7     |\n",
      "|    exploration_rate | 0.114    |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 179      |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 933      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.128    |\n",
      "|    n_updates        | 208      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.5     |\n",
      "|    ep_rew_mean      | 13.5     |\n",
      "|    exploration_rate | 0.0766   |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 177      |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 972      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.117    |\n",
      "|    n_updates        | 217      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.3     |\n",
      "|    ep_rew_mean      | 13.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 176      |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 1009     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0819   |\n",
      "|    n_updates        | 227      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13.1     |\n",
      "|    ep_rew_mean      | 13.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 174      |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 1049     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0892   |\n",
      "|    n_updates        | 237      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 13       |\n",
      "|    ep_rew_mean      | 13       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 173      |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 1088     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0643   |\n",
      "|    n_updates        | 246      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.8     |\n",
      "|    ep_rew_mean      | 12.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 172      |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 1128     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0707   |\n",
      "|    n_updates        | 256      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.6     |\n",
      "|    ep_rew_mean      | 12.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 170      |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 1163     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0668   |\n",
      "|    n_updates        | 265      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.5     |\n",
      "|    ep_rew_mean      | 12.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 169      |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 1199     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0508   |\n",
      "|    n_updates        | 274      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.4     |\n",
      "|    ep_rew_mean      | 12.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 169      |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 1237     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0493   |\n",
      "|    n_updates        | 284      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 12.2     |\n",
      "|    ep_rew_mean      | 12.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 168      |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 1279     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0447   |\n",
      "|    n_updates        | 294      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11.7     |\n",
      "|    ep_rew_mean      | 11.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 168      |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 1318     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0368   |\n",
      "|    n_updates        | 304      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.9     |\n",
      "|    ep_rew_mean      | 10.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 167      |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 1356     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0255   |\n",
      "|    n_updates        | 313      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.8     |\n",
      "|    ep_rew_mean      | 10.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 165      |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 1402     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0339   |\n",
      "|    n_updates        | 325      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.7     |\n",
      "|    ep_rew_mean      | 10.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 165      |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 1439     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0295   |\n",
      "|    n_updates        | 334      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.5     |\n",
      "|    ep_rew_mean      | 10.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 164      |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 1477     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0186   |\n",
      "|    n_updates        | 344      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.3     |\n",
      "|    ep_rew_mean      | 10.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 164      |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 1517     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0284   |\n",
      "|    n_updates        | 354      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.1     |\n",
      "|    ep_rew_mean      | 10.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 163      |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 1552     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0211   |\n",
      "|    n_updates        | 362      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.99     |\n",
      "|    ep_rew_mean      | 9.99     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 162      |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 1591     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.022    |\n",
      "|    n_updates        | 372      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.93     |\n",
      "|    ep_rew_mean      | 9.93     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 162      |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 1629     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0163   |\n",
      "|    n_updates        | 382      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.86     |\n",
      "|    ep_rew_mean      | 9.86     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 161      |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 1667     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0226   |\n",
      "|    n_updates        | 391      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.87     |\n",
      "|    ep_rew_mean      | 9.87     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 161      |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 1711     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0124   |\n",
      "|    n_updates        | 402      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.87     |\n",
      "|    ep_rew_mean      | 9.87     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 152      |\n",
      "|    fps              | 160      |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 1751     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0129   |\n",
      "|    n_updates        | 412      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.82     |\n",
      "|    ep_rew_mean      | 9.82     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 156      |\n",
      "|    fps              | 160      |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 1792     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00609  |\n",
      "|    n_updates        | 422      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.78     |\n",
      "|    ep_rew_mean      | 9.78     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 160      |\n",
      "|    fps              | 160      |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 1833     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0137   |\n",
      "|    n_updates        | 433      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.83     |\n",
      "|    ep_rew_mean      | 9.83     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 164      |\n",
      "|    fps              | 159      |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 1877     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00289  |\n",
      "|    n_updates        | 444      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.87     |\n",
      "|    ep_rew_mean      | 9.87     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 168      |\n",
      "|    fps              | 158      |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 1920     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00866  |\n",
      "|    n_updates        | 454      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.86     |\n",
      "|    ep_rew_mean      | 9.86     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 172      |\n",
      "|    fps              | 158      |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 1958     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00667  |\n",
      "|    n_updates        | 464      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.91     |\n",
      "|    ep_rew_mean      | 9.91     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 176      |\n",
      "|    fps              | 158      |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 2000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00769  |\n",
      "|    n_updates        | 474      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.88     |\n",
      "|    ep_rew_mean      | 9.88     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 180      |\n",
      "|    fps              | 157      |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 2037     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0123   |\n",
      "|    n_updates        | 484      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.91     |\n",
      "|    ep_rew_mean      | 9.91     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 184      |\n",
      "|    fps              | 157      |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 2079     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00697  |\n",
      "|    n_updates        | 494      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.91     |\n",
      "|    ep_rew_mean      | 9.91     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 188      |\n",
      "|    fps              | 157      |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 2119     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00998  |\n",
      "|    n_updates        | 504      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.98     |\n",
      "|    ep_rew_mean      | 9.98     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 192      |\n",
      "|    fps              | 157      |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 2161     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0103   |\n",
      "|    n_updates        | 515      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10       |\n",
      "|    ep_rew_mean      | 10       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 196      |\n",
      "|    fps              | 157      |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 2203     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00368  |\n",
      "|    n_updates        | 525      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.1     |\n",
      "|    ep_rew_mean      | 10.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 200      |\n",
      "|    fps              | 156      |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 2242     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00603  |\n",
      "|    n_updates        | 535      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10       |\n",
      "|    ep_rew_mean      | 10       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 204      |\n",
      "|    fps              | 156      |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 2280     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00498  |\n",
      "|    n_updates        | 544      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10       |\n",
      "|    ep_rew_mean      | 10       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 208      |\n",
      "|    fps              | 156      |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 2321     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0036   |\n",
      "|    n_updates        | 555      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.1     |\n",
      "|    ep_rew_mean      | 10.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 212      |\n",
      "|    fps              | 156      |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 2363     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00258  |\n",
      "|    n_updates        | 565      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.99     |\n",
      "|    ep_rew_mean      | 9.99     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 216      |\n",
      "|    fps              | 155      |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 2401     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00186  |\n",
      "|    n_updates        | 575      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.1     |\n",
      "|    ep_rew_mean      | 10.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 220      |\n",
      "|    fps              | 155      |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 2444     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00125  |\n",
      "|    n_updates        | 585      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.1     |\n",
      "|    ep_rew_mean      | 10.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 224      |\n",
      "|    fps              | 155      |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 2490     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00631  |\n",
      "|    n_updates        | 597      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.1     |\n",
      "|    ep_rew_mean      | 10.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 228      |\n",
      "|    fps              | 155      |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 2531     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00767  |\n",
      "|    n_updates        | 607      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.2     |\n",
      "|    ep_rew_mean      | 10.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 232      |\n",
      "|    fps              | 154      |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 2570     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00286  |\n",
      "|    n_updates        | 617      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.2     |\n",
      "|    ep_rew_mean      | 10.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 236      |\n",
      "|    fps              | 154      |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 2613     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00317  |\n",
      "|    n_updates        | 628      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.2     |\n",
      "|    ep_rew_mean      | 10.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 240      |\n",
      "|    fps              | 154      |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 2653     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00458  |\n",
      "|    n_updates        | 638      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.3     |\n",
      "|    ep_rew_mean      | 10.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 244      |\n",
      "|    fps              | 154      |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 2695     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00364  |\n",
      "|    n_updates        | 648      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.2     |\n",
      "|    ep_rew_mean      | 10.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 248      |\n",
      "|    fps              | 154      |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 2733     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00274  |\n",
      "|    n_updates        | 658      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.2     |\n",
      "|    ep_rew_mean      | 10.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 252      |\n",
      "|    fps              | 154      |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 2774     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00251  |\n",
      "|    n_updates        | 668      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.2     |\n",
      "|    ep_rew_mean      | 10.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 256      |\n",
      "|    fps              | 154      |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 2811     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0028   |\n",
      "|    n_updates        | 677      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.2     |\n",
      "|    ep_rew_mean      | 10.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 260      |\n",
      "|    fps              | 154      |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 2855     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00407  |\n",
      "|    n_updates        | 688      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.2     |\n",
      "|    ep_rew_mean      | 10.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 264      |\n",
      "|    fps              | 154      |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 2896     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00261  |\n",
      "|    n_updates        | 698      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.2     |\n",
      "|    ep_rew_mean      | 10.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 268      |\n",
      "|    fps              | 154      |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 2939     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00342  |\n",
      "|    n_updates        | 709      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.2     |\n",
      "|    ep_rew_mean      | 10.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 272      |\n",
      "|    fps              | 154      |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 2977     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00124  |\n",
      "|    n_updates        | 719      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.2     |\n",
      "|    ep_rew_mean      | 10.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 276      |\n",
      "|    fps              | 154      |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 3018     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00137  |\n",
      "|    n_updates        | 729      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.2     |\n",
      "|    ep_rew_mean      | 10.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 280      |\n",
      "|    fps              | 154      |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 3055     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0015   |\n",
      "|    n_updates        | 738      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.2     |\n",
      "|    ep_rew_mean      | 10.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 284      |\n",
      "|    fps              | 154      |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 3095     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00134  |\n",
      "|    n_updates        | 748      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.2     |\n",
      "|    ep_rew_mean      | 10.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 288      |\n",
      "|    fps              | 154      |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 3139     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00143  |\n",
      "|    n_updates        | 759      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.2     |\n",
      "|    ep_rew_mean      | 10.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 292      |\n",
      "|    fps              | 154      |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 3181     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00149  |\n",
      "|    n_updates        | 770      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.2     |\n",
      "|    ep_rew_mean      | 10.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 296      |\n",
      "|    fps              | 154      |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 3226     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0028   |\n",
      "|    n_updates        | 781      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.3     |\n",
      "|    ep_rew_mean      | 10.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 300      |\n",
      "|    fps              | 154      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 3268     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00163  |\n",
      "|    n_updates        | 791      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.3     |\n",
      "|    ep_rew_mean      | 10.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 304      |\n",
      "|    fps              | 154      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 3307     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000948 |\n",
      "|    n_updates        | 801      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.2     |\n",
      "|    ep_rew_mean      | 10.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 308      |\n",
      "|    fps              | 153      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 3344     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000995 |\n",
      "|    n_updates        | 810      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.2     |\n",
      "|    ep_rew_mean      | 10.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 312      |\n",
      "|    fps              | 153      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 3382     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00262  |\n",
      "|    n_updates        | 820      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.2     |\n",
      "|    ep_rew_mean      | 10.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 316      |\n",
      "|    fps              | 153      |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 3424     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0011   |\n",
      "|    n_updates        | 830      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.2     |\n",
      "|    ep_rew_mean      | 10.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 320      |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 3461     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00133  |\n",
      "|    n_updates        | 840      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.1     |\n",
      "|    ep_rew_mean      | 10.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 324      |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 3502     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00124  |\n",
      "|    n_updates        | 850      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.1     |\n",
      "|    ep_rew_mean      | 10.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 328      |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 3541     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00109  |\n",
      "|    n_updates        | 860      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.1     |\n",
      "|    ep_rew_mean      | 10.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 332      |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 3581     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0013   |\n",
      "|    n_updates        | 870      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.1     |\n",
      "|    ep_rew_mean      | 10.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 336      |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 3620     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00153  |\n",
      "|    n_updates        | 879      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.1     |\n",
      "|    ep_rew_mean      | 10.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 340      |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 3662     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00151  |\n",
      "|    n_updates        | 890      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.1     |\n",
      "|    ep_rew_mean      | 10.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 344      |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 3704     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00119  |\n",
      "|    n_updates        | 900      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.1     |\n",
      "|    ep_rew_mean      | 10.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 348      |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total_timesteps  | 3742     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00131  |\n",
      "|    n_updates        | 910      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.1     |\n",
      "|    ep_rew_mean      | 10.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 352      |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total_timesteps  | 3784     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00113  |\n",
      "|    n_updates        | 920      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.1     |\n",
      "|    ep_rew_mean      | 10.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 356      |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total_timesteps  | 3824     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00105  |\n",
      "|    n_updates        | 930      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.1     |\n",
      "|    ep_rew_mean      | 10.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 360      |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total_timesteps  | 3866     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00138  |\n",
      "|    n_updates        | 941      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.2     |\n",
      "|    ep_rew_mean      | 10.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 364      |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 3912     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00109  |\n",
      "|    n_updates        | 952      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.1     |\n",
      "|    ep_rew_mean      | 10.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 368      |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 3952     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000665 |\n",
      "|    n_updates        | 962      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.2     |\n",
      "|    ep_rew_mean      | 10.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 372      |\n",
      "|    fps              | 144      |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 3999     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000365 |\n",
      "|    n_updates        | 974      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.2     |\n",
      "|    ep_rew_mean      | 10.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 376      |\n",
      "|    fps              | 144      |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total_timesteps  | 4040     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000345 |\n",
      "|    n_updates        | 984      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.2     |\n",
      "|    ep_rew_mean      | 10.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 380      |\n",
      "|    fps              | 144      |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total_timesteps  | 4079     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000557 |\n",
      "|    n_updates        | 994      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.2     |\n",
      "|    ep_rew_mean      | 10.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 384      |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total_timesteps  | 4119     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000536 |\n",
      "|    n_updates        | 1004     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.2     |\n",
      "|    ep_rew_mean      | 10.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 388      |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total_timesteps  | 4162     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00188  |\n",
      "|    n_updates        | 1015     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.2     |\n",
      "|    ep_rew_mean      | 10.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 392      |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 4203     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00172  |\n",
      "|    n_updates        | 1025     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.2     |\n",
      "|    ep_rew_mean      | 10.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 396      |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 4247     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000899 |\n",
      "|    n_updates        | 1036     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.2     |\n",
      "|    ep_rew_mean      | 10.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 400      |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 4289     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000766 |\n",
      "|    n_updates        | 1047     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.2     |\n",
      "|    ep_rew_mean      | 10.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 404      |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 30       |\n",
      "|    total_timesteps  | 4325     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0015   |\n",
      "|    n_updates        | 1056     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.2     |\n",
      "|    ep_rew_mean      | 10.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 408      |\n",
      "|    fps              | 144      |\n",
      "|    time_elapsed     | 30       |\n",
      "|    total_timesteps  | 4363     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00109  |\n",
      "|    n_updates        | 1065     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.2     |\n",
      "|    ep_rew_mean      | 10.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 412      |\n",
      "|    fps              | 144      |\n",
      "|    time_elapsed     | 30       |\n",
      "|    total_timesteps  | 4401     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000432 |\n",
      "|    n_updates        | 1075     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.2     |\n",
      "|    ep_rew_mean      | 10.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 416      |\n",
      "|    fps              | 144      |\n",
      "|    time_elapsed     | 30       |\n",
      "|    total_timesteps  | 4443     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000215 |\n",
      "|    n_updates        | 1085     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.2     |\n",
      "|    ep_rew_mean      | 10.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 420      |\n",
      "|    fps              | 144      |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 4483     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00092  |\n",
      "|    n_updates        | 1095     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.2     |\n",
      "|    ep_rew_mean      | 10.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 424      |\n",
      "|    fps              | 144      |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 4523     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000986 |\n",
      "|    n_updates        | 1105     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.2     |\n",
      "|    ep_rew_mean      | 10.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 428      |\n",
      "|    fps              | 144      |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 4564     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000507 |\n",
      "|    n_updates        | 1115     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.2     |\n",
      "|    ep_rew_mean      | 10.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 432      |\n",
      "|    fps              | 144      |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 4604     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000209 |\n",
      "|    n_updates        | 1125     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.2     |\n",
      "|    ep_rew_mean      | 10.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 436      |\n",
      "|    fps              | 144      |\n",
      "|    time_elapsed     | 32       |\n",
      "|    total_timesteps  | 4644     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000579 |\n",
      "|    n_updates        | 1135     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.2     |\n",
      "|    ep_rew_mean      | 10.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 440      |\n",
      "|    fps              | 144      |\n",
      "|    time_elapsed     | 32       |\n",
      "|    total_timesteps  | 4684     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000174 |\n",
      "|    n_updates        | 1145     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.2     |\n",
      "|    ep_rew_mean      | 10.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 444      |\n",
      "|    fps              | 144      |\n",
      "|    time_elapsed     | 32       |\n",
      "|    total_timesteps  | 4725     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000852 |\n",
      "|    n_updates        | 1156     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.2     |\n",
      "|    ep_rew_mean      | 10.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 448      |\n",
      "|    fps              | 144      |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 4764     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000383 |\n",
      "|    n_updates        | 1165     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.2     |\n",
      "|    ep_rew_mean      | 10.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 452      |\n",
      "|    fps              | 144      |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 4805     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00043  |\n",
      "|    n_updates        | 1176     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.2     |\n",
      "|    ep_rew_mean      | 10.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 456      |\n",
      "|    fps              | 144      |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 4844     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000291 |\n",
      "|    n_updates        | 1185     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.2     |\n",
      "|    ep_rew_mean      | 10.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 460      |\n",
      "|    fps              | 144      |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 4883     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000661 |\n",
      "|    n_updates        | 1195     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.1     |\n",
      "|    ep_rew_mean      | 10.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 464      |\n",
      "|    fps              | 144      |\n",
      "|    time_elapsed     | 34       |\n",
      "|    total_timesteps  | 4923     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000526 |\n",
      "|    n_updates        | 1205     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.1     |\n",
      "|    ep_rew_mean      | 10.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 468      |\n",
      "|    fps              | 144      |\n",
      "|    time_elapsed     | 34       |\n",
      "|    total_timesteps  | 4963     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000799 |\n",
      "|    n_updates        | 1215     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10       |\n",
      "|    ep_rew_mean      | 10       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 472      |\n",
      "|    fps              | 144      |\n",
      "|    time_elapsed     | 34       |\n",
      "|    total_timesteps  | 5003     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000736 |\n",
      "|    n_updates        | 1225     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.1     |\n",
      "|    ep_rew_mean      | 10.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 476      |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total_timesteps  | 5045     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00035  |\n",
      "|    n_updates        | 1236     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10       |\n",
      "|    ep_rew_mean      | 10       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 480      |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total_timesteps  | 5083     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000688 |\n",
      "|    n_updates        | 1245     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10       |\n",
      "|    ep_rew_mean      | 10       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 484      |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total_timesteps  | 5122     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000707 |\n",
      "|    n_updates        | 1255     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.99     |\n",
      "|    ep_rew_mean      | 9.99     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 488      |\n",
      "|    fps              | 144      |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total_timesteps  | 5161     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000895 |\n",
      "|    n_updates        | 1265     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10       |\n",
      "|    ep_rew_mean      | 10       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 492      |\n",
      "|    fps              | 144      |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 5203     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000338 |\n",
      "|    n_updates        | 1275     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.98     |\n",
      "|    ep_rew_mean      | 9.98     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 496      |\n",
      "|    fps              | 144      |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 5245     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000777 |\n",
      "|    n_updates        | 1286     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.98     |\n",
      "|    ep_rew_mean      | 9.98     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 500      |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 5287     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000384 |\n",
      "|    n_updates        | 1296     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10       |\n",
      "|    ep_rew_mean      | 10       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 504      |\n",
      "|    fps              | 144      |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 5326     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000556 |\n",
      "|    n_updates        | 1306     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.1     |\n",
      "|    ep_rew_mean      | 10.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 508      |\n",
      "|    fps              | 144      |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 5369     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000286 |\n",
      "|    n_updates        | 1317     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.1     |\n",
      "|    ep_rew_mean      | 10.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 512      |\n",
      "|    fps              | 144      |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 5409     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000415 |\n",
      "|    n_updates        | 1327     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.1     |\n",
      "|    ep_rew_mean      | 10.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 516      |\n",
      "|    fps              | 144      |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 5449     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000312 |\n",
      "|    n_updates        | 1337     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.1     |\n",
      "|    ep_rew_mean      | 10.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 520      |\n",
      "|    fps              | 144      |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 5492     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000228 |\n",
      "|    n_updates        | 1347     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.1     |\n",
      "|    ep_rew_mean      | 10.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 524      |\n",
      "|    fps              | 144      |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 5535     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000446 |\n",
      "|    n_updates        | 1358     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.1     |\n",
      "|    ep_rew_mean      | 10.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 528      |\n",
      "|    fps              | 144      |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 5572     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000498 |\n",
      "|    n_updates        | 1367     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10       |\n",
      "|    ep_rew_mean      | 10       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 532      |\n",
      "|    fps              | 144      |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 5608     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000344 |\n",
      "|    n_updates        | 1376     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.1     |\n",
      "|    ep_rew_mean      | 10.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 536      |\n",
      "|    fps              | 144      |\n",
      "|    time_elapsed     | 39       |\n",
      "|    total_timesteps  | 5649     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000211 |\n",
      "|    n_updates        | 1387     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10       |\n",
      "|    ep_rew_mean      | 10       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 540      |\n",
      "|    fps              | 144      |\n",
      "|    time_elapsed     | 39       |\n",
      "|    total_timesteps  | 5688     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000416 |\n",
      "|    n_updates        | 1396     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.1     |\n",
      "|    ep_rew_mean      | 10.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 544      |\n",
      "|    fps              | 144      |\n",
      "|    time_elapsed     | 39       |\n",
      "|    total_timesteps  | 5731     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000426 |\n",
      "|    n_updates        | 1407     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.1     |\n",
      "|    ep_rew_mean      | 10.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 548      |\n",
      "|    fps              | 144      |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 5770     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00034  |\n",
      "|    n_updates        | 1417     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.1     |\n",
      "|    ep_rew_mean      | 10.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 552      |\n",
      "|    fps              | 144      |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 5811     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000387 |\n",
      "|    n_updates        | 1427     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.1     |\n",
      "|    ep_rew_mean      | 10.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 556      |\n",
      "|    fps              | 144      |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 5853     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000919 |\n",
      "|    n_updates        | 1438     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.1     |\n",
      "|    ep_rew_mean      | 10.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 560      |\n",
      "|    fps              | 144      |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 5893     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000589 |\n",
      "|    n_updates        | 1448     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.1     |\n",
      "|    ep_rew_mean      | 10.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 564      |\n",
      "|    fps              | 144      |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 5937     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000343 |\n",
      "|    n_updates        | 1459     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.2     |\n",
      "|    ep_rew_mean      | 10.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 568      |\n",
      "|    fps              | 144      |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 5978     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000331 |\n",
      "|    n_updates        | 1469     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.1     |\n",
      "|    ep_rew_mean      | 10.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 572      |\n",
      "|    fps              | 144      |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 6016     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000698 |\n",
      "|    n_updates        | 1478     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.1     |\n",
      "|    ep_rew_mean      | 10.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 576      |\n",
      "|    fps              | 144      |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 6059     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000389 |\n",
      "|    n_updates        | 1489     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.2     |\n",
      "|    ep_rew_mean      | 10.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 580      |\n",
      "|    fps              | 144      |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 6100     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000259 |\n",
      "|    n_updates        | 1499     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.2     |\n",
      "|    ep_rew_mean      | 10.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 584      |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 6138     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000234 |\n",
      "|    n_updates        | 1509     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.1     |\n",
      "|    ep_rew_mean      | 10.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 588      |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 6175     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000359 |\n",
      "|    n_updates        | 1518     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.1     |\n",
      "|    ep_rew_mean      | 10.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 592      |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 6214     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000122 |\n",
      "|    n_updates        | 1528     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.1     |\n",
      "|    ep_rew_mean      | 10.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 596      |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 6259     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000196 |\n",
      "|    n_updates        | 1539     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.1     |\n",
      "|    ep_rew_mean      | 10.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 600      |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 6298     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00055  |\n",
      "|    n_updates        | 1549     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.1     |\n",
      "|    ep_rew_mean      | 10.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 604      |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 6338     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000371 |\n",
      "|    n_updates        | 1559     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.1     |\n",
      "|    ep_rew_mean      | 10.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 608      |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 6374     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000418 |\n",
      "|    n_updates        | 1568     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.1     |\n",
      "|    ep_rew_mean      | 10.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 612      |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 6417     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000179 |\n",
      "|    n_updates        | 1579     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.1     |\n",
      "|    ep_rew_mean      | 10.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 616      |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 6459     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000272 |\n",
      "|    n_updates        | 1589     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.1     |\n",
      "|    ep_rew_mean      | 10.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 620      |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 6498     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000256 |\n",
      "|    n_updates        | 1599     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10       |\n",
      "|    ep_rew_mean      | 10       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 624      |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 6539     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000458 |\n",
      "|    n_updates        | 1609     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10       |\n",
      "|    ep_rew_mean      | 10       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 628      |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 6575     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000315 |\n",
      "|    n_updates        | 1618     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.1     |\n",
      "|    ep_rew_mean      | 10.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 632      |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 6614     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000198 |\n",
      "|    n_updates        | 1628     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.1     |\n",
      "|    ep_rew_mean      | 10.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 636      |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 6654     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000296 |\n",
      "|    n_updates        | 1638     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.1     |\n",
      "|    ep_rew_mean      | 10.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 640      |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 6696     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000356 |\n",
      "|    n_updates        | 1648     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.1     |\n",
      "|    ep_rew_mean      | 10.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 644      |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 6739     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000326 |\n",
      "|    n_updates        | 1659     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.1     |\n",
      "|    ep_rew_mean      | 10.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 648      |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 47       |\n",
      "|    total_timesteps  | 6779     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00024  |\n",
      "|    n_updates        | 1669     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.1     |\n",
      "|    ep_rew_mean      | 10.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 652      |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 47       |\n",
      "|    total_timesteps  | 6819     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000164 |\n",
      "|    n_updates        | 1679     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10       |\n",
      "|    ep_rew_mean      | 10       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 656      |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 47       |\n",
      "|    total_timesteps  | 6857     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000284 |\n",
      "|    n_updates        | 1689     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10.1     |\n",
      "|    ep_rew_mean      | 10.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 660      |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 6898     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00164  |\n",
      "|    n_updates        | 1699     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10       |\n",
      "|    ep_rew_mean      | 10       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 664      |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 6937     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000331 |\n",
      "|    n_updates        | 1709     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.99     |\n",
      "|    ep_rew_mean      | 9.99     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 668      |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 6977     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000425 |\n",
      "|    n_updates        | 1719     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.98     |\n",
      "|    ep_rew_mean      | 9.98     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 672      |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 7014     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000456 |\n",
      "|    n_updates        | 1728     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.93     |\n",
      "|    ep_rew_mean      | 9.93     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 676      |\n",
      "|    fps              | 143      |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 7052     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000166 |\n",
      "|    n_updates        | 1737     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.91     |\n",
      "|    ep_rew_mean      | 9.91     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 680      |\n",
      "|    fps              | 137      |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total_timesteps  | 7091     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000211 |\n",
      "|    n_updates        | 1747     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.94     |\n",
      "|    ep_rew_mean      | 9.94     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 684      |\n",
      "|    fps              | 137      |\n",
      "|    time_elapsed     | 52       |\n",
      "|    total_timesteps  | 7132     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000367 |\n",
      "|    n_updates        | 1757     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.99     |\n",
      "|    ep_rew_mean      | 9.99     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 688      |\n",
      "|    fps              | 137      |\n",
      "|    time_elapsed     | 52       |\n",
      "|    total_timesteps  | 7174     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000963 |\n",
      "|    n_updates        | 1768     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10       |\n",
      "|    ep_rew_mean      | 10       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 692      |\n",
      "|    fps              | 137      |\n",
      "|    time_elapsed     | 52       |\n",
      "|    total_timesteps  | 7214     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000296 |\n",
      "|    n_updates        | 1778     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.93     |\n",
      "|    ep_rew_mean      | 9.93     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 696      |\n",
      "|    fps              | 137      |\n",
      "|    time_elapsed     | 52       |\n",
      "|    total_timesteps  | 7252     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000147 |\n",
      "|    n_updates        | 1787     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.95     |\n",
      "|    ep_rew_mean      | 9.95     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 700      |\n",
      "|    fps              | 137      |\n",
      "|    time_elapsed     | 53       |\n",
      "|    total_timesteps  | 7293     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000401 |\n",
      "|    n_updates        | 1798     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.93     |\n",
      "|    ep_rew_mean      | 9.93     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 704      |\n",
      "|    fps              | 137      |\n",
      "|    time_elapsed     | 53       |\n",
      "|    total_timesteps  | 7331     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000312 |\n",
      "|    n_updates        | 1807     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.94     |\n",
      "|    ep_rew_mean      | 9.94     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 708      |\n",
      "|    fps              | 137      |\n",
      "|    time_elapsed     | 53       |\n",
      "|    total_timesteps  | 7368     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000323 |\n",
      "|    n_updates        | 1816     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.89     |\n",
      "|    ep_rew_mean      | 9.89     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 712      |\n",
      "|    fps              | 137      |\n",
      "|    time_elapsed     | 53       |\n",
      "|    total_timesteps  | 7406     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000328 |\n",
      "|    n_updates        | 1826     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.84     |\n",
      "|    ep_rew_mean      | 9.84     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 716      |\n",
      "|    fps              | 137      |\n",
      "|    time_elapsed     | 54       |\n",
      "|    total_timesteps  | 7443     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000368 |\n",
      "|    n_updates        | 1835     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.81     |\n",
      "|    ep_rew_mean      | 9.81     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 720      |\n",
      "|    fps              | 137      |\n",
      "|    time_elapsed     | 54       |\n",
      "|    total_timesteps  | 7479     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000416 |\n",
      "|    n_updates        | 1844     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.78     |\n",
      "|    ep_rew_mean      | 9.78     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 724      |\n",
      "|    fps              | 137      |\n",
      "|    time_elapsed     | 54       |\n",
      "|    total_timesteps  | 7517     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000274 |\n",
      "|    n_updates        | 1854     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.78     |\n",
      "|    ep_rew_mean      | 9.78     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 728      |\n",
      "|    fps              | 137      |\n",
      "|    time_elapsed     | 54       |\n",
      "|    total_timesteps  | 7553     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000244 |\n",
      "|    n_updates        | 1863     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.81     |\n",
      "|    ep_rew_mean      | 9.81     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 732      |\n",
      "|    fps              | 137      |\n",
      "|    time_elapsed     | 55       |\n",
      "|    total_timesteps  | 7595     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000255 |\n",
      "|    n_updates        | 1873     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.81     |\n",
      "|    ep_rew_mean      | 9.81     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 736      |\n",
      "|    fps              | 138      |\n",
      "|    time_elapsed     | 55       |\n",
      "|    total_timesteps  | 7635     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000237 |\n",
      "|    n_updates        | 1883     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.79     |\n",
      "|    ep_rew_mean      | 9.79     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 740      |\n",
      "|    fps              | 138      |\n",
      "|    time_elapsed     | 55       |\n",
      "|    total_timesteps  | 7675     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000214 |\n",
      "|    n_updates        | 1893     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.72     |\n",
      "|    ep_rew_mean      | 9.72     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 744      |\n",
      "|    fps              | 138      |\n",
      "|    time_elapsed     | 55       |\n",
      "|    total_timesteps  | 7711     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000277 |\n",
      "|    n_updates        | 1902     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.69     |\n",
      "|    ep_rew_mean      | 9.69     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 748      |\n",
      "|    fps              | 138      |\n",
      "|    time_elapsed     | 56       |\n",
      "|    total_timesteps  | 7748     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000273 |\n",
      "|    n_updates        | 1911     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.68     |\n",
      "|    ep_rew_mean      | 9.68     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 752      |\n",
      "|    fps              | 138      |\n",
      "|    time_elapsed     | 56       |\n",
      "|    total_timesteps  | 7787     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000206 |\n",
      "|    n_updates        | 1921     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.72     |\n",
      "|    ep_rew_mean      | 9.72     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 756      |\n",
      "|    fps              | 138      |\n",
      "|    time_elapsed     | 56       |\n",
      "|    total_timesteps  | 7829     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000243 |\n",
      "|    n_updates        | 1932     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.74     |\n",
      "|    ep_rew_mean      | 9.74     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 760      |\n",
      "|    fps              | 138      |\n",
      "|    time_elapsed     | 56       |\n",
      "|    total_timesteps  | 7872     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000309 |\n",
      "|    n_updates        | 1942     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.76     |\n",
      "|    ep_rew_mean      | 9.76     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 764      |\n",
      "|    fps              | 138      |\n",
      "|    time_elapsed     | 57       |\n",
      "|    total_timesteps  | 7913     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000289 |\n",
      "|    n_updates        | 1953     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.75     |\n",
      "|    ep_rew_mean      | 9.75     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 768      |\n",
      "|    fps              | 138      |\n",
      "|    time_elapsed     | 57       |\n",
      "|    total_timesteps  | 7952     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000124 |\n",
      "|    n_updates        | 1962     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.76     |\n",
      "|    ep_rew_mean      | 9.76     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 772      |\n",
      "|    fps              | 138      |\n",
      "|    time_elapsed     | 57       |\n",
      "|    total_timesteps  | 7990     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000226 |\n",
      "|    n_updates        | 1972     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.77     |\n",
      "|    ep_rew_mean      | 9.77     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 776      |\n",
      "|    fps              | 138      |\n",
      "|    time_elapsed     | 57       |\n",
      "|    total_timesteps  | 8029     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000436 |\n",
      "|    n_updates        | 1982     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.78     |\n",
      "|    ep_rew_mean      | 9.78     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 780      |\n",
      "|    fps              | 139      |\n",
      "|    time_elapsed     | 58       |\n",
      "|    total_timesteps  | 8069     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000184 |\n",
      "|    n_updates        | 1992     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.76     |\n",
      "|    ep_rew_mean      | 9.76     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 784      |\n",
      "|    fps              | 139      |\n",
      "|    time_elapsed     | 58       |\n",
      "|    total_timesteps  | 8108     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000199 |\n",
      "|    n_updates        | 2001     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.75     |\n",
      "|    ep_rew_mean      | 9.75     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 788      |\n",
      "|    fps              | 139      |\n",
      "|    time_elapsed     | 58       |\n",
      "|    total_timesteps  | 8149     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000425 |\n",
      "|    n_updates        | 2012     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.74     |\n",
      "|    ep_rew_mean      | 9.74     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 792      |\n",
      "|    fps              | 139      |\n",
      "|    time_elapsed     | 58       |\n",
      "|    total_timesteps  | 8188     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000317 |\n",
      "|    n_updates        | 2021     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.72     |\n",
      "|    ep_rew_mean      | 9.72     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 796      |\n",
      "|    fps              | 139      |\n",
      "|    time_elapsed     | 58       |\n",
      "|    total_timesteps  | 8224     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000206 |\n",
      "|    n_updates        | 2030     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.68     |\n",
      "|    ep_rew_mean      | 9.68     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 800      |\n",
      "|    fps              | 139      |\n",
      "|    time_elapsed     | 59       |\n",
      "|    total_timesteps  | 8261     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000299 |\n",
      "|    n_updates        | 2040     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.67     |\n",
      "|    ep_rew_mean      | 9.67     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 804      |\n",
      "|    fps              | 139      |\n",
      "|    time_elapsed     | 59       |\n",
      "|    total_timesteps  | 8298     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000226 |\n",
      "|    n_updates        | 2049     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.72     |\n",
      "|    ep_rew_mean      | 9.72     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 808      |\n",
      "|    fps              | 139      |\n",
      "|    time_elapsed     | 59       |\n",
      "|    total_timesteps  | 8340     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000245 |\n",
      "|    n_updates        | 2059     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.77     |\n",
      "|    ep_rew_mean      | 9.77     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 812      |\n",
      "|    fps              | 140      |\n",
      "|    time_elapsed     | 59       |\n",
      "|    total_timesteps  | 8383     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000125 |\n",
      "|    n_updates        | 2070     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.78     |\n",
      "|    ep_rew_mean      | 9.78     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 816      |\n",
      "|    fps              | 140      |\n",
      "|    time_elapsed     | 60       |\n",
      "|    total_timesteps  | 8421     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000227 |\n",
      "|    n_updates        | 2080     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.81     |\n",
      "|    ep_rew_mean      | 9.81     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 820      |\n",
      "|    fps              | 140      |\n",
      "|    time_elapsed     | 60       |\n",
      "|    total_timesteps  | 8460     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00023  |\n",
      "|    n_updates        | 2089     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.84     |\n",
      "|    ep_rew_mean      | 9.84     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 824      |\n",
      "|    fps              | 140      |\n",
      "|    time_elapsed     | 60       |\n",
      "|    total_timesteps  | 8501     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00015  |\n",
      "|    n_updates        | 2100     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.89     |\n",
      "|    ep_rew_mean      | 9.89     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 828      |\n",
      "|    fps              | 140      |\n",
      "|    time_elapsed     | 60       |\n",
      "|    total_timesteps  | 8542     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000463 |\n",
      "|    n_updates        | 2110     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.88     |\n",
      "|    ep_rew_mean      | 9.88     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 832      |\n",
      "|    fps              | 140      |\n",
      "|    time_elapsed     | 60       |\n",
      "|    total_timesteps  | 8583     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000226 |\n",
      "|    n_updates        | 2120     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.87     |\n",
      "|    ep_rew_mean      | 9.87     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 836      |\n",
      "|    fps              | 140      |\n",
      "|    time_elapsed     | 61       |\n",
      "|    total_timesteps  | 8622     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000294 |\n",
      "|    n_updates        | 2130     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.86     |\n",
      "|    ep_rew_mean      | 9.86     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 840      |\n",
      "|    fps              | 141      |\n",
      "|    time_elapsed     | 61       |\n",
      "|    total_timesteps  | 8661     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000202 |\n",
      "|    n_updates        | 2140     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.93     |\n",
      "|    ep_rew_mean      | 9.93     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 844      |\n",
      "|    fps              | 141      |\n",
      "|    time_elapsed     | 61       |\n",
      "|    total_timesteps  | 8704     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000208 |\n",
      "|    n_updates        | 2150     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10       |\n",
      "|    ep_rew_mean      | 10       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 848      |\n",
      "|    fps              | 141      |\n",
      "|    time_elapsed     | 61       |\n",
      "|    total_timesteps  | 8750     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0002   |\n",
      "|    n_updates        | 2162     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10       |\n",
      "|    ep_rew_mean      | 10       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 852      |\n",
      "|    fps              | 141      |\n",
      "|    time_elapsed     | 62       |\n",
      "|    total_timesteps  | 8791     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000194 |\n",
      "|    n_updates        | 2172     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.98     |\n",
      "|    ep_rew_mean      | 9.98     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 856      |\n",
      "|    fps              | 141      |\n",
      "|    time_elapsed     | 62       |\n",
      "|    total_timesteps  | 8827     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000159 |\n",
      "|    n_updates        | 2181     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.94     |\n",
      "|    ep_rew_mean      | 9.94     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 860      |\n",
      "|    fps              | 141      |\n",
      "|    time_elapsed     | 62       |\n",
      "|    total_timesteps  | 8866     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000224 |\n",
      "|    n_updates        | 2191     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.92     |\n",
      "|    ep_rew_mean      | 9.92     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 864      |\n",
      "|    fps              | 141      |\n",
      "|    time_elapsed     | 62       |\n",
      "|    total_timesteps  | 8905     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00027  |\n",
      "|    n_updates        | 2201     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.9      |\n",
      "|    ep_rew_mean      | 9.9      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 868      |\n",
      "|    fps              | 141      |\n",
      "|    time_elapsed     | 63       |\n",
      "|    total_timesteps  | 8942     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000336 |\n",
      "|    n_updates        | 2210     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.91     |\n",
      "|    ep_rew_mean      | 9.91     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 872      |\n",
      "|    fps              | 141      |\n",
      "|    time_elapsed     | 63       |\n",
      "|    total_timesteps  | 8981     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000234 |\n",
      "|    n_updates        | 2220     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.94     |\n",
      "|    ep_rew_mean      | 9.94     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 876      |\n",
      "|    fps              | 141      |\n",
      "|    time_elapsed     | 63       |\n",
      "|    total_timesteps  | 9023     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000104 |\n",
      "|    n_updates        | 2230     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.92     |\n",
      "|    ep_rew_mean      | 9.92     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 880      |\n",
      "|    fps              | 141      |\n",
      "|    time_elapsed     | 63       |\n",
      "|    total_timesteps  | 9061     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000113 |\n",
      "|    n_updates        | 2240     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.92     |\n",
      "|    ep_rew_mean      | 9.92     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 884      |\n",
      "|    fps              | 141      |\n",
      "|    time_elapsed     | 64       |\n",
      "|    total_timesteps  | 9100     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000178 |\n",
      "|    n_updates        | 2249     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.92     |\n",
      "|    ep_rew_mean      | 9.92     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 888      |\n",
      "|    fps              | 141      |\n",
      "|    time_elapsed     | 64       |\n",
      "|    total_timesteps  | 9141     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000277 |\n",
      "|    n_updates        | 2260     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.93     |\n",
      "|    ep_rew_mean      | 9.93     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 892      |\n",
      "|    fps              | 141      |\n",
      "|    time_elapsed     | 64       |\n",
      "|    total_timesteps  | 9181     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000279 |\n",
      "|    n_updates        | 2270     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.96     |\n",
      "|    ep_rew_mean      | 9.96     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 896      |\n",
      "|    fps              | 141      |\n",
      "|    time_elapsed     | 65       |\n",
      "|    total_timesteps  | 9220     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00017  |\n",
      "|    n_updates        | 2279     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.98     |\n",
      "|    ep_rew_mean      | 9.98     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 900      |\n",
      "|    fps              | 141      |\n",
      "|    time_elapsed     | 65       |\n",
      "|    total_timesteps  | 9259     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000216 |\n",
      "|    n_updates        | 2289     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10       |\n",
      "|    ep_rew_mean      | 10       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 904      |\n",
      "|    fps              | 141      |\n",
      "|    time_elapsed     | 65       |\n",
      "|    total_timesteps  | 9298     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000147 |\n",
      "|    n_updates        | 2299     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.97     |\n",
      "|    ep_rew_mean      | 9.97     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 908      |\n",
      "|    fps              | 141      |\n",
      "|    time_elapsed     | 65       |\n",
      "|    total_timesteps  | 9337     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000137 |\n",
      "|    n_updates        | 2309     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.97     |\n",
      "|    ep_rew_mean      | 9.97     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 912      |\n",
      "|    fps              | 141      |\n",
      "|    time_elapsed     | 66       |\n",
      "|    total_timesteps  | 9380     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000197 |\n",
      "|    n_updates        | 2319     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.99     |\n",
      "|    ep_rew_mean      | 9.99     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 916      |\n",
      "|    fps              | 141      |\n",
      "|    time_elapsed     | 66       |\n",
      "|    total_timesteps  | 9420     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000262 |\n",
      "|    n_updates        | 2329     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10       |\n",
      "|    ep_rew_mean      | 10       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 920      |\n",
      "|    fps              | 141      |\n",
      "|    time_elapsed     | 66       |\n",
      "|    total_timesteps  | 9460     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000321 |\n",
      "|    n_updates        | 2339     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.98     |\n",
      "|    ep_rew_mean      | 9.98     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 924      |\n",
      "|    fps              | 141      |\n",
      "|    time_elapsed     | 66       |\n",
      "|    total_timesteps  | 9499     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000219 |\n",
      "|    n_updates        | 2349     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.99     |\n",
      "|    ep_rew_mean      | 9.99     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 928      |\n",
      "|    fps              | 141      |\n",
      "|    time_elapsed     | 67       |\n",
      "|    total_timesteps  | 9541     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00015  |\n",
      "|    n_updates        | 2360     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.97     |\n",
      "|    ep_rew_mean      | 9.97     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 932      |\n",
      "|    fps              | 141      |\n",
      "|    time_elapsed     | 67       |\n",
      "|    total_timesteps  | 9580     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000488 |\n",
      "|    n_updates        | 2369     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 10       |\n",
      "|    ep_rew_mean      | 10       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 936      |\n",
      "|    fps              | 141      |\n",
      "|    time_elapsed     | 68       |\n",
      "|    total_timesteps  | 9623     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000309 |\n",
      "|    n_updates        | 2380     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.99     |\n",
      "|    ep_rew_mean      | 9.99     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 940      |\n",
      "|    fps              | 141      |\n",
      "|    time_elapsed     | 68       |\n",
      "|    total_timesteps  | 9660     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000225 |\n",
      "|    n_updates        | 2389     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.95     |\n",
      "|    ep_rew_mean      | 9.95     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 944      |\n",
      "|    fps              | 141      |\n",
      "|    time_elapsed     | 68       |\n",
      "|    total_timesteps  | 9699     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00023  |\n",
      "|    n_updates        | 2399     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.9      |\n",
      "|    ep_rew_mean      | 9.9      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 948      |\n",
      "|    fps              | 141      |\n",
      "|    time_elapsed     | 68       |\n",
      "|    total_timesteps  | 9740     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000362 |\n",
      "|    n_updates        | 2409     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.89     |\n",
      "|    ep_rew_mean      | 9.89     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 952      |\n",
      "|    fps              | 141      |\n",
      "|    time_elapsed     | 69       |\n",
      "|    total_timesteps  | 9780     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000312 |\n",
      "|    n_updates        | 2419     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.91     |\n",
      "|    ep_rew_mean      | 9.91     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 956      |\n",
      "|    fps              | 141      |\n",
      "|    time_elapsed     | 69       |\n",
      "|    total_timesteps  | 9818     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000131 |\n",
      "|    n_updates        | 2429     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.94     |\n",
      "|    ep_rew_mean      | 9.94     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 960      |\n",
      "|    fps              | 141      |\n",
      "|    time_elapsed     | 69       |\n",
      "|    total_timesteps  | 9860     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000214 |\n",
      "|    n_updates        | 2439     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.93     |\n",
      "|    ep_rew_mean      | 9.93     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 964      |\n",
      "|    fps              | 141      |\n",
      "|    time_elapsed     | 70       |\n",
      "|    total_timesteps  | 9898     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000315 |\n",
      "|    n_updates        | 2449     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.95     |\n",
      "|    ep_rew_mean      | 9.95     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 968      |\n",
      "|    fps              | 141      |\n",
      "|    time_elapsed     | 70       |\n",
      "|    total_timesteps  | 9937     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000242 |\n",
      "|    n_updates        | 2459     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 9.96     |\n",
      "|    ep_rew_mean      | 9.96     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 972      |\n",
      "|    fps              | 141      |\n",
      "|    time_elapsed     | 70       |\n",
      "|    total_timesteps  | 9977     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 8.75e-05 |\n",
      "|    n_updates        | 2469     |\n",
      "----------------------------------\n",
      "Evaluating DQN...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. \n",
      "\u001b[1;31m셀의 코드를 검토하여 가능한 오류 원인을 식별하세요. \n",
      "\u001b[1;31m자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'>여기</a>를 클릭하세요. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from stable_baselines3 import PPO, A2C, DQN\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "# RenderCallback 클래스 정의\n",
    "class RenderCallback(BaseCallback):\n",
    "    def __init__(self, verbose=0):\n",
    "        super(RenderCallback, self).__init__(verbose)\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        frame = self.training_env.render()\n",
    "        if frame is not None and frame.size > 0:\n",
    "            cv2.imshow('CartPole', frame)\n",
    "            cv2.waitKey(1)\n",
    "        return True\n",
    "\n",
    "# 모델 학습 함수 정의\n",
    "def train_model(model_class, model_name, env, total_timesteps=10000):\n",
    "    model = model_class('MlpPolicy', env, verbose=1)\n",
    "    callback = RenderCallback()\n",
    "    model.learn(total_timesteps=total_timesteps, callback=callback)\n",
    "    return model\n",
    "\n",
    "# 성능 평가 함수 정의\n",
    "def evaluate_model(model, env, num_episodes=10):\n",
    "    episode_rewards = []\n",
    "    for _ in range(num_episodes):\n",
    "        obs = env.reset()\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "        while not done:\n",
    "            action, _states = model.predict(obs)\n",
    "            obs, reward, done, info = env.step(action)\n",
    "            total_reward += reward\n",
    "        episode_rewards.append(total_reward)\n",
    "    return np.mean(episode_rewards), np.std(episode_rewards)\n",
    "\n",
    "# 환경 설정\n",
    "env_id = 'CartPole-v1'\n",
    "total_timesteps = 10000\n",
    "num_episodes = 10\n",
    "\n",
    "# 모델 리스트\n",
    "models = [\n",
    "    (PPO, 'PPO'),\n",
    "    (A2C, 'A2C'),\n",
    "    (DQN, 'DQN')\n",
    "]\n",
    "\n",
    "# 성능 비교를 위한 로그 데이터 초기화\n",
    "log_data = {\n",
    "    \"model_name\": [],\n",
    "    \"mean_reward\": [],\n",
    "    \"std_reward\": []\n",
    "}\n",
    "\n",
    "# 각 모델 학습 및 평가\n",
    "for model_class, model_name in models:\n",
    "    env = make_vec_env(env_id, n_envs=1)\n",
    "    print(f'Training {model_name}...')\n",
    "    model = train_model(model_class, model_name, env, total_timesteps=total_timesteps)\n",
    "    \n",
    "    print(f'Evaluating {model_name}...')\n",
    "    mean_reward, std_reward = evaluate_model(model, env, num_episodes=num_episodes)\n",
    "    \n",
    "    log_data[\"model_name\"].append(model_name)\n",
    "    log_data[\"mean_reward\"].append(mean_reward)\n",
    "    log_data[\"std_reward\"].append(std_reward)\n",
    "\n",
    "# 시각화 함수 정의\n",
    "def plot_comparison(log_data):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(log_data[\"model_name\"], log_data[\"mean_reward\"], yerr=log_data[\"std_reward\"], capsize=5)\n",
    "    ax.set_ylabel('Mean Reward')\n",
    "    ax.set_title('Model Performance Comparison')\n",
    "    plt.show()\n",
    "\n",
    "# 성능 비교 시각화\n",
    "plot_comparison(log_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cv로 이미지프레임 받기 코드 (cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gymnasium pendulum을 cv로 받아 이미지 프레임을 cnn으로 처리하여 강화학습 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "env = gym.make('CartPole-v1', render_mode='rgb_array')\n",
    "\n",
    "def get_image_from_env(env):\n",
    "    frame = env.render()\n",
    "    return frame\n",
    "\n",
    "state = env.reset()\n",
    "image = get_image_from_env(env)\n",
    "\n",
    "cv2.imshow(\"Pendulum\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "def preprocess_image(image):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # 흑백으로 변환\n",
    "    image = cv2.resize(image, (64, 64))  # 크기 조정\n",
    "    image = image.astype(np.float32) / 255.0  # 정규화\n",
    "    image = np.expand_dims(image, axis=0)  # 배치 차원 추가\n",
    "    return image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class PendulumCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PendulumCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=2)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=2)\n",
    "        self.fc1 = nn.Linear(64*7*7, 256)\n",
    "        self.fc2 = nn.Linear(256, 1)  # 펜듈럼의 제어 변수는 1개\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.relu(self.conv3(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# 모델 초기화\n",
    "model = PendulumCNN().cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "for episode in range(1000):\n",
    "    state = env.reset()\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        image = get_image_from_env(env)\n",
    "        image = preprocess_image(image)\n",
    "        image = torch.FloatTensor(image).unsqueeze(0).cuda()  # 배치 차원 추가\n",
    "        \n",
    "        action = model(image).cpu().detach().numpy().flatten()\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        \n",
    "        # 손실 계산 및 역전파\n",
    "        optimizer.zero_grad()\n",
    "        output = model(image)\n",
    "        loss = criterion(output, torch.FloatTensor(action).unsqueeze(0).cuda())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_reward += reward\n",
    "    \n",
    "    print(f\"Episode {episode}, Total Reward: {total_reward}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 환경 설정\n",
    "Gymnasium의 Pendulum 환경을 설정하고 OpenCV를 사용하여 이미지를 캡처한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "env = gym.make('CartPole-v1', render_mode='rgb_array')\n",
    "\n",
    "def get_image_from_env(env):\n",
    "    frame = env.render()\n",
    "    return frame\n",
    "\n",
    "state = env.reset()\n",
    "image = get_image_from_env(env)\n",
    "\n",
    "cv2.imshow(\"Pendulum\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 이미지 처리\n",
    "이미지를 신경망에 입력할 수 있는 형태로 전처리한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # 흑백으로 변환\n",
    "    image = cv2.resize(image, (64, 64))  # 크기 조정\n",
    "    image = image.astype(np.float32) / 255.0  # 정규화\n",
    "    image = np.expand_dims(image, axis=0)  # 배치 차원 추가\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 신경망 설계\n",
    "CNN을 사용하여 이미지를 처리하고 상태를 인식한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class PendulumCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PendulumCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=2)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=2)\n",
    "        self.fc1 = nn.Linear(64*7*7, 256)\n",
    "        self.fc2 = nn.Linear(256, 1)  # 펜듈럼의 제어 변수는 1개\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.relu(self.conv3(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# 모델 초기화\n",
    "model = PendulumCNN().cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cnn rl 통합본"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0, Total Reward: 10.0, Steps: 10, Elapsed Time: 0.15 seconds\n",
      "Episode 1, Total Reward: 8.0, Steps: 8, Elapsed Time: 0.23 seconds\n",
      "Episode 2, Total Reward: 9.0, Steps: 9, Elapsed Time: 0.33 seconds\n",
      "Episode 3, Total Reward: 10.0, Steps: 10, Elapsed Time: 0.43 seconds\n",
      "Episode 4, Total Reward: 9.0, Steps: 9, Elapsed Time: 0.52 seconds\n",
      "Episode 5, Total Reward: 9.0, Steps: 9, Elapsed Time: 0.62 seconds\n",
      "Episode 6, Total Reward: 9.0, Steps: 9, Elapsed Time: 0.71 seconds\n",
      "Episode 7, Total Reward: 9.0, Steps: 9, Elapsed Time: 0.81 seconds\n",
      "Episode 8, Total Reward: 10.0, Steps: 10, Elapsed Time: 0.91 seconds\n",
      "Episode 9, Total Reward: 8.0, Steps: 8, Elapsed Time: 0.99 seconds\n",
      "Episode 10, Total Reward: 10.0, Steps: 10, Elapsed Time: 1.09 seconds\n",
      "Episode 11, Total Reward: 8.0, Steps: 8, Elapsed Time: 1.18 seconds\n",
      "Episode 12, Total Reward: 10.0, Steps: 10, Elapsed Time: 1.29 seconds\n",
      "Episode 13, Total Reward: 10.0, Steps: 10, Elapsed Time: 1.40 seconds\n",
      "Episode 14, Total Reward: 10.0, Steps: 10, Elapsed Time: 1.50 seconds\n",
      "Episode 15, Total Reward: 10.0, Steps: 10, Elapsed Time: 1.61 seconds\n",
      "Episode 16, Total Reward: 9.0, Steps: 9, Elapsed Time: 1.70 seconds\n",
      "Episode 17, Total Reward: 10.0, Steps: 10, Elapsed Time: 1.80 seconds\n",
      "Episode 18, Total Reward: 10.0, Steps: 10, Elapsed Time: 1.91 seconds\n",
      "Episode 19, Total Reward: 8.0, Steps: 8, Elapsed Time: 1.99 seconds\n",
      "Episode 20, Total Reward: 10.0, Steps: 10, Elapsed Time: 2.10 seconds\n",
      "Episode 21, Total Reward: 8.0, Steps: 8, Elapsed Time: 2.19 seconds\n",
      "Episode 22, Total Reward: 8.0, Steps: 8, Elapsed Time: 2.27 seconds\n",
      "Episode 23, Total Reward: 10.0, Steps: 10, Elapsed Time: 2.38 seconds\n",
      "Episode 24, Total Reward: 9.0, Steps: 9, Elapsed Time: 2.48 seconds\n",
      "Episode 25, Total Reward: 10.0, Steps: 10, Elapsed Time: 2.59 seconds\n",
      "Episode 26, Total Reward: 9.0, Steps: 9, Elapsed Time: 2.69 seconds\n",
      "Episode 27, Total Reward: 10.0, Steps: 10, Elapsed Time: 2.79 seconds\n",
      "Episode 28, Total Reward: 10.0, Steps: 10, Elapsed Time: 2.90 seconds\n",
      "Episode 29, Total Reward: 9.0, Steps: 9, Elapsed Time: 2.99 seconds\n",
      "Episode 30, Total Reward: 10.0, Steps: 10, Elapsed Time: 3.10 seconds\n",
      "Episode 31, Total Reward: 9.0, Steps: 9, Elapsed Time: 3.19 seconds\n",
      "Episode 32, Total Reward: 9.0, Steps: 9, Elapsed Time: 3.29 seconds\n",
      "Episode 33, Total Reward: 10.0, Steps: 10, Elapsed Time: 3.39 seconds\n",
      "Episode 34, Total Reward: 9.0, Steps: 9, Elapsed Time: 3.49 seconds\n",
      "Episode 35, Total Reward: 9.0, Steps: 9, Elapsed Time: 3.59 seconds\n",
      "Episode 36, Total Reward: 10.0, Steps: 10, Elapsed Time: 3.69 seconds\n",
      "Episode 37, Total Reward: 9.0, Steps: 9, Elapsed Time: 3.78 seconds\n",
      "Episode 38, Total Reward: 10.0, Steps: 10, Elapsed Time: 3.89 seconds\n",
      "Episode 39, Total Reward: 8.0, Steps: 8, Elapsed Time: 3.97 seconds\n",
      "Episode 40, Total Reward: 10.0, Steps: 10, Elapsed Time: 4.08 seconds\n",
      "Episode 41, Total Reward: 9.0, Steps: 9, Elapsed Time: 4.18 seconds\n",
      "Episode 42, Total Reward: 9.0, Steps: 9, Elapsed Time: 4.30 seconds\n",
      "Episode 43, Total Reward: 10.0, Steps: 10, Elapsed Time: 4.41 seconds\n",
      "Episode 44, Total Reward: 9.0, Steps: 9, Elapsed Time: 4.51 seconds\n",
      "Episode 45, Total Reward: 10.0, Steps: 10, Elapsed Time: 4.61 seconds\n",
      "Episode 46, Total Reward: 8.0, Steps: 8, Elapsed Time: 4.70 seconds\n",
      "Episode 47, Total Reward: 9.0, Steps: 9, Elapsed Time: 4.79 seconds\n",
      "Episode 48, Total Reward: 8.0, Steps: 8, Elapsed Time: 4.87 seconds\n",
      "Episode 49, Total Reward: 10.0, Steps: 10, Elapsed Time: 4.99 seconds\n",
      "Episode 50, Total Reward: 10.0, Steps: 10, Elapsed Time: 5.09 seconds\n",
      "Episode 51, Total Reward: 10.0, Steps: 10, Elapsed Time: 5.20 seconds\n",
      "Episode 52, Total Reward: 8.0, Steps: 8, Elapsed Time: 5.29 seconds\n",
      "Episode 53, Total Reward: 8.0, Steps: 8, Elapsed Time: 5.38 seconds\n",
      "Episode 54, Total Reward: 9.0, Steps: 9, Elapsed Time: 5.48 seconds\n",
      "Episode 55, Total Reward: 9.0, Steps: 9, Elapsed Time: 5.57 seconds\n",
      "Episode 56, Total Reward: 10.0, Steps: 10, Elapsed Time: 5.68 seconds\n",
      "Episode 57, Total Reward: 9.0, Steps: 9, Elapsed Time: 5.79 seconds\n",
      "Episode 58, Total Reward: 10.0, Steps: 10, Elapsed Time: 5.90 seconds\n",
      "Episode 59, Total Reward: 10.0, Steps: 10, Elapsed Time: 6.01 seconds\n",
      "Episode 60, Total Reward: 10.0, Steps: 10, Elapsed Time: 6.12 seconds\n",
      "Episode 61, Total Reward: 9.0, Steps: 9, Elapsed Time: 6.21 seconds\n",
      "Episode 62, Total Reward: 10.0, Steps: 10, Elapsed Time: 6.31 seconds\n",
      "Episode 63, Total Reward: 8.0, Steps: 8, Elapsed Time: 6.39 seconds\n",
      "Episode 64, Total Reward: 10.0, Steps: 10, Elapsed Time: 6.50 seconds\n",
      "Episode 65, Total Reward: 9.0, Steps: 9, Elapsed Time: 6.60 seconds\n",
      "Episode 66, Total Reward: 9.0, Steps: 9, Elapsed Time: 6.69 seconds\n",
      "Episode 67, Total Reward: 10.0, Steps: 10, Elapsed Time: 6.79 seconds\n",
      "Episode 68, Total Reward: 10.0, Steps: 10, Elapsed Time: 6.90 seconds\n",
      "Episode 69, Total Reward: 9.0, Steps: 9, Elapsed Time: 6.99 seconds\n",
      "Episode 70, Total Reward: 9.0, Steps: 9, Elapsed Time: 7.09 seconds\n",
      "Episode 71, Total Reward: 10.0, Steps: 10, Elapsed Time: 7.20 seconds\n",
      "Episode 72, Total Reward: 10.0, Steps: 10, Elapsed Time: 7.32 seconds\n",
      "Episode 73, Total Reward: 10.0, Steps: 10, Elapsed Time: 7.43 seconds\n",
      "Episode 74, Total Reward: 10.0, Steps: 10, Elapsed Time: 7.55 seconds\n",
      "Episode 75, Total Reward: 8.0, Steps: 8, Elapsed Time: 7.64 seconds\n",
      "Episode 76, Total Reward: 10.0, Steps: 10, Elapsed Time: 7.76 seconds\n",
      "Episode 77, Total Reward: 10.0, Steps: 10, Elapsed Time: 7.89 seconds\n",
      "Episode 78, Total Reward: 8.0, Steps: 8, Elapsed Time: 7.98 seconds\n",
      "Episode 79, Total Reward: 8.0, Steps: 8, Elapsed Time: 8.08 seconds\n",
      "Episode 80, Total Reward: 10.0, Steps: 10, Elapsed Time: 8.20 seconds\n",
      "Episode 81, Total Reward: 10.0, Steps: 10, Elapsed Time: 8.32 seconds\n",
      "Episode 82, Total Reward: 9.0, Steps: 9, Elapsed Time: 8.44 seconds\n",
      "Episode 83, Total Reward: 10.0, Steps: 10, Elapsed Time: 8.57 seconds\n",
      "Episode 84, Total Reward: 10.0, Steps: 10, Elapsed Time: 8.70 seconds\n",
      "Episode 85, Total Reward: 9.0, Steps: 9, Elapsed Time: 8.81 seconds\n",
      "Episode 86, Total Reward: 9.0, Steps: 9, Elapsed Time: 8.92 seconds\n",
      "Episode 87, Total Reward: 8.0, Steps: 8, Elapsed Time: 9.02 seconds\n",
      "Episode 88, Total Reward: 9.0, Steps: 9, Elapsed Time: 9.14 seconds\n",
      "Episode 89, Total Reward: 9.0, Steps: 9, Elapsed Time: 9.26 seconds\n",
      "Episode 90, Total Reward: 10.0, Steps: 10, Elapsed Time: 9.39 seconds\n",
      "Episode 91, Total Reward: 9.0, Steps: 9, Elapsed Time: 9.51 seconds\n",
      "Episode 92, Total Reward: 10.0, Steps: 10, Elapsed Time: 9.63 seconds\n",
      "Episode 93, Total Reward: 10.0, Steps: 10, Elapsed Time: 9.75 seconds\n",
      "Episode 94, Total Reward: 9.0, Steps: 9, Elapsed Time: 9.86 seconds\n",
      "Episode 95, Total Reward: 8.0, Steps: 8, Elapsed Time: 9.95 seconds\n",
      "Episode 96, Total Reward: 10.0, Steps: 10, Elapsed Time: 10.07 seconds\n",
      "Episode 97, Total Reward: 9.0, Steps: 9, Elapsed Time: 10.17 seconds\n",
      "Episode 98, Total Reward: 10.0, Steps: 10, Elapsed Time: 10.29 seconds\n",
      "Episode 99, Total Reward: 9.0, Steps: 9, Elapsed Time: 10.40 seconds\n",
      "Episode 100, Total Reward: 10.0, Steps: 10, Elapsed Time: 10.52 seconds\n",
      "Episode 101, Total Reward: 10.0, Steps: 10, Elapsed Time: 10.64 seconds\n",
      "Episode 102, Total Reward: 10.0, Steps: 10, Elapsed Time: 10.76 seconds\n",
      "Episode 103, Total Reward: 10.0, Steps: 10, Elapsed Time: 10.89 seconds\n",
      "Episode 104, Total Reward: 8.0, Steps: 8, Elapsed Time: 10.99 seconds\n",
      "Episode 105, Total Reward: 10.0, Steps: 10, Elapsed Time: 11.11 seconds\n",
      "Episode 106, Total Reward: 8.0, Steps: 8, Elapsed Time: 11.21 seconds\n",
      "Episode 107, Total Reward: 10.0, Steps: 10, Elapsed Time: 11.34 seconds\n",
      "Episode 108, Total Reward: 8.0, Steps: 8, Elapsed Time: 11.43 seconds\n",
      "Episode 109, Total Reward: 10.0, Steps: 10, Elapsed Time: 11.56 seconds\n",
      "Episode 110, Total Reward: 9.0, Steps: 9, Elapsed Time: 11.66 seconds\n",
      "Episode 111, Total Reward: 10.0, Steps: 10, Elapsed Time: 11.78 seconds\n",
      "Episode 112, Total Reward: 9.0, Steps: 9, Elapsed Time: 11.88 seconds\n",
      "Episode 113, Total Reward: 10.0, Steps: 10, Elapsed Time: 12.01 seconds\n",
      "Episode 114, Total Reward: 10.0, Steps: 10, Elapsed Time: 12.13 seconds\n",
      "Episode 115, Total Reward: 11.0, Steps: 11, Elapsed Time: 12.26 seconds\n",
      "Episode 116, Total Reward: 9.0, Steps: 9, Elapsed Time: 12.37 seconds\n",
      "Episode 117, Total Reward: 10.0, Steps: 10, Elapsed Time: 12.50 seconds\n",
      "Episode 118, Total Reward: 10.0, Steps: 10, Elapsed Time: 12.62 seconds\n",
      "Episode 119, Total Reward: 9.0, Steps: 9, Elapsed Time: 12.73 seconds\n",
      "Episode 120, Total Reward: 10.0, Steps: 10, Elapsed Time: 12.84 seconds\n",
      "Episode 121, Total Reward: 9.0, Steps: 9, Elapsed Time: 12.95 seconds\n",
      "Episode 122, Total Reward: 9.0, Steps: 9, Elapsed Time: 13.06 seconds\n",
      "Episode 123, Total Reward: 9.0, Steps: 9, Elapsed Time: 13.17 seconds\n",
      "Episode 124, Total Reward: 10.0, Steps: 10, Elapsed Time: 13.29 seconds\n",
      "Episode 125, Total Reward: 8.0, Steps: 8, Elapsed Time: 13.38 seconds\n",
      "Episode 126, Total Reward: 10.0, Steps: 10, Elapsed Time: 13.50 seconds\n",
      "Episode 127, Total Reward: 11.0, Steps: 11, Elapsed Time: 13.63 seconds\n",
      "Episode 128, Total Reward: 10.0, Steps: 10, Elapsed Time: 13.75 seconds\n",
      "Episode 129, Total Reward: 9.0, Steps: 9, Elapsed Time: 13.87 seconds\n",
      "Episode 130, Total Reward: 9.0, Steps: 9, Elapsed Time: 13.98 seconds\n",
      "Episode 131, Total Reward: 10.0, Steps: 10, Elapsed Time: 14.11 seconds\n",
      "Episode 132, Total Reward: 10.0, Steps: 10, Elapsed Time: 14.22 seconds\n",
      "Episode 133, Total Reward: 10.0, Steps: 10, Elapsed Time: 14.34 seconds\n",
      "Episode 134, Total Reward: 9.0, Steps: 9, Elapsed Time: 14.45 seconds\n",
      "Episode 135, Total Reward: 10.0, Steps: 10, Elapsed Time: 14.58 seconds\n",
      "Episode 136, Total Reward: 9.0, Steps: 9, Elapsed Time: 14.69 seconds\n",
      "Episode 137, Total Reward: 9.0, Steps: 9, Elapsed Time: 14.80 seconds\n",
      "Episode 138, Total Reward: 10.0, Steps: 10, Elapsed Time: 14.92 seconds\n",
      "Episode 139, Total Reward: 9.0, Steps: 9, Elapsed Time: 15.03 seconds\n",
      "Episode 140, Total Reward: 9.0, Steps: 9, Elapsed Time: 15.15 seconds\n",
      "Episode 141, Total Reward: 9.0, Steps: 9, Elapsed Time: 15.27 seconds\n",
      "Episode 142, Total Reward: 10.0, Steps: 10, Elapsed Time: 15.39 seconds\n",
      "Episode 143, Total Reward: 10.0, Steps: 10, Elapsed Time: 15.50 seconds\n",
      "Episode 144, Total Reward: 8.0, Steps: 8, Elapsed Time: 15.61 seconds\n",
      "Episode 145, Total Reward: 9.0, Steps: 9, Elapsed Time: 15.73 seconds\n",
      "Episode 146, Total Reward: 8.0, Steps: 8, Elapsed Time: 15.83 seconds\n",
      "Episode 147, Total Reward: 10.0, Steps: 10, Elapsed Time: 15.95 seconds\n",
      "Episode 148, Total Reward: 9.0, Steps: 9, Elapsed Time: 16.06 seconds\n",
      "Episode 149, Total Reward: 10.0, Steps: 10, Elapsed Time: 16.18 seconds\n",
      "Episode 150, Total Reward: 10.0, Steps: 10, Elapsed Time: 16.30 seconds\n",
      "Episode 151, Total Reward: 10.0, Steps: 10, Elapsed Time: 16.43 seconds\n",
      "Episode 152, Total Reward: 9.0, Steps: 9, Elapsed Time: 16.54 seconds\n",
      "Episode 153, Total Reward: 9.0, Steps: 9, Elapsed Time: 16.65 seconds\n",
      "Episode 154, Total Reward: 10.0, Steps: 10, Elapsed Time: 16.77 seconds\n",
      "Episode 155, Total Reward: 10.0, Steps: 10, Elapsed Time: 16.90 seconds\n",
      "Episode 156, Total Reward: 10.0, Steps: 10, Elapsed Time: 17.02 seconds\n",
      "Episode 157, Total Reward: 11.0, Steps: 11, Elapsed Time: 17.15 seconds\n",
      "Episode 158, Total Reward: 10.0, Steps: 10, Elapsed Time: 17.27 seconds\n",
      "Episode 159, Total Reward: 9.0, Steps: 9, Elapsed Time: 17.38 seconds\n",
      "Episode 160, Total Reward: 9.0, Steps: 9, Elapsed Time: 17.50 seconds\n",
      "Episode 161, Total Reward: 9.0, Steps: 9, Elapsed Time: 17.60 seconds\n",
      "Episode 162, Total Reward: 10.0, Steps: 10, Elapsed Time: 17.73 seconds\n",
      "Episode 163, Total Reward: 9.0, Steps: 9, Elapsed Time: 17.84 seconds\n",
      "Episode 164, Total Reward: 10.0, Steps: 10, Elapsed Time: 17.95 seconds\n",
      "Episode 165, Total Reward: 9.0, Steps: 9, Elapsed Time: 18.06 seconds\n",
      "Episode 166, Total Reward: 9.0, Steps: 9, Elapsed Time: 18.17 seconds\n",
      "Episode 167, Total Reward: 9.0, Steps: 9, Elapsed Time: 18.28 seconds\n",
      "Episode 168, Total Reward: 8.0, Steps: 8, Elapsed Time: 18.37 seconds\n",
      "Episode 169, Total Reward: 8.0, Steps: 8, Elapsed Time: 18.47 seconds\n",
      "Episode 170, Total Reward: 8.0, Steps: 8, Elapsed Time: 18.57 seconds\n",
      "Episode 171, Total Reward: 10.0, Steps: 10, Elapsed Time: 18.73 seconds\n",
      "Episode 172, Total Reward: 10.0, Steps: 10, Elapsed Time: 18.88 seconds\n",
      "Episode 173, Total Reward: 10.0, Steps: 10, Elapsed Time: 19.00 seconds\n",
      "Episode 174, Total Reward: 10.0, Steps: 10, Elapsed Time: 19.13 seconds\n",
      "Episode 175, Total Reward: 9.0, Steps: 9, Elapsed Time: 19.23 seconds\n",
      "Episode 176, Total Reward: 10.0, Steps: 10, Elapsed Time: 19.35 seconds\n",
      "Episode 177, Total Reward: 8.0, Steps: 8, Elapsed Time: 19.45 seconds\n",
      "Episode 178, Total Reward: 9.0, Steps: 9, Elapsed Time: 19.56 seconds\n",
      "Episode 179, Total Reward: 8.0, Steps: 8, Elapsed Time: 19.66 seconds\n",
      "Episode 180, Total Reward: 9.0, Steps: 9, Elapsed Time: 19.77 seconds\n",
      "Episode 181, Total Reward: 10.0, Steps: 10, Elapsed Time: 19.89 seconds\n",
      "Episode 182, Total Reward: 10.0, Steps: 10, Elapsed Time: 20.01 seconds\n",
      "Episode 183, Total Reward: 10.0, Steps: 10, Elapsed Time: 20.12 seconds\n",
      "Episode 184, Total Reward: 8.0, Steps: 8, Elapsed Time: 20.22 seconds\n",
      "Episode 185, Total Reward: 10.0, Steps: 10, Elapsed Time: 20.33 seconds\n",
      "Episode 186, Total Reward: 9.0, Steps: 9, Elapsed Time: 20.44 seconds\n",
      "Episode 187, Total Reward: 9.0, Steps: 9, Elapsed Time: 20.54 seconds\n",
      "Episode 188, Total Reward: 9.0, Steps: 9, Elapsed Time: 20.65 seconds\n",
      "Episode 189, Total Reward: 10.0, Steps: 10, Elapsed Time: 20.77 seconds\n",
      "Episode 190, Total Reward: 10.0, Steps: 10, Elapsed Time: 20.91 seconds\n",
      "Episode 191, Total Reward: 10.0, Steps: 10, Elapsed Time: 21.03 seconds\n",
      "Episode 192, Total Reward: 10.0, Steps: 10, Elapsed Time: 21.15 seconds\n",
      "Episode 193, Total Reward: 9.0, Steps: 9, Elapsed Time: 21.27 seconds\n",
      "Episode 194, Total Reward: 9.0, Steps: 9, Elapsed Time: 21.38 seconds\n",
      "Episode 195, Total Reward: 9.0, Steps: 9, Elapsed Time: 21.48 seconds\n",
      "Episode 196, Total Reward: 8.0, Steps: 8, Elapsed Time: 21.58 seconds\n",
      "Episode 197, Total Reward: 8.0, Steps: 8, Elapsed Time: 21.68 seconds\n",
      "Episode 198, Total Reward: 9.0, Steps: 9, Elapsed Time: 21.79 seconds\n",
      "Episode 199, Total Reward: 9.0, Steps: 9, Elapsed Time: 21.90 seconds\n",
      "Episode 200, Total Reward: 10.0, Steps: 10, Elapsed Time: 22.03 seconds\n",
      "Episode 201, Total Reward: 9.0, Steps: 9, Elapsed Time: 22.14 seconds\n",
      "Episode 202, Total Reward: 9.0, Steps: 9, Elapsed Time: 22.25 seconds\n",
      "Episode 203, Total Reward: 9.0, Steps: 9, Elapsed Time: 22.37 seconds\n",
      "Episode 204, Total Reward: 8.0, Steps: 8, Elapsed Time: 22.47 seconds\n",
      "Episode 205, Total Reward: 9.0, Steps: 9, Elapsed Time: 22.58 seconds\n",
      "Episode 206, Total Reward: 8.0, Steps: 8, Elapsed Time: 22.68 seconds\n",
      "Episode 207, Total Reward: 10.0, Steps: 10, Elapsed Time: 22.80 seconds\n",
      "Episode 208, Total Reward: 10.0, Steps: 10, Elapsed Time: 22.93 seconds\n",
      "Episode 209, Total Reward: 10.0, Steps: 10, Elapsed Time: 23.05 seconds\n",
      "Episode 210, Total Reward: 9.0, Steps: 9, Elapsed Time: 23.16 seconds\n",
      "Episode 211, Total Reward: 9.0, Steps: 9, Elapsed Time: 23.28 seconds\n",
      "Episode 212, Total Reward: 9.0, Steps: 9, Elapsed Time: 23.39 seconds\n",
      "Episode 213, Total Reward: 9.0, Steps: 9, Elapsed Time: 23.50 seconds\n",
      "Episode 214, Total Reward: 9.0, Steps: 9, Elapsed Time: 23.61 seconds\n",
      "Episode 215, Total Reward: 9.0, Steps: 9, Elapsed Time: 23.72 seconds\n",
      "Episode 216, Total Reward: 9.0, Steps: 9, Elapsed Time: 23.83 seconds\n",
      "Episode 217, Total Reward: 10.0, Steps: 10, Elapsed Time: 23.95 seconds\n",
      "Episode 218, Total Reward: 11.0, Steps: 11, Elapsed Time: 24.10 seconds\n",
      "Episode 219, Total Reward: 8.0, Steps: 8, Elapsed Time: 24.19 seconds\n",
      "Episode 220, Total Reward: 8.0, Steps: 8, Elapsed Time: 24.29 seconds\n",
      "Episode 221, Total Reward: 9.0, Steps: 9, Elapsed Time: 24.40 seconds\n",
      "Episode 222, Total Reward: 11.0, Steps: 11, Elapsed Time: 24.53 seconds\n",
      "Episode 223, Total Reward: 9.0, Steps: 9, Elapsed Time: 24.64 seconds\n",
      "Episode 224, Total Reward: 10.0, Steps: 10, Elapsed Time: 24.76 seconds\n",
      "Episode 225, Total Reward: 10.0, Steps: 10, Elapsed Time: 24.88 seconds\n",
      "Episode 226, Total Reward: 10.0, Steps: 10, Elapsed Time: 25.00 seconds\n",
      "Episode 227, Total Reward: 10.0, Steps: 10, Elapsed Time: 25.12 seconds\n",
      "Episode 228, Total Reward: 9.0, Steps: 9, Elapsed Time: 25.24 seconds\n",
      "Episode 229, Total Reward: 9.0, Steps: 9, Elapsed Time: 25.35 seconds\n",
      "Episode 230, Total Reward: 10.0, Steps: 10, Elapsed Time: 25.48 seconds\n",
      "Episode 231, Total Reward: 11.0, Steps: 11, Elapsed Time: 25.62 seconds\n",
      "Episode 232, Total Reward: 9.0, Steps: 9, Elapsed Time: 25.74 seconds\n",
      "Episode 233, Total Reward: 9.0, Steps: 9, Elapsed Time: 25.85 seconds\n",
      "Episode 234, Total Reward: 8.0, Steps: 8, Elapsed Time: 25.95 seconds\n",
      "Episode 235, Total Reward: 10.0, Steps: 10, Elapsed Time: 26.07 seconds\n",
      "Episode 236, Total Reward: 10.0, Steps: 10, Elapsed Time: 26.20 seconds\n",
      "Episode 237, Total Reward: 8.0, Steps: 8, Elapsed Time: 26.31 seconds\n",
      "Episode 238, Total Reward: 9.0, Steps: 9, Elapsed Time: 26.42 seconds\n",
      "Episode 239, Total Reward: 9.0, Steps: 9, Elapsed Time: 26.53 seconds\n",
      "Episode 240, Total Reward: 10.0, Steps: 10, Elapsed Time: 26.65 seconds\n",
      "Episode 241, Total Reward: 10.0, Steps: 10, Elapsed Time: 26.77 seconds\n",
      "Episode 242, Total Reward: 9.0, Steps: 9, Elapsed Time: 26.88 seconds\n",
      "Episode 243, Total Reward: 10.0, Steps: 10, Elapsed Time: 27.00 seconds\n",
      "Episode 244, Total Reward: 10.0, Steps: 10, Elapsed Time: 27.12 seconds\n",
      "Episode 245, Total Reward: 10.0, Steps: 10, Elapsed Time: 27.23 seconds\n",
      "Episode 246, Total Reward: 8.0, Steps: 8, Elapsed Time: 27.33 seconds\n",
      "Episode 247, Total Reward: 10.0, Steps: 10, Elapsed Time: 27.46 seconds\n",
      "Episode 248, Total Reward: 10.0, Steps: 10, Elapsed Time: 27.58 seconds\n",
      "Episode 249, Total Reward: 10.0, Steps: 10, Elapsed Time: 27.71 seconds\n",
      "Episode 250, Total Reward: 9.0, Steps: 9, Elapsed Time: 27.81 seconds\n",
      "Episode 251, Total Reward: 9.0, Steps: 9, Elapsed Time: 27.92 seconds\n",
      "Episode 252, Total Reward: 8.0, Steps: 8, Elapsed Time: 28.02 seconds\n",
      "Episode 253, Total Reward: 10.0, Steps: 10, Elapsed Time: 28.15 seconds\n",
      "Episode 254, Total Reward: 10.0, Steps: 10, Elapsed Time: 28.27 seconds\n",
      "Episode 255, Total Reward: 10.0, Steps: 10, Elapsed Time: 28.39 seconds\n",
      "Episode 256, Total Reward: 10.0, Steps: 10, Elapsed Time: 28.52 seconds\n",
      "Episode 257, Total Reward: 10.0, Steps: 10, Elapsed Time: 28.65 seconds\n",
      "Episode 258, Total Reward: 10.0, Steps: 10, Elapsed Time: 28.77 seconds\n",
      "Episode 259, Total Reward: 9.0, Steps: 9, Elapsed Time: 28.89 seconds\n",
      "Episode 260, Total Reward: 10.0, Steps: 10, Elapsed Time: 29.03 seconds\n",
      "Episode 261, Total Reward: 8.0, Steps: 8, Elapsed Time: 29.13 seconds\n",
      "Episode 262, Total Reward: 9.0, Steps: 9, Elapsed Time: 29.24 seconds\n",
      "Episode 263, Total Reward: 10.0, Steps: 10, Elapsed Time: 29.37 seconds\n",
      "Episode 264, Total Reward: 10.0, Steps: 10, Elapsed Time: 29.50 seconds\n",
      "Episode 265, Total Reward: 10.0, Steps: 10, Elapsed Time: 29.64 seconds\n",
      "Episode 266, Total Reward: 11.0, Steps: 11, Elapsed Time: 29.78 seconds\n",
      "Episode 267, Total Reward: 11.0, Steps: 11, Elapsed Time: 29.92 seconds\n",
      "Episode 268, Total Reward: 9.0, Steps: 9, Elapsed Time: 30.03 seconds\n",
      "Episode 269, Total Reward: 10.0, Steps: 10, Elapsed Time: 30.16 seconds\n",
      "Episode 270, Total Reward: 8.0, Steps: 8, Elapsed Time: 30.25 seconds\n",
      "Episode 271, Total Reward: 9.0, Steps: 9, Elapsed Time: 30.37 seconds\n",
      "Episode 272, Total Reward: 9.0, Steps: 9, Elapsed Time: 30.48 seconds\n",
      "Episode 273, Total Reward: 9.0, Steps: 9, Elapsed Time: 30.59 seconds\n",
      "Episode 274, Total Reward: 9.0, Steps: 9, Elapsed Time: 30.71 seconds\n",
      "Episode 275, Total Reward: 10.0, Steps: 10, Elapsed Time: 30.83 seconds\n",
      "Episode 276, Total Reward: 10.0, Steps: 10, Elapsed Time: 30.95 seconds\n",
      "Episode 277, Total Reward: 10.0, Steps: 10, Elapsed Time: 31.07 seconds\n",
      "Episode 278, Total Reward: 10.0, Steps: 10, Elapsed Time: 31.19 seconds\n",
      "Episode 279, Total Reward: 9.0, Steps: 9, Elapsed Time: 31.30 seconds\n",
      "Episode 280, Total Reward: 10.0, Steps: 10, Elapsed Time: 31.41 seconds\n",
      "Episode 281, Total Reward: 11.0, Steps: 11, Elapsed Time: 31.55 seconds\n",
      "Episode 282, Total Reward: 10.0, Steps: 10, Elapsed Time: 31.67 seconds\n",
      "Episode 283, Total Reward: 9.0, Steps: 9, Elapsed Time: 31.78 seconds\n",
      "Episode 284, Total Reward: 10.0, Steps: 10, Elapsed Time: 31.90 seconds\n",
      "Episode 285, Total Reward: 9.0, Steps: 9, Elapsed Time: 32.01 seconds\n",
      "Episode 286, Total Reward: 10.0, Steps: 10, Elapsed Time: 32.13 seconds\n",
      "Episode 287, Total Reward: 10.0, Steps: 10, Elapsed Time: 32.26 seconds\n",
      "Episode 288, Total Reward: 10.0, Steps: 10, Elapsed Time: 32.38 seconds\n",
      "Episode 289, Total Reward: 9.0, Steps: 9, Elapsed Time: 32.49 seconds\n",
      "Episode 290, Total Reward: 9.0, Steps: 9, Elapsed Time: 32.60 seconds\n",
      "Episode 291, Total Reward: 8.0, Steps: 8, Elapsed Time: 32.70 seconds\n",
      "Episode 292, Total Reward: 10.0, Steps: 10, Elapsed Time: 32.83 seconds\n",
      "Episode 293, Total Reward: 10.0, Steps: 10, Elapsed Time: 32.96 seconds\n",
      "Episode 294, Total Reward: 9.0, Steps: 9, Elapsed Time: 33.07 seconds\n",
      "Episode 295, Total Reward: 10.0, Steps: 10, Elapsed Time: 33.19 seconds\n",
      "Episode 296, Total Reward: 8.0, Steps: 8, Elapsed Time: 33.29 seconds\n",
      "Episode 297, Total Reward: 9.0, Steps: 9, Elapsed Time: 33.43 seconds\n",
      "Episode 298, Total Reward: 9.0, Steps: 9, Elapsed Time: 33.54 seconds\n",
      "Episode 299, Total Reward: 10.0, Steps: 10, Elapsed Time: 33.68 seconds\n",
      "Episode 300, Total Reward: 10.0, Steps: 10, Elapsed Time: 33.80 seconds\n",
      "Episode 301, Total Reward: 10.0, Steps: 10, Elapsed Time: 33.92 seconds\n",
      "Episode 302, Total Reward: 9.0, Steps: 9, Elapsed Time: 34.03 seconds\n",
      "Episode 303, Total Reward: 9.0, Steps: 9, Elapsed Time: 34.14 seconds\n",
      "Episode 304, Total Reward: 9.0, Steps: 9, Elapsed Time: 34.24 seconds\n",
      "Episode 305, Total Reward: 8.0, Steps: 8, Elapsed Time: 34.34 seconds\n",
      "Episode 306, Total Reward: 10.0, Steps: 10, Elapsed Time: 34.46 seconds\n",
      "Episode 307, Total Reward: 11.0, Steps: 11, Elapsed Time: 34.59 seconds\n",
      "Episode 308, Total Reward: 9.0, Steps: 9, Elapsed Time: 34.71 seconds\n",
      "Episode 309, Total Reward: 8.0, Steps: 8, Elapsed Time: 34.81 seconds\n",
      "Episode 310, Total Reward: 9.0, Steps: 9, Elapsed Time: 34.92 seconds\n",
      "Episode 311, Total Reward: 9.0, Steps: 9, Elapsed Time: 35.03 seconds\n",
      "Episode 312, Total Reward: 9.0, Steps: 9, Elapsed Time: 35.15 seconds\n",
      "Episode 313, Total Reward: 8.0, Steps: 8, Elapsed Time: 35.25 seconds\n",
      "Episode 314, Total Reward: 8.0, Steps: 8, Elapsed Time: 35.35 seconds\n",
      "Episode 315, Total Reward: 9.0, Steps: 9, Elapsed Time: 35.46 seconds\n",
      "Episode 316, Total Reward: 9.0, Steps: 9, Elapsed Time: 35.59 seconds\n",
      "Episode 317, Total Reward: 8.0, Steps: 8, Elapsed Time: 35.71 seconds\n",
      "Episode 318, Total Reward: 8.0, Steps: 8, Elapsed Time: 35.81 seconds\n",
      "Episode 319, Total Reward: 10.0, Steps: 10, Elapsed Time: 35.93 seconds\n",
      "Episode 320, Total Reward: 10.0, Steps: 10, Elapsed Time: 36.05 seconds\n",
      "Episode 321, Total Reward: 10.0, Steps: 10, Elapsed Time: 36.18 seconds\n",
      "Episode 322, Total Reward: 9.0, Steps: 9, Elapsed Time: 36.29 seconds\n",
      "Episode 323, Total Reward: 9.0, Steps: 9, Elapsed Time: 36.40 seconds\n",
      "Episode 324, Total Reward: 9.0, Steps: 9, Elapsed Time: 36.51 seconds\n",
      "Episode 325, Total Reward: 10.0, Steps: 10, Elapsed Time: 36.63 seconds\n",
      "Episode 326, Total Reward: 10.0, Steps: 10, Elapsed Time: 36.75 seconds\n",
      "Episode 327, Total Reward: 9.0, Steps: 9, Elapsed Time: 36.86 seconds\n",
      "Episode 328, Total Reward: 9.0, Steps: 9, Elapsed Time: 36.97 seconds\n",
      "Episode 329, Total Reward: 10.0, Steps: 10, Elapsed Time: 37.09 seconds\n",
      "Episode 330, Total Reward: 9.0, Steps: 9, Elapsed Time: 37.20 seconds\n",
      "Episode 331, Total Reward: 8.0, Steps: 8, Elapsed Time: 37.30 seconds\n",
      "Episode 332, Total Reward: 9.0, Steps: 9, Elapsed Time: 37.41 seconds\n",
      "Episode 333, Total Reward: 10.0, Steps: 10, Elapsed Time: 37.53 seconds\n",
      "Episode 334, Total Reward: 8.0, Steps: 8, Elapsed Time: 37.64 seconds\n",
      "Episode 335, Total Reward: 8.0, Steps: 8, Elapsed Time: 37.73 seconds\n",
      "Episode 336, Total Reward: 9.0, Steps: 9, Elapsed Time: 37.84 seconds\n",
      "Episode 337, Total Reward: 9.0, Steps: 9, Elapsed Time: 37.95 seconds\n",
      "Episode 338, Total Reward: 9.0, Steps: 9, Elapsed Time: 38.06 seconds\n",
      "Episode 339, Total Reward: 8.0, Steps: 8, Elapsed Time: 38.16 seconds\n",
      "Episode 340, Total Reward: 9.0, Steps: 9, Elapsed Time: 38.27 seconds\n",
      "Episode 341, Total Reward: 9.0, Steps: 9, Elapsed Time: 38.37 seconds\n",
      "Episode 342, Total Reward: 9.0, Steps: 9, Elapsed Time: 38.48 seconds\n",
      "Episode 343, Total Reward: 10.0, Steps: 10, Elapsed Time: 38.60 seconds\n",
      "Episode 344, Total Reward: 9.0, Steps: 9, Elapsed Time: 38.72 seconds\n",
      "Episode 345, Total Reward: 10.0, Steps: 10, Elapsed Time: 38.85 seconds\n",
      "Episode 346, Total Reward: 9.0, Steps: 9, Elapsed Time: 38.97 seconds\n",
      "Episode 347, Total Reward: 9.0, Steps: 9, Elapsed Time: 39.08 seconds\n",
      "Episode 348, Total Reward: 9.0, Steps: 9, Elapsed Time: 39.19 seconds\n",
      "Episode 349, Total Reward: 10.0, Steps: 10, Elapsed Time: 39.32 seconds\n",
      "Episode 350, Total Reward: 10.0, Steps: 10, Elapsed Time: 39.44 seconds\n",
      "Episode 351, Total Reward: 8.0, Steps: 8, Elapsed Time: 39.54 seconds\n",
      "Episode 352, Total Reward: 9.0, Steps: 9, Elapsed Time: 39.65 seconds\n",
      "Episode 353, Total Reward: 10.0, Steps: 10, Elapsed Time: 39.80 seconds\n",
      "Episode 354, Total Reward: 10.0, Steps: 10, Elapsed Time: 39.92 seconds\n",
      "Episode 355, Total Reward: 9.0, Steps: 9, Elapsed Time: 40.02 seconds\n",
      "Episode 356, Total Reward: 10.0, Steps: 10, Elapsed Time: 40.14 seconds\n",
      "Episode 357, Total Reward: 9.0, Steps: 9, Elapsed Time: 40.25 seconds\n",
      "Episode 358, Total Reward: 10.0, Steps: 10, Elapsed Time: 40.37 seconds\n",
      "Episode 359, Total Reward: 8.0, Steps: 8, Elapsed Time: 40.47 seconds\n",
      "Episode 360, Total Reward: 8.0, Steps: 8, Elapsed Time: 40.56 seconds\n",
      "Episode 361, Total Reward: 9.0, Steps: 9, Elapsed Time: 40.67 seconds\n",
      "Episode 362, Total Reward: 9.0, Steps: 9, Elapsed Time: 40.78 seconds\n",
      "Episode 363, Total Reward: 8.0, Steps: 8, Elapsed Time: 40.87 seconds\n",
      "Episode 364, Total Reward: 9.0, Steps: 9, Elapsed Time: 40.99 seconds\n",
      "Episode 365, Total Reward: 10.0, Steps: 10, Elapsed Time: 41.11 seconds\n",
      "Episode 366, Total Reward: 10.0, Steps: 10, Elapsed Time: 41.23 seconds\n",
      "Episode 367, Total Reward: 9.0, Steps: 9, Elapsed Time: 41.34 seconds\n",
      "Episode 368, Total Reward: 10.0, Steps: 10, Elapsed Time: 41.46 seconds\n",
      "Episode 369, Total Reward: 9.0, Steps: 9, Elapsed Time: 41.57 seconds\n",
      "Episode 370, Total Reward: 9.0, Steps: 9, Elapsed Time: 41.68 seconds\n",
      "Episode 371, Total Reward: 9.0, Steps: 9, Elapsed Time: 41.79 seconds\n",
      "Episode 372, Total Reward: 8.0, Steps: 8, Elapsed Time: 41.89 seconds\n",
      "Episode 373, Total Reward: 9.0, Steps: 9, Elapsed Time: 42.00 seconds\n",
      "Episode 374, Total Reward: 9.0, Steps: 9, Elapsed Time: 42.11 seconds\n",
      "Episode 375, Total Reward: 10.0, Steps: 10, Elapsed Time: 42.24 seconds\n",
      "Episode 376, Total Reward: 9.0, Steps: 9, Elapsed Time: 42.35 seconds\n",
      "Episode 377, Total Reward: 9.0, Steps: 9, Elapsed Time: 42.46 seconds\n",
      "Episode 378, Total Reward: 10.0, Steps: 10, Elapsed Time: 42.58 seconds\n",
      "Episode 379, Total Reward: 10.0, Steps: 10, Elapsed Time: 42.70 seconds\n",
      "Episode 380, Total Reward: 11.0, Steps: 11, Elapsed Time: 42.84 seconds\n",
      "Episode 381, Total Reward: 9.0, Steps: 9, Elapsed Time: 42.95 seconds\n",
      "Episode 382, Total Reward: 9.0, Steps: 9, Elapsed Time: 43.05 seconds\n",
      "Episode 383, Total Reward: 9.0, Steps: 9, Elapsed Time: 43.16 seconds\n",
      "Episode 384, Total Reward: 10.0, Steps: 10, Elapsed Time: 43.28 seconds\n",
      "Episode 385, Total Reward: 10.0, Steps: 10, Elapsed Time: 43.40 seconds\n",
      "Episode 386, Total Reward: 9.0, Steps: 9, Elapsed Time: 43.51 seconds\n",
      "Episode 387, Total Reward: 9.0, Steps: 9, Elapsed Time: 43.62 seconds\n",
      "Episode 388, Total Reward: 9.0, Steps: 9, Elapsed Time: 43.73 seconds\n",
      "Episode 389, Total Reward: 10.0, Steps: 10, Elapsed Time: 43.85 seconds\n",
      "Episode 390, Total Reward: 9.0, Steps: 9, Elapsed Time: 43.96 seconds\n",
      "Episode 391, Total Reward: 9.0, Steps: 9, Elapsed Time: 44.07 seconds\n",
      "Episode 392, Total Reward: 10.0, Steps: 10, Elapsed Time: 44.19 seconds\n",
      "Episode 393, Total Reward: 9.0, Steps: 9, Elapsed Time: 44.30 seconds\n",
      "Episode 394, Total Reward: 10.0, Steps: 10, Elapsed Time: 44.42 seconds\n",
      "Episode 395, Total Reward: 10.0, Steps: 10, Elapsed Time: 44.55 seconds\n",
      "Episode 396, Total Reward: 10.0, Steps: 10, Elapsed Time: 44.67 seconds\n",
      "Episode 397, Total Reward: 8.0, Steps: 8, Elapsed Time: 44.76 seconds\n",
      "Episode 398, Total Reward: 10.0, Steps: 10, Elapsed Time: 44.89 seconds\n",
      "Episode 399, Total Reward: 10.0, Steps: 10, Elapsed Time: 45.02 seconds\n",
      "Episode 400, Total Reward: 8.0, Steps: 8, Elapsed Time: 45.12 seconds\n",
      "Episode 401, Total Reward: 9.0, Steps: 9, Elapsed Time: 45.23 seconds\n",
      "Episode 402, Total Reward: 10.0, Steps: 10, Elapsed Time: 45.35 seconds\n",
      "Episode 403, Total Reward: 10.0, Steps: 10, Elapsed Time: 45.49 seconds\n",
      "Episode 404, Total Reward: 10.0, Steps: 10, Elapsed Time: 45.62 seconds\n",
      "Episode 405, Total Reward: 10.0, Steps: 10, Elapsed Time: 45.75 seconds\n",
      "Episode 406, Total Reward: 11.0, Steps: 11, Elapsed Time: 45.89 seconds\n",
      "Episode 407, Total Reward: 8.0, Steps: 8, Elapsed Time: 46.00 seconds\n",
      "Episode 408, Total Reward: 9.0, Steps: 9, Elapsed Time: 46.12 seconds\n",
      "Episode 409, Total Reward: 9.0, Steps: 9, Elapsed Time: 46.23 seconds\n",
      "Episode 410, Total Reward: 9.0, Steps: 9, Elapsed Time: 46.34 seconds\n",
      "Episode 411, Total Reward: 10.0, Steps: 10, Elapsed Time: 46.46 seconds\n",
      "Episode 412, Total Reward: 9.0, Steps: 9, Elapsed Time: 46.58 seconds\n",
      "Episode 413, Total Reward: 8.0, Steps: 8, Elapsed Time: 46.68 seconds\n",
      "Episode 414, Total Reward: 8.0, Steps: 8, Elapsed Time: 46.78 seconds\n",
      "Episode 415, Total Reward: 9.0, Steps: 9, Elapsed Time: 46.89 seconds\n",
      "Episode 416, Total Reward: 9.0, Steps: 9, Elapsed Time: 47.00 seconds\n",
      "Episode 417, Total Reward: 10.0, Steps: 10, Elapsed Time: 47.13 seconds\n",
      "Episode 418, Total Reward: 9.0, Steps: 9, Elapsed Time: 47.26 seconds\n",
      "Episode 419, Total Reward: 10.0, Steps: 10, Elapsed Time: 47.40 seconds\n",
      "Episode 420, Total Reward: 9.0, Steps: 9, Elapsed Time: 47.51 seconds\n",
      "Episode 421, Total Reward: 9.0, Steps: 9, Elapsed Time: 47.65 seconds\n",
      "Episode 422, Total Reward: 9.0, Steps: 9, Elapsed Time: 47.76 seconds\n",
      "Episode 423, Total Reward: 9.0, Steps: 9, Elapsed Time: 47.88 seconds\n",
      "Episode 424, Total Reward: 10.0, Steps: 10, Elapsed Time: 48.01 seconds\n",
      "Episode 425, Total Reward: 9.0, Steps: 9, Elapsed Time: 48.13 seconds\n",
      "Episode 426, Total Reward: 10.0, Steps: 10, Elapsed Time: 48.25 seconds\n",
      "Episode 427, Total Reward: 10.0, Steps: 10, Elapsed Time: 48.39 seconds\n",
      "Episode 428, Total Reward: 10.0, Steps: 10, Elapsed Time: 48.52 seconds\n",
      "Episode 429, Total Reward: 9.0, Steps: 9, Elapsed Time: 48.68 seconds\n",
      "Episode 430, Total Reward: 10.0, Steps: 10, Elapsed Time: 48.88 seconds\n",
      "Episode 431, Total Reward: 8.0, Steps: 8, Elapsed Time: 49.03 seconds\n",
      "Episode 432, Total Reward: 9.0, Steps: 9, Elapsed Time: 49.18 seconds\n",
      "Episode 433, Total Reward: 9.0, Steps: 9, Elapsed Time: 49.32 seconds\n",
      "Episode 434, Total Reward: 9.0, Steps: 9, Elapsed Time: 49.46 seconds\n",
      "Episode 435, Total Reward: 8.0, Steps: 8, Elapsed Time: 49.59 seconds\n",
      "Episode 436, Total Reward: 10.0, Steps: 10, Elapsed Time: 49.73 seconds\n",
      "Episode 437, Total Reward: 9.0, Steps: 9, Elapsed Time: 49.85 seconds\n",
      "Episode 438, Total Reward: 9.0, Steps: 9, Elapsed Time: 49.97 seconds\n",
      "Episode 439, Total Reward: 9.0, Steps: 9, Elapsed Time: 50.09 seconds\n",
      "Episode 440, Total Reward: 11.0, Steps: 11, Elapsed Time: 50.25 seconds\n",
      "Episode 441, Total Reward: 9.0, Steps: 9, Elapsed Time: 50.39 seconds\n",
      "Episode 442, Total Reward: 10.0, Steps: 10, Elapsed Time: 50.52 seconds\n",
      "Episode 443, Total Reward: 10.0, Steps: 10, Elapsed Time: 50.65 seconds\n",
      "Episode 444, Total Reward: 10.0, Steps: 10, Elapsed Time: 50.77 seconds\n",
      "Episode 445, Total Reward: 9.0, Steps: 9, Elapsed Time: 50.88 seconds\n",
      "Episode 446, Total Reward: 10.0, Steps: 10, Elapsed Time: 51.01 seconds\n",
      "Episode 447, Total Reward: 9.0, Steps: 9, Elapsed Time: 51.12 seconds\n",
      "Episode 448, Total Reward: 9.0, Steps: 9, Elapsed Time: 51.23 seconds\n",
      "Episode 449, Total Reward: 10.0, Steps: 10, Elapsed Time: 51.36 seconds\n",
      "Episode 450, Total Reward: 9.0, Steps: 9, Elapsed Time: 51.47 seconds\n",
      "Episode 451, Total Reward: 10.0, Steps: 10, Elapsed Time: 51.59 seconds\n",
      "Episode 452, Total Reward: 9.0, Steps: 9, Elapsed Time: 51.70 seconds\n",
      "Episode 453, Total Reward: 10.0, Steps: 10, Elapsed Time: 51.83 seconds\n",
      "Episode 454, Total Reward: 9.0, Steps: 9, Elapsed Time: 51.95 seconds\n",
      "Episode 455, Total Reward: 9.0, Steps: 9, Elapsed Time: 52.06 seconds\n",
      "Episode 456, Total Reward: 8.0, Steps: 8, Elapsed Time: 52.16 seconds\n",
      "Episode 457, Total Reward: 8.0, Steps: 8, Elapsed Time: 52.26 seconds\n",
      "Episode 458, Total Reward: 10.0, Steps: 10, Elapsed Time: 52.39 seconds\n",
      "Episode 459, Total Reward: 9.0, Steps: 9, Elapsed Time: 52.50 seconds\n",
      "Episode 460, Total Reward: 9.0, Steps: 9, Elapsed Time: 52.62 seconds\n",
      "Episode 461, Total Reward: 8.0, Steps: 8, Elapsed Time: 52.72 seconds\n",
      "Episode 462, Total Reward: 10.0, Steps: 10, Elapsed Time: 52.85 seconds\n",
      "Episode 463, Total Reward: 10.0, Steps: 10, Elapsed Time: 52.99 seconds\n",
      "Episode 464, Total Reward: 10.0, Steps: 10, Elapsed Time: 53.14 seconds\n",
      "Episode 465, Total Reward: 9.0, Steps: 9, Elapsed Time: 53.27 seconds\n",
      "Episode 466, Total Reward: 9.0, Steps: 9, Elapsed Time: 53.42 seconds\n",
      "Episode 467, Total Reward: 9.0, Steps: 9, Elapsed Time: 53.55 seconds\n",
      "Episode 468, Total Reward: 9.0, Steps: 9, Elapsed Time: 53.67 seconds\n",
      "Episode 469, Total Reward: 9.0, Steps: 9, Elapsed Time: 53.79 seconds\n",
      "Episode 470, Total Reward: 10.0, Steps: 10, Elapsed Time: 53.93 seconds\n",
      "Episode 471, Total Reward: 9.0, Steps: 9, Elapsed Time: 54.06 seconds\n",
      "Episode 472, Total Reward: 10.0, Steps: 10, Elapsed Time: 54.20 seconds\n",
      "Episode 473, Total Reward: 9.0, Steps: 9, Elapsed Time: 54.31 seconds\n",
      "Episode 474, Total Reward: 10.0, Steps: 10, Elapsed Time: 54.46 seconds\n",
      "Episode 475, Total Reward: 10.0, Steps: 10, Elapsed Time: 54.60 seconds\n",
      "Episode 476, Total Reward: 9.0, Steps: 9, Elapsed Time: 54.71 seconds\n",
      "Episode 477, Total Reward: 10.0, Steps: 10, Elapsed Time: 54.83 seconds\n",
      "Episode 478, Total Reward: 10.0, Steps: 10, Elapsed Time: 54.97 seconds\n",
      "Episode 479, Total Reward: 8.0, Steps: 8, Elapsed Time: 55.07 seconds\n",
      "Episode 480, Total Reward: 9.0, Steps: 9, Elapsed Time: 55.17 seconds\n",
      "Episode 481, Total Reward: 9.0, Steps: 9, Elapsed Time: 55.28 seconds\n",
      "Episode 482, Total Reward: 10.0, Steps: 10, Elapsed Time: 55.40 seconds\n",
      "Episode 483, Total Reward: 9.0, Steps: 9, Elapsed Time: 55.51 seconds\n",
      "Episode 484, Total Reward: 8.0, Steps: 8, Elapsed Time: 55.61 seconds\n",
      "Episode 485, Total Reward: 10.0, Steps: 10, Elapsed Time: 55.75 seconds\n",
      "Episode 486, Total Reward: 11.0, Steps: 11, Elapsed Time: 55.89 seconds\n",
      "Episode 487, Total Reward: 9.0, Steps: 9, Elapsed Time: 56.00 seconds\n",
      "Episode 488, Total Reward: 8.0, Steps: 8, Elapsed Time: 56.10 seconds\n",
      "Episode 489, Total Reward: 9.0, Steps: 9, Elapsed Time: 56.20 seconds\n",
      "Episode 490, Total Reward: 10.0, Steps: 10, Elapsed Time: 56.32 seconds\n",
      "Episode 491, Total Reward: 9.0, Steps: 9, Elapsed Time: 56.43 seconds\n",
      "Episode 492, Total Reward: 9.0, Steps: 9, Elapsed Time: 56.54 seconds\n",
      "Episode 493, Total Reward: 9.0, Steps: 9, Elapsed Time: 56.65 seconds\n",
      "Episode 494, Total Reward: 9.0, Steps: 9, Elapsed Time: 56.75 seconds\n",
      "Episode 495, Total Reward: 9.0, Steps: 9, Elapsed Time: 56.86 seconds\n",
      "Episode 496, Total Reward: 10.0, Steps: 10, Elapsed Time: 56.98 seconds\n",
      "Episode 497, Total Reward: 10.0, Steps: 10, Elapsed Time: 57.12 seconds\n",
      "Episode 498, Total Reward: 9.0, Steps: 9, Elapsed Time: 57.23 seconds\n",
      "Episode 499, Total Reward: 9.0, Steps: 9, Elapsed Time: 57.34 seconds\n",
      "Episode 500, Total Reward: 9.0, Steps: 9, Elapsed Time: 57.46 seconds\n",
      "Episode 501, Total Reward: 10.0, Steps: 10, Elapsed Time: 57.58 seconds\n",
      "Episode 502, Total Reward: 9.0, Steps: 9, Elapsed Time: 57.70 seconds\n",
      "Episode 503, Total Reward: 10.0, Steps: 10, Elapsed Time: 57.83 seconds\n",
      "Episode 504, Total Reward: 9.0, Steps: 9, Elapsed Time: 57.96 seconds\n",
      "Episode 505, Total Reward: 9.0, Steps: 9, Elapsed Time: 58.07 seconds\n",
      "Episode 506, Total Reward: 10.0, Steps: 10, Elapsed Time: 58.19 seconds\n",
      "Episode 507, Total Reward: 10.0, Steps: 10, Elapsed Time: 58.31 seconds\n",
      "Episode 508, Total Reward: 10.0, Steps: 10, Elapsed Time: 58.44 seconds\n",
      "Episode 509, Total Reward: 10.0, Steps: 10, Elapsed Time: 58.57 seconds\n",
      "Episode 510, Total Reward: 9.0, Steps: 9, Elapsed Time: 58.68 seconds\n",
      "Episode 511, Total Reward: 9.0, Steps: 9, Elapsed Time: 58.79 seconds\n",
      "Episode 512, Total Reward: 9.0, Steps: 9, Elapsed Time: 58.90 seconds\n",
      "Episode 513, Total Reward: 9.0, Steps: 9, Elapsed Time: 59.01 seconds\n",
      "Episode 514, Total Reward: 10.0, Steps: 10, Elapsed Time: 59.15 seconds\n",
      "Episode 515, Total Reward: 9.0, Steps: 9, Elapsed Time: 59.26 seconds\n",
      "Episode 516, Total Reward: 10.0, Steps: 10, Elapsed Time: 59.39 seconds\n",
      "Episode 517, Total Reward: 11.0, Steps: 11, Elapsed Time: 59.52 seconds\n",
      "Episode 518, Total Reward: 8.0, Steps: 8, Elapsed Time: 59.62 seconds\n",
      "Episode 519, Total Reward: 9.0, Steps: 9, Elapsed Time: 59.72 seconds\n",
      "Episode 520, Total Reward: 8.0, Steps: 8, Elapsed Time: 59.83 seconds\n",
      "Episode 521, Total Reward: 9.0, Steps: 9, Elapsed Time: 59.94 seconds\n",
      "Episode 522, Total Reward: 9.0, Steps: 9, Elapsed Time: 60.06 seconds\n",
      "Episode 523, Total Reward: 8.0, Steps: 8, Elapsed Time: 60.16 seconds\n",
      "Episode 524, Total Reward: 9.0, Steps: 9, Elapsed Time: 60.28 seconds\n",
      "Episode 525, Total Reward: 10.0, Steps: 10, Elapsed Time: 60.41 seconds\n",
      "Episode 526, Total Reward: 8.0, Steps: 8, Elapsed Time: 60.52 seconds\n",
      "Episode 527, Total Reward: 10.0, Steps: 10, Elapsed Time: 60.64 seconds\n",
      "Episode 528, Total Reward: 8.0, Steps: 8, Elapsed Time: 60.75 seconds\n",
      "Episode 529, Total Reward: 10.0, Steps: 10, Elapsed Time: 60.88 seconds\n",
      "Episode 530, Total Reward: 9.0, Steps: 9, Elapsed Time: 60.99 seconds\n",
      "Episode 531, Total Reward: 10.0, Steps: 10, Elapsed Time: 61.11 seconds\n",
      "Episode 532, Total Reward: 9.0, Steps: 9, Elapsed Time: 61.23 seconds\n",
      "Episode 533, Total Reward: 9.0, Steps: 9, Elapsed Time: 61.34 seconds\n",
      "Episode 534, Total Reward: 10.0, Steps: 10, Elapsed Time: 61.47 seconds\n",
      "Episode 535, Total Reward: 9.0, Steps: 9, Elapsed Time: 61.60 seconds\n",
      "Episode 536, Total Reward: 9.0, Steps: 9, Elapsed Time: 61.71 seconds\n",
      "Episode 537, Total Reward: 8.0, Steps: 8, Elapsed Time: 61.81 seconds\n",
      "Episode 538, Total Reward: 9.0, Steps: 9, Elapsed Time: 61.92 seconds\n",
      "Episode 539, Total Reward: 10.0, Steps: 10, Elapsed Time: 62.05 seconds\n",
      "Episode 540, Total Reward: 10.0, Steps: 10, Elapsed Time: 62.18 seconds\n",
      "Episode 541, Total Reward: 11.0, Steps: 11, Elapsed Time: 62.32 seconds\n",
      "Episode 542, Total Reward: 9.0, Steps: 9, Elapsed Time: 62.45 seconds\n",
      "Episode 543, Total Reward: 9.0, Steps: 9, Elapsed Time: 62.56 seconds\n",
      "Episode 544, Total Reward: 9.0, Steps: 9, Elapsed Time: 62.68 seconds\n",
      "Episode 545, Total Reward: 9.0, Steps: 9, Elapsed Time: 62.79 seconds\n",
      "Episode 546, Total Reward: 9.0, Steps: 9, Elapsed Time: 62.90 seconds\n",
      "Episode 547, Total Reward: 9.0, Steps: 9, Elapsed Time: 63.01 seconds\n",
      "Episode 548, Total Reward: 10.0, Steps: 10, Elapsed Time: 63.13 seconds\n",
      "Episode 549, Total Reward: 10.0, Steps: 10, Elapsed Time: 63.25 seconds\n",
      "Episode 550, Total Reward: 9.0, Steps: 9, Elapsed Time: 63.35 seconds\n",
      "Episode 551, Total Reward: 9.0, Steps: 9, Elapsed Time: 63.46 seconds\n",
      "Episode 552, Total Reward: 10.0, Steps: 10, Elapsed Time: 63.59 seconds\n",
      "Episode 553, Total Reward: 10.0, Steps: 10, Elapsed Time: 63.71 seconds\n",
      "Episode 554, Total Reward: 9.0, Steps: 9, Elapsed Time: 63.82 seconds\n",
      "Episode 555, Total Reward: 9.0, Steps: 9, Elapsed Time: 63.92 seconds\n",
      "Episode 556, Total Reward: 10.0, Steps: 10, Elapsed Time: 64.05 seconds\n",
      "Episode 557, Total Reward: 9.0, Steps: 9, Elapsed Time: 64.16 seconds\n",
      "Episode 558, Total Reward: 9.0, Steps: 9, Elapsed Time: 64.27 seconds\n",
      "Episode 559, Total Reward: 9.0, Steps: 9, Elapsed Time: 64.38 seconds\n",
      "Episode 560, Total Reward: 9.0, Steps: 9, Elapsed Time: 64.50 seconds\n",
      "Episode 561, Total Reward: 9.0, Steps: 9, Elapsed Time: 64.60 seconds\n",
      "Episode 562, Total Reward: 10.0, Steps: 10, Elapsed Time: 64.72 seconds\n",
      "Episode 563, Total Reward: 9.0, Steps: 9, Elapsed Time: 64.82 seconds\n",
      "Episode 564, Total Reward: 9.0, Steps: 9, Elapsed Time: 64.93 seconds\n",
      "Episode 565, Total Reward: 9.0, Steps: 9, Elapsed Time: 65.05 seconds\n",
      "Episode 566, Total Reward: 8.0, Steps: 8, Elapsed Time: 65.14 seconds\n",
      "Episode 567, Total Reward: 10.0, Steps: 10, Elapsed Time: 65.26 seconds\n",
      "Episode 568, Total Reward: 10.0, Steps: 10, Elapsed Time: 65.38 seconds\n",
      "Episode 569, Total Reward: 9.0, Steps: 9, Elapsed Time: 65.48 seconds\n",
      "Episode 570, Total Reward: 10.0, Steps: 10, Elapsed Time: 65.60 seconds\n",
      "Episode 571, Total Reward: 9.0, Steps: 9, Elapsed Time: 65.72 seconds\n",
      "Episode 572, Total Reward: 10.0, Steps: 10, Elapsed Time: 65.84 seconds\n",
      "Episode 573, Total Reward: 9.0, Steps: 9, Elapsed Time: 65.95 seconds\n",
      "Episode 574, Total Reward: 10.0, Steps: 10, Elapsed Time: 66.07 seconds\n",
      "Episode 575, Total Reward: 8.0, Steps: 8, Elapsed Time: 66.17 seconds\n",
      "Episode 576, Total Reward: 10.0, Steps: 10, Elapsed Time: 66.29 seconds\n",
      "Episode 577, Total Reward: 9.0, Steps: 9, Elapsed Time: 66.39 seconds\n",
      "Episode 578, Total Reward: 9.0, Steps: 9, Elapsed Time: 66.50 seconds\n",
      "Episode 579, Total Reward: 10.0, Steps: 10, Elapsed Time: 66.63 seconds\n",
      "Episode 580, Total Reward: 10.0, Steps: 10, Elapsed Time: 66.74 seconds\n",
      "Episode 581, Total Reward: 10.0, Steps: 10, Elapsed Time: 66.86 seconds\n",
      "Episode 582, Total Reward: 9.0, Steps: 9, Elapsed Time: 66.97 seconds\n",
      "Episode 583, Total Reward: 9.0, Steps: 9, Elapsed Time: 67.08 seconds\n",
      "Episode 584, Total Reward: 10.0, Steps: 10, Elapsed Time: 67.19 seconds\n",
      "Episode 585, Total Reward: 10.0, Steps: 10, Elapsed Time: 67.31 seconds\n",
      "Episode 586, Total Reward: 10.0, Steps: 10, Elapsed Time: 67.43 seconds\n",
      "Episode 587, Total Reward: 8.0, Steps: 8, Elapsed Time: 67.52 seconds\n",
      "Episode 588, Total Reward: 8.0, Steps: 8, Elapsed Time: 67.61 seconds\n",
      "Episode 589, Total Reward: 9.0, Steps: 9, Elapsed Time: 67.72 seconds\n",
      "Episode 590, Total Reward: 10.0, Steps: 10, Elapsed Time: 67.84 seconds\n",
      "Episode 591, Total Reward: 9.0, Steps: 9, Elapsed Time: 67.95 seconds\n",
      "Episode 592, Total Reward: 10.0, Steps: 10, Elapsed Time: 68.08 seconds\n",
      "Episode 593, Total Reward: 9.0, Steps: 9, Elapsed Time: 68.19 seconds\n",
      "Episode 594, Total Reward: 10.0, Steps: 10, Elapsed Time: 68.31 seconds\n",
      "Episode 595, Total Reward: 8.0, Steps: 8, Elapsed Time: 68.40 seconds\n",
      "Episode 596, Total Reward: 9.0, Steps: 9, Elapsed Time: 68.52 seconds\n",
      "Episode 597, Total Reward: 9.0, Steps: 9, Elapsed Time: 68.62 seconds\n",
      "Episode 598, Total Reward: 9.0, Steps: 9, Elapsed Time: 68.73 seconds\n",
      "Episode 599, Total Reward: 10.0, Steps: 10, Elapsed Time: 68.86 seconds\n",
      "Episode 600, Total Reward: 9.0, Steps: 9, Elapsed Time: 68.97 seconds\n",
      "Episode 601, Total Reward: 10.0, Steps: 10, Elapsed Time: 69.10 seconds\n",
      "Episode 602, Total Reward: 10.0, Steps: 10, Elapsed Time: 69.22 seconds\n",
      "Episode 603, Total Reward: 10.0, Steps: 10, Elapsed Time: 69.34 seconds\n",
      "Episode 604, Total Reward: 9.0, Steps: 9, Elapsed Time: 69.44 seconds\n",
      "Episode 605, Total Reward: 9.0, Steps: 9, Elapsed Time: 69.55 seconds\n",
      "Episode 606, Total Reward: 10.0, Steps: 10, Elapsed Time: 69.67 seconds\n",
      "Episode 607, Total Reward: 9.0, Steps: 9, Elapsed Time: 69.77 seconds\n",
      "Episode 608, Total Reward: 10.0, Steps: 10, Elapsed Time: 69.89 seconds\n",
      "Episode 609, Total Reward: 10.0, Steps: 10, Elapsed Time: 70.01 seconds\n",
      "Episode 610, Total Reward: 8.0, Steps: 8, Elapsed Time: 70.11 seconds\n",
      "Episode 611, Total Reward: 8.0, Steps: 8, Elapsed Time: 70.20 seconds\n",
      "Episode 612, Total Reward: 9.0, Steps: 9, Elapsed Time: 70.32 seconds\n",
      "Episode 613, Total Reward: 10.0, Steps: 10, Elapsed Time: 70.45 seconds\n",
      "Episode 614, Total Reward: 10.0, Steps: 10, Elapsed Time: 70.57 seconds\n",
      "Episode 615, Total Reward: 8.0, Steps: 8, Elapsed Time: 70.66 seconds\n",
      "Episode 616, Total Reward: 9.0, Steps: 9, Elapsed Time: 70.77 seconds\n",
      "Episode 617, Total Reward: 9.0, Steps: 9, Elapsed Time: 70.87 seconds\n",
      "Episode 618, Total Reward: 10.0, Steps: 10, Elapsed Time: 71.00 seconds\n",
      "Episode 619, Total Reward: 10.0, Steps: 10, Elapsed Time: 71.12 seconds\n",
      "Episode 620, Total Reward: 10.0, Steps: 10, Elapsed Time: 71.24 seconds\n",
      "Episode 621, Total Reward: 9.0, Steps: 9, Elapsed Time: 71.34 seconds\n",
      "Episode 622, Total Reward: 10.0, Steps: 10, Elapsed Time: 71.46 seconds\n",
      "Episode 623, Total Reward: 10.0, Steps: 10, Elapsed Time: 71.58 seconds\n",
      "Episode 624, Total Reward: 9.0, Steps: 9, Elapsed Time: 71.69 seconds\n",
      "Episode 625, Total Reward: 9.0, Steps: 9, Elapsed Time: 71.80 seconds\n",
      "Episode 626, Total Reward: 9.0, Steps: 9, Elapsed Time: 71.91 seconds\n",
      "Episode 627, Total Reward: 9.0, Steps: 9, Elapsed Time: 72.03 seconds\n",
      "Episode 628, Total Reward: 9.0, Steps: 9, Elapsed Time: 72.15 seconds\n",
      "Episode 629, Total Reward: 9.0, Steps: 9, Elapsed Time: 72.27 seconds\n",
      "Episode 630, Total Reward: 9.0, Steps: 9, Elapsed Time: 72.38 seconds\n",
      "Episode 631, Total Reward: 9.0, Steps: 9, Elapsed Time: 72.50 seconds\n",
      "Episode 632, Total Reward: 10.0, Steps: 10, Elapsed Time: 72.63 seconds\n",
      "Episode 633, Total Reward: 9.0, Steps: 9, Elapsed Time: 72.74 seconds\n",
      "Episode 634, Total Reward: 10.0, Steps: 10, Elapsed Time: 72.86 seconds\n",
      "Episode 635, Total Reward: 8.0, Steps: 8, Elapsed Time: 72.95 seconds\n",
      "Episode 636, Total Reward: 10.0, Steps: 10, Elapsed Time: 73.07 seconds\n",
      "Episode 637, Total Reward: 10.0, Steps: 10, Elapsed Time: 73.19 seconds\n",
      "Episode 638, Total Reward: 10.0, Steps: 10, Elapsed Time: 73.31 seconds\n",
      "Episode 639, Total Reward: 11.0, Steps: 11, Elapsed Time: 73.45 seconds\n",
      "Episode 640, Total Reward: 9.0, Steps: 9, Elapsed Time: 73.56 seconds\n",
      "Episode 641, Total Reward: 10.0, Steps: 10, Elapsed Time: 73.69 seconds\n",
      "Episode 642, Total Reward: 10.0, Steps: 10, Elapsed Time: 73.81 seconds\n",
      "Episode 643, Total Reward: 10.0, Steps: 10, Elapsed Time: 73.93 seconds\n",
      "Episode 644, Total Reward: 8.0, Steps: 8, Elapsed Time: 74.03 seconds\n",
      "Episode 645, Total Reward: 8.0, Steps: 8, Elapsed Time: 74.13 seconds\n",
      "Episode 646, Total Reward: 10.0, Steps: 10, Elapsed Time: 74.25 seconds\n",
      "Episode 647, Total Reward: 9.0, Steps: 9, Elapsed Time: 74.35 seconds\n",
      "Episode 648, Total Reward: 9.0, Steps: 9, Elapsed Time: 74.46 seconds\n",
      "Episode 649, Total Reward: 10.0, Steps: 10, Elapsed Time: 74.59 seconds\n",
      "Episode 650, Total Reward: 8.0, Steps: 8, Elapsed Time: 74.68 seconds\n",
      "Episode 651, Total Reward: 9.0, Steps: 9, Elapsed Time: 74.79 seconds\n",
      "Episode 652, Total Reward: 10.0, Steps: 10, Elapsed Time: 74.92 seconds\n",
      "Episode 653, Total Reward: 9.0, Steps: 9, Elapsed Time: 75.03 seconds\n",
      "Episode 654, Total Reward: 11.0, Steps: 11, Elapsed Time: 75.17 seconds\n",
      "Episode 655, Total Reward: 9.0, Steps: 9, Elapsed Time: 75.28 seconds\n",
      "Episode 656, Total Reward: 11.0, Steps: 11, Elapsed Time: 75.41 seconds\n",
      "Episode 657, Total Reward: 11.0, Steps: 11, Elapsed Time: 75.56 seconds\n",
      "Episode 658, Total Reward: 9.0, Steps: 9, Elapsed Time: 75.67 seconds\n",
      "Episode 659, Total Reward: 9.0, Steps: 9, Elapsed Time: 75.79 seconds\n",
      "Episode 660, Total Reward: 10.0, Steps: 10, Elapsed Time: 75.91 seconds\n",
      "Episode 661, Total Reward: 10.0, Steps: 10, Elapsed Time: 76.03 seconds\n",
      "Episode 662, Total Reward: 10.0, Steps: 10, Elapsed Time: 76.16 seconds\n",
      "Episode 663, Total Reward: 9.0, Steps: 9, Elapsed Time: 76.27 seconds\n",
      "Episode 664, Total Reward: 9.0, Steps: 9, Elapsed Time: 76.37 seconds\n",
      "Episode 665, Total Reward: 8.0, Steps: 8, Elapsed Time: 76.47 seconds\n",
      "Episode 666, Total Reward: 9.0, Steps: 9, Elapsed Time: 76.58 seconds\n",
      "Episode 667, Total Reward: 9.0, Steps: 9, Elapsed Time: 76.68 seconds\n",
      "Episode 668, Total Reward: 10.0, Steps: 10, Elapsed Time: 76.80 seconds\n",
      "Episode 669, Total Reward: 8.0, Steps: 8, Elapsed Time: 76.90 seconds\n",
      "Episode 670, Total Reward: 10.0, Steps: 10, Elapsed Time: 77.03 seconds\n",
      "Episode 671, Total Reward: 9.0, Steps: 9, Elapsed Time: 77.16 seconds\n",
      "Episode 672, Total Reward: 9.0, Steps: 9, Elapsed Time: 77.28 seconds\n",
      "Episode 673, Total Reward: 10.0, Steps: 10, Elapsed Time: 77.40 seconds\n",
      "Episode 674, Total Reward: 9.0, Steps: 9, Elapsed Time: 77.51 seconds\n",
      "Episode 675, Total Reward: 8.0, Steps: 8, Elapsed Time: 77.61 seconds\n",
      "Episode 676, Total Reward: 9.0, Steps: 9, Elapsed Time: 77.71 seconds\n",
      "Episode 677, Total Reward: 9.0, Steps: 9, Elapsed Time: 77.82 seconds\n",
      "Episode 678, Total Reward: 9.0, Steps: 9, Elapsed Time: 77.92 seconds\n",
      "Episode 679, Total Reward: 9.0, Steps: 9, Elapsed Time: 78.02 seconds\n",
      "Episode 680, Total Reward: 10.0, Steps: 10, Elapsed Time: 78.14 seconds\n",
      "Episode 681, Total Reward: 9.0, Steps: 9, Elapsed Time: 78.24 seconds\n",
      "Episode 682, Total Reward: 10.0, Steps: 10, Elapsed Time: 78.36 seconds\n",
      "Episode 683, Total Reward: 10.0, Steps: 10, Elapsed Time: 78.48 seconds\n",
      "Episode 684, Total Reward: 9.0, Steps: 9, Elapsed Time: 78.58 seconds\n",
      "Episode 685, Total Reward: 8.0, Steps: 8, Elapsed Time: 78.67 seconds\n",
      "Episode 686, Total Reward: 9.0, Steps: 9, Elapsed Time: 78.78 seconds\n",
      "Episode 687, Total Reward: 9.0, Steps: 9, Elapsed Time: 78.89 seconds\n",
      "Episode 688, Total Reward: 10.0, Steps: 10, Elapsed Time: 79.02 seconds\n",
      "Episode 689, Total Reward: 10.0, Steps: 10, Elapsed Time: 79.14 seconds\n",
      "Episode 690, Total Reward: 8.0, Steps: 8, Elapsed Time: 79.24 seconds\n",
      "Episode 691, Total Reward: 10.0, Steps: 10, Elapsed Time: 79.36 seconds\n",
      "Episode 692, Total Reward: 9.0, Steps: 9, Elapsed Time: 79.46 seconds\n",
      "Episode 693, Total Reward: 10.0, Steps: 10, Elapsed Time: 79.58 seconds\n",
      "Episode 694, Total Reward: 10.0, Steps: 10, Elapsed Time: 79.70 seconds\n",
      "Episode 695, Total Reward: 9.0, Steps: 9, Elapsed Time: 79.81 seconds\n",
      "Episode 696, Total Reward: 9.0, Steps: 9, Elapsed Time: 79.92 seconds\n",
      "Episode 697, Total Reward: 9.0, Steps: 9, Elapsed Time: 80.03 seconds\n",
      "Episode 698, Total Reward: 9.0, Steps: 9, Elapsed Time: 80.13 seconds\n",
      "Episode 699, Total Reward: 10.0, Steps: 10, Elapsed Time: 80.26 seconds\n",
      "Episode 700, Total Reward: 9.0, Steps: 9, Elapsed Time: 80.37 seconds\n",
      "Episode 701, Total Reward: 9.0, Steps: 9, Elapsed Time: 80.47 seconds\n",
      "Episode 702, Total Reward: 10.0, Steps: 10, Elapsed Time: 80.59 seconds\n",
      "Episode 703, Total Reward: 9.0, Steps: 9, Elapsed Time: 80.70 seconds\n",
      "Episode 704, Total Reward: 8.0, Steps: 8, Elapsed Time: 80.79 seconds\n",
      "Episode 705, Total Reward: 8.0, Steps: 8, Elapsed Time: 80.89 seconds\n",
      "Episode 706, Total Reward: 10.0, Steps: 10, Elapsed Time: 81.00 seconds\n",
      "Episode 707, Total Reward: 9.0, Steps: 9, Elapsed Time: 81.11 seconds\n",
      "Episode 708, Total Reward: 11.0, Steps: 11, Elapsed Time: 81.24 seconds\n",
      "Episode 709, Total Reward: 10.0, Steps: 10, Elapsed Time: 81.36 seconds\n",
      "Episode 710, Total Reward: 9.0, Steps: 9, Elapsed Time: 81.47 seconds\n",
      "Episode 711, Total Reward: 10.0, Steps: 10, Elapsed Time: 81.59 seconds\n",
      "Episode 712, Total Reward: 10.0, Steps: 10, Elapsed Time: 81.70 seconds\n",
      "Episode 713, Total Reward: 9.0, Steps: 9, Elapsed Time: 81.81 seconds\n",
      "Episode 714, Total Reward: 10.0, Steps: 10, Elapsed Time: 81.93 seconds\n",
      "Episode 715, Total Reward: 10.0, Steps: 10, Elapsed Time: 82.05 seconds\n",
      "Episode 716, Total Reward: 9.0, Steps: 9, Elapsed Time: 82.16 seconds\n",
      "Episode 717, Total Reward: 10.0, Steps: 10, Elapsed Time: 82.29 seconds\n",
      "Episode 718, Total Reward: 9.0, Steps: 9, Elapsed Time: 82.40 seconds\n",
      "Episode 719, Total Reward: 9.0, Steps: 9, Elapsed Time: 82.51 seconds\n",
      "Episode 720, Total Reward: 9.0, Steps: 9, Elapsed Time: 82.61 seconds\n",
      "Episode 721, Total Reward: 10.0, Steps: 10, Elapsed Time: 82.73 seconds\n",
      "Episode 722, Total Reward: 10.0, Steps: 10, Elapsed Time: 82.85 seconds\n",
      "Episode 723, Total Reward: 10.0, Steps: 10, Elapsed Time: 82.99 seconds\n",
      "Episode 724, Total Reward: 10.0, Steps: 10, Elapsed Time: 83.11 seconds\n",
      "Episode 725, Total Reward: 10.0, Steps: 10, Elapsed Time: 83.24 seconds\n",
      "Episode 726, Total Reward: 10.0, Steps: 10, Elapsed Time: 83.38 seconds\n",
      "Episode 727, Total Reward: 10.0, Steps: 10, Elapsed Time: 83.52 seconds\n",
      "Episode 728, Total Reward: 9.0, Steps: 9, Elapsed Time: 83.63 seconds\n",
      "Episode 729, Total Reward: 8.0, Steps: 8, Elapsed Time: 83.74 seconds\n",
      "Episode 730, Total Reward: 10.0, Steps: 10, Elapsed Time: 83.86 seconds\n",
      "Episode 731, Total Reward: 10.0, Steps: 10, Elapsed Time: 83.98 seconds\n",
      "Episode 732, Total Reward: 10.0, Steps: 10, Elapsed Time: 84.11 seconds\n",
      "Episode 733, Total Reward: 10.0, Steps: 10, Elapsed Time: 84.23 seconds\n",
      "Episode 734, Total Reward: 10.0, Steps: 10, Elapsed Time: 84.35 seconds\n",
      "Episode 735, Total Reward: 9.0, Steps: 9, Elapsed Time: 84.46 seconds\n",
      "Episode 736, Total Reward: 10.0, Steps: 10, Elapsed Time: 84.59 seconds\n",
      "Episode 737, Total Reward: 11.0, Steps: 11, Elapsed Time: 84.72 seconds\n",
      "Episode 738, Total Reward: 10.0, Steps: 10, Elapsed Time: 84.84 seconds\n",
      "Episode 739, Total Reward: 9.0, Steps: 9, Elapsed Time: 84.95 seconds\n",
      "Episode 740, Total Reward: 10.0, Steps: 10, Elapsed Time: 85.07 seconds\n",
      "Episode 741, Total Reward: 10.0, Steps: 10, Elapsed Time: 85.19 seconds\n",
      "Episode 742, Total Reward: 10.0, Steps: 10, Elapsed Time: 85.32 seconds\n",
      "Episode 743, Total Reward: 10.0, Steps: 10, Elapsed Time: 85.44 seconds\n",
      "Episode 744, Total Reward: 10.0, Steps: 10, Elapsed Time: 85.57 seconds\n",
      "Episode 745, Total Reward: 10.0, Steps: 10, Elapsed Time: 85.70 seconds\n",
      "Episode 746, Total Reward: 11.0, Steps: 11, Elapsed Time: 85.83 seconds\n",
      "Episode 747, Total Reward: 10.0, Steps: 10, Elapsed Time: 85.96 seconds\n",
      "Episode 748, Total Reward: 9.0, Steps: 9, Elapsed Time: 86.07 seconds\n",
      "Episode 749, Total Reward: 9.0, Steps: 9, Elapsed Time: 86.18 seconds\n",
      "Episode 750, Total Reward: 10.0, Steps: 10, Elapsed Time: 86.30 seconds\n",
      "Episode 751, Total Reward: 9.0, Steps: 9, Elapsed Time: 86.41 seconds\n",
      "Episode 752, Total Reward: 8.0, Steps: 8, Elapsed Time: 86.50 seconds\n",
      "Episode 753, Total Reward: 10.0, Steps: 10, Elapsed Time: 86.62 seconds\n",
      "Episode 754, Total Reward: 9.0, Steps: 9, Elapsed Time: 86.73 seconds\n",
      "Episode 755, Total Reward: 8.0, Steps: 8, Elapsed Time: 86.82 seconds\n",
      "Episode 756, Total Reward: 10.0, Steps: 10, Elapsed Time: 86.95 seconds\n",
      "Episode 757, Total Reward: 9.0, Steps: 9, Elapsed Time: 87.06 seconds\n",
      "Episode 758, Total Reward: 9.0, Steps: 9, Elapsed Time: 87.16 seconds\n",
      "Episode 759, Total Reward: 11.0, Steps: 11, Elapsed Time: 87.30 seconds\n",
      "Episode 760, Total Reward: 10.0, Steps: 10, Elapsed Time: 87.41 seconds\n",
      "Episode 761, Total Reward: 9.0, Steps: 9, Elapsed Time: 87.52 seconds\n",
      "Episode 762, Total Reward: 9.0, Steps: 9, Elapsed Time: 87.63 seconds\n",
      "Episode 763, Total Reward: 9.0, Steps: 9, Elapsed Time: 87.74 seconds\n",
      "Episode 764, Total Reward: 10.0, Steps: 10, Elapsed Time: 87.86 seconds\n",
      "Episode 765, Total Reward: 10.0, Steps: 10, Elapsed Time: 87.98 seconds\n",
      "Episode 766, Total Reward: 9.0, Steps: 9, Elapsed Time: 88.09 seconds\n",
      "Episode 767, Total Reward: 8.0, Steps: 8, Elapsed Time: 88.19 seconds\n",
      "Episode 768, Total Reward: 10.0, Steps: 10, Elapsed Time: 88.32 seconds\n",
      "Episode 769, Total Reward: 8.0, Steps: 8, Elapsed Time: 88.42 seconds\n",
      "Episode 770, Total Reward: 9.0, Steps: 9, Elapsed Time: 88.53 seconds\n",
      "Episode 771, Total Reward: 10.0, Steps: 10, Elapsed Time: 88.66 seconds\n",
      "Episode 772, Total Reward: 10.0, Steps: 10, Elapsed Time: 88.79 seconds\n",
      "Episode 773, Total Reward: 8.0, Steps: 8, Elapsed Time: 88.89 seconds\n",
      "Episode 774, Total Reward: 8.0, Steps: 8, Elapsed Time: 89.01 seconds\n",
      "Episode 775, Total Reward: 8.0, Steps: 8, Elapsed Time: 89.12 seconds\n",
      "Episode 776, Total Reward: 10.0, Steps: 10, Elapsed Time: 89.25 seconds\n",
      "Episode 777, Total Reward: 9.0, Steps: 9, Elapsed Time: 89.37 seconds\n",
      "Episode 778, Total Reward: 9.0, Steps: 9, Elapsed Time: 89.49 seconds\n",
      "Episode 779, Total Reward: 9.0, Steps: 9, Elapsed Time: 89.61 seconds\n",
      "Episode 780, Total Reward: 9.0, Steps: 9, Elapsed Time: 89.72 seconds\n",
      "Episode 781, Total Reward: 9.0, Steps: 9, Elapsed Time: 89.83 seconds\n",
      "Episode 782, Total Reward: 9.0, Steps: 9, Elapsed Time: 89.94 seconds\n",
      "Episode 783, Total Reward: 10.0, Steps: 10, Elapsed Time: 90.08 seconds\n",
      "Episode 784, Total Reward: 10.0, Steps: 10, Elapsed Time: 90.20 seconds\n",
      "Episode 785, Total Reward: 9.0, Steps: 9, Elapsed Time: 90.33 seconds\n",
      "Episode 786, Total Reward: 8.0, Steps: 8, Elapsed Time: 90.43 seconds\n",
      "Episode 787, Total Reward: 9.0, Steps: 9, Elapsed Time: 90.55 seconds\n",
      "Episode 788, Total Reward: 9.0, Steps: 9, Elapsed Time: 90.67 seconds\n",
      "Episode 789, Total Reward: 9.0, Steps: 9, Elapsed Time: 90.78 seconds\n",
      "Episode 790, Total Reward: 10.0, Steps: 10, Elapsed Time: 90.90 seconds\n",
      "Episode 791, Total Reward: 10.0, Steps: 10, Elapsed Time: 91.02 seconds\n",
      "Episode 792, Total Reward: 8.0, Steps: 8, Elapsed Time: 91.12 seconds\n",
      "Episode 793, Total Reward: 9.0, Steps: 9, Elapsed Time: 91.23 seconds\n",
      "Episode 794, Total Reward: 10.0, Steps: 10, Elapsed Time: 91.36 seconds\n",
      "Episode 795, Total Reward: 10.0, Steps: 10, Elapsed Time: 91.48 seconds\n",
      "Episode 796, Total Reward: 11.0, Steps: 11, Elapsed Time: 91.61 seconds\n",
      "Episode 797, Total Reward: 9.0, Steps: 9, Elapsed Time: 91.73 seconds\n",
      "Episode 798, Total Reward: 10.0, Steps: 10, Elapsed Time: 91.85 seconds\n",
      "Episode 799, Total Reward: 9.0, Steps: 9, Elapsed Time: 91.96 seconds\n",
      "Episode 800, Total Reward: 10.0, Steps: 10, Elapsed Time: 92.12 seconds\n",
      "Episode 801, Total Reward: 9.0, Steps: 9, Elapsed Time: 92.25 seconds\n",
      "Episode 802, Total Reward: 9.0, Steps: 9, Elapsed Time: 92.37 seconds\n",
      "Episode 803, Total Reward: 9.0, Steps: 9, Elapsed Time: 92.49 seconds\n",
      "Episode 804, Total Reward: 9.0, Steps: 9, Elapsed Time: 92.61 seconds\n",
      "Episode 805, Total Reward: 10.0, Steps: 10, Elapsed Time: 92.75 seconds\n",
      "Episode 806, Total Reward: 9.0, Steps: 9, Elapsed Time: 92.89 seconds\n",
      "Episode 807, Total Reward: 10.0, Steps: 10, Elapsed Time: 93.01 seconds\n",
      "Episode 808, Total Reward: 10.0, Steps: 10, Elapsed Time: 93.15 seconds\n",
      "Episode 809, Total Reward: 10.0, Steps: 10, Elapsed Time: 93.29 seconds\n",
      "Episode 810, Total Reward: 10.0, Steps: 10, Elapsed Time: 93.42 seconds\n",
      "Episode 811, Total Reward: 10.0, Steps: 10, Elapsed Time: 93.56 seconds\n",
      "Episode 812, Total Reward: 10.0, Steps: 10, Elapsed Time: 93.69 seconds\n",
      "Episode 813, Total Reward: 8.0, Steps: 8, Elapsed Time: 93.80 seconds\n",
      "Episode 814, Total Reward: 9.0, Steps: 9, Elapsed Time: 93.91 seconds\n",
      "Episode 815, Total Reward: 10.0, Steps: 10, Elapsed Time: 94.05 seconds\n",
      "Episode 816, Total Reward: 8.0, Steps: 8, Elapsed Time: 94.15 seconds\n",
      "Episode 817, Total Reward: 8.0, Steps: 8, Elapsed Time: 94.25 seconds\n",
      "Episode 818, Total Reward: 10.0, Steps: 10, Elapsed Time: 94.39 seconds\n",
      "Episode 819, Total Reward: 9.0, Steps: 9, Elapsed Time: 94.51 seconds\n",
      "Episode 820, Total Reward: 10.0, Steps: 10, Elapsed Time: 94.65 seconds\n",
      "Episode 821, Total Reward: 10.0, Steps: 10, Elapsed Time: 94.80 seconds\n",
      "Episode 822, Total Reward: 10.0, Steps: 10, Elapsed Time: 94.94 seconds\n",
      "Episode 823, Total Reward: 10.0, Steps: 10, Elapsed Time: 95.07 seconds\n",
      "Episode 824, Total Reward: 10.0, Steps: 10, Elapsed Time: 95.21 seconds\n",
      "Episode 825, Total Reward: 10.0, Steps: 10, Elapsed Time: 95.35 seconds\n",
      "Episode 826, Total Reward: 10.0, Steps: 10, Elapsed Time: 95.49 seconds\n",
      "Episode 827, Total Reward: 9.0, Steps: 9, Elapsed Time: 95.62 seconds\n",
      "Episode 828, Total Reward: 10.0, Steps: 10, Elapsed Time: 95.76 seconds\n",
      "Episode 829, Total Reward: 9.0, Steps: 9, Elapsed Time: 95.88 seconds\n",
      "Episode 830, Total Reward: 10.0, Steps: 10, Elapsed Time: 96.01 seconds\n",
      "Episode 831, Total Reward: 10.0, Steps: 10, Elapsed Time: 96.14 seconds\n",
      "Episode 832, Total Reward: 9.0, Steps: 9, Elapsed Time: 96.26 seconds\n",
      "Episode 833, Total Reward: 10.0, Steps: 10, Elapsed Time: 96.40 seconds\n",
      "Episode 834, Total Reward: 10.0, Steps: 10, Elapsed Time: 96.53 seconds\n",
      "Episode 835, Total Reward: 9.0, Steps: 9, Elapsed Time: 96.64 seconds\n",
      "Episode 836, Total Reward: 10.0, Steps: 10, Elapsed Time: 96.77 seconds\n",
      "Episode 837, Total Reward: 9.0, Steps: 9, Elapsed Time: 96.88 seconds\n",
      "Episode 838, Total Reward: 10.0, Steps: 10, Elapsed Time: 97.02 seconds\n",
      "Episode 839, Total Reward: 10.0, Steps: 10, Elapsed Time: 97.15 seconds\n",
      "Episode 840, Total Reward: 8.0, Steps: 8, Elapsed Time: 97.26 seconds\n",
      "Episode 841, Total Reward: 10.0, Steps: 10, Elapsed Time: 97.39 seconds\n",
      "Episode 842, Total Reward: 9.0, Steps: 9, Elapsed Time: 97.50 seconds\n",
      "Episode 843, Total Reward: 8.0, Steps: 8, Elapsed Time: 97.60 seconds\n",
      "Episode 844, Total Reward: 9.0, Steps: 9, Elapsed Time: 97.71 seconds\n",
      "Episode 845, Total Reward: 10.0, Steps: 10, Elapsed Time: 97.83 seconds\n",
      "Episode 846, Total Reward: 8.0, Steps: 8, Elapsed Time: 97.94 seconds\n",
      "Episode 847, Total Reward: 10.0, Steps: 10, Elapsed Time: 98.06 seconds\n",
      "Episode 848, Total Reward: 11.0, Steps: 11, Elapsed Time: 98.21 seconds\n",
      "Episode 849, Total Reward: 10.0, Steps: 10, Elapsed Time: 98.35 seconds\n",
      "Episode 850, Total Reward: 10.0, Steps: 10, Elapsed Time: 98.49 seconds\n",
      "Episode 851, Total Reward: 8.0, Steps: 8, Elapsed Time: 98.60 seconds\n",
      "Episode 852, Total Reward: 9.0, Steps: 9, Elapsed Time: 98.72 seconds\n",
      "Episode 853, Total Reward: 10.0, Steps: 10, Elapsed Time: 98.86 seconds\n",
      "Episode 854, Total Reward: 9.0, Steps: 9, Elapsed Time: 98.99 seconds\n",
      "Episode 855, Total Reward: 9.0, Steps: 9, Elapsed Time: 99.12 seconds\n",
      "Episode 856, Total Reward: 11.0, Steps: 11, Elapsed Time: 99.27 seconds\n",
      "Episode 857, Total Reward: 9.0, Steps: 9, Elapsed Time: 99.39 seconds\n",
      "Episode 858, Total Reward: 9.0, Steps: 9, Elapsed Time: 99.50 seconds\n",
      "Episode 859, Total Reward: 10.0, Steps: 10, Elapsed Time: 99.62 seconds\n",
      "Episode 860, Total Reward: 10.0, Steps: 10, Elapsed Time: 99.75 seconds\n",
      "Episode 861, Total Reward: 9.0, Steps: 9, Elapsed Time: 99.86 seconds\n",
      "Episode 862, Total Reward: 8.0, Steps: 8, Elapsed Time: 99.96 seconds\n",
      "Episode 863, Total Reward: 10.0, Steps: 10, Elapsed Time: 100.08 seconds\n",
      "Episode 864, Total Reward: 10.0, Steps: 10, Elapsed Time: 100.21 seconds\n",
      "Episode 865, Total Reward: 8.0, Steps: 8, Elapsed Time: 100.31 seconds\n",
      "Episode 866, Total Reward: 10.0, Steps: 10, Elapsed Time: 100.44 seconds\n",
      "Episode 867, Total Reward: 9.0, Steps: 9, Elapsed Time: 100.55 seconds\n",
      "Episode 868, Total Reward: 9.0, Steps: 9, Elapsed Time: 100.66 seconds\n",
      "Episode 869, Total Reward: 8.0, Steps: 8, Elapsed Time: 100.76 seconds\n",
      "Episode 870, Total Reward: 10.0, Steps: 10, Elapsed Time: 100.88 seconds\n",
      "Episode 871, Total Reward: 8.0, Steps: 8, Elapsed Time: 100.98 seconds\n",
      "Episode 872, Total Reward: 8.0, Steps: 8, Elapsed Time: 101.08 seconds\n",
      "Episode 873, Total Reward: 9.0, Steps: 9, Elapsed Time: 101.20 seconds\n",
      "Episode 874, Total Reward: 10.0, Steps: 10, Elapsed Time: 101.32 seconds\n",
      "Episode 875, Total Reward: 10.0, Steps: 10, Elapsed Time: 101.45 seconds\n",
      "Episode 876, Total Reward: 8.0, Steps: 8, Elapsed Time: 101.55 seconds\n",
      "Episode 877, Total Reward: 10.0, Steps: 10, Elapsed Time: 101.68 seconds\n",
      "Episode 878, Total Reward: 10.0, Steps: 10, Elapsed Time: 101.80 seconds\n",
      "Episode 879, Total Reward: 8.0, Steps: 8, Elapsed Time: 101.90 seconds\n",
      "Episode 880, Total Reward: 10.0, Steps: 10, Elapsed Time: 102.02 seconds\n",
      "Episode 881, Total Reward: 9.0, Steps: 9, Elapsed Time: 102.14 seconds\n",
      "Episode 882, Total Reward: 10.0, Steps: 10, Elapsed Time: 102.27 seconds\n",
      "Episode 883, Total Reward: 10.0, Steps: 10, Elapsed Time: 102.41 seconds\n",
      "Episode 884, Total Reward: 8.0, Steps: 8, Elapsed Time: 102.51 seconds\n",
      "Episode 885, Total Reward: 9.0, Steps: 9, Elapsed Time: 102.62 seconds\n",
      "Episode 886, Total Reward: 10.0, Steps: 10, Elapsed Time: 102.75 seconds\n",
      "Episode 887, Total Reward: 8.0, Steps: 8, Elapsed Time: 102.85 seconds\n",
      "Episode 888, Total Reward: 10.0, Steps: 10, Elapsed Time: 102.97 seconds\n",
      "Episode 889, Total Reward: 9.0, Steps: 9, Elapsed Time: 103.08 seconds\n",
      "Episode 890, Total Reward: 9.0, Steps: 9, Elapsed Time: 103.19 seconds\n",
      "Episode 891, Total Reward: 10.0, Steps: 10, Elapsed Time: 103.31 seconds\n",
      "Episode 892, Total Reward: 10.0, Steps: 10, Elapsed Time: 103.43 seconds\n",
      "Episode 893, Total Reward: 10.0, Steps: 10, Elapsed Time: 103.55 seconds\n",
      "Episode 894, Total Reward: 9.0, Steps: 9, Elapsed Time: 103.67 seconds\n",
      "Episode 895, Total Reward: 9.0, Steps: 9, Elapsed Time: 103.78 seconds\n",
      "Episode 896, Total Reward: 9.0, Steps: 9, Elapsed Time: 103.89 seconds\n",
      "Episode 897, Total Reward: 10.0, Steps: 10, Elapsed Time: 104.01 seconds\n",
      "Episode 898, Total Reward: 9.0, Steps: 9, Elapsed Time: 104.12 seconds\n",
      "Episode 899, Total Reward: 8.0, Steps: 8, Elapsed Time: 104.22 seconds\n",
      "Episode 900, Total Reward: 10.0, Steps: 10, Elapsed Time: 104.34 seconds\n",
      "Episode 901, Total Reward: 9.0, Steps: 9, Elapsed Time: 104.45 seconds\n",
      "Episode 902, Total Reward: 10.0, Steps: 10, Elapsed Time: 104.57 seconds\n",
      "Episode 903, Total Reward: 9.0, Steps: 9, Elapsed Time: 104.68 seconds\n",
      "Episode 904, Total Reward: 10.0, Steps: 10, Elapsed Time: 104.81 seconds\n",
      "Episode 905, Total Reward: 9.0, Steps: 9, Elapsed Time: 104.92 seconds\n",
      "Episode 906, Total Reward: 10.0, Steps: 10, Elapsed Time: 105.05 seconds\n",
      "Episode 907, Total Reward: 9.0, Steps: 9, Elapsed Time: 105.16 seconds\n",
      "Episode 908, Total Reward: 8.0, Steps: 8, Elapsed Time: 105.25 seconds\n",
      "Episode 909, Total Reward: 9.0, Steps: 9, Elapsed Time: 105.36 seconds\n",
      "Episode 910, Total Reward: 10.0, Steps: 10, Elapsed Time: 105.50 seconds\n",
      "Episode 911, Total Reward: 10.0, Steps: 10, Elapsed Time: 105.64 seconds\n",
      "Episode 912, Total Reward: 9.0, Steps: 9, Elapsed Time: 105.75 seconds\n",
      "Episode 913, Total Reward: 8.0, Steps: 8, Elapsed Time: 105.86 seconds\n",
      "Episode 914, Total Reward: 9.0, Steps: 9, Elapsed Time: 105.97 seconds\n",
      "Episode 915, Total Reward: 8.0, Steps: 8, Elapsed Time: 106.07 seconds\n",
      "Episode 916, Total Reward: 9.0, Steps: 9, Elapsed Time: 106.18 seconds\n",
      "Episode 917, Total Reward: 10.0, Steps: 10, Elapsed Time: 106.30 seconds\n",
      "Episode 918, Total Reward: 9.0, Steps: 9, Elapsed Time: 106.41 seconds\n",
      "Episode 919, Total Reward: 9.0, Steps: 9, Elapsed Time: 106.52 seconds\n",
      "Episode 920, Total Reward: 10.0, Steps: 10, Elapsed Time: 106.64 seconds\n",
      "Episode 921, Total Reward: 10.0, Steps: 10, Elapsed Time: 106.77 seconds\n",
      "Episode 922, Total Reward: 10.0, Steps: 10, Elapsed Time: 106.89 seconds\n",
      "Episode 923, Total Reward: 10.0, Steps: 10, Elapsed Time: 107.03 seconds\n",
      "Episode 924, Total Reward: 10.0, Steps: 10, Elapsed Time: 107.15 seconds\n",
      "Episode 925, Total Reward: 9.0, Steps: 9, Elapsed Time: 107.26 seconds\n",
      "Episode 926, Total Reward: 9.0, Steps: 9, Elapsed Time: 107.37 seconds\n",
      "Episode 927, Total Reward: 10.0, Steps: 10, Elapsed Time: 107.50 seconds\n",
      "Episode 928, Total Reward: 10.0, Steps: 10, Elapsed Time: 107.64 seconds\n",
      "Episode 929, Total Reward: 11.0, Steps: 11, Elapsed Time: 107.78 seconds\n",
      "Episode 930, Total Reward: 10.0, Steps: 10, Elapsed Time: 107.90 seconds\n",
      "Episode 931, Total Reward: 9.0, Steps: 9, Elapsed Time: 108.02 seconds\n",
      "Episode 932, Total Reward: 10.0, Steps: 10, Elapsed Time: 108.14 seconds\n",
      "Episode 933, Total Reward: 10.0, Steps: 10, Elapsed Time: 108.26 seconds\n",
      "Episode 934, Total Reward: 9.0, Steps: 9, Elapsed Time: 108.37 seconds\n",
      "Episode 935, Total Reward: 10.0, Steps: 10, Elapsed Time: 108.49 seconds\n",
      "Episode 936, Total Reward: 10.0, Steps: 10, Elapsed Time: 108.61 seconds\n",
      "Episode 937, Total Reward: 9.0, Steps: 9, Elapsed Time: 108.72 seconds\n",
      "Episode 938, Total Reward: 10.0, Steps: 10, Elapsed Time: 108.85 seconds\n",
      "Episode 939, Total Reward: 10.0, Steps: 10, Elapsed Time: 108.99 seconds\n",
      "Episode 940, Total Reward: 9.0, Steps: 9, Elapsed Time: 109.10 seconds\n",
      "Episode 941, Total Reward: 10.0, Steps: 10, Elapsed Time: 109.22 seconds\n",
      "Episode 942, Total Reward: 9.0, Steps: 9, Elapsed Time: 109.33 seconds\n",
      "Episode 943, Total Reward: 9.0, Steps: 9, Elapsed Time: 109.44 seconds\n",
      "Episode 944, Total Reward: 10.0, Steps: 10, Elapsed Time: 109.56 seconds\n",
      "Episode 945, Total Reward: 10.0, Steps: 10, Elapsed Time: 109.68 seconds\n",
      "Episode 946, Total Reward: 10.0, Steps: 10, Elapsed Time: 109.81 seconds\n",
      "Episode 947, Total Reward: 10.0, Steps: 10, Elapsed Time: 109.93 seconds\n",
      "Episode 948, Total Reward: 9.0, Steps: 9, Elapsed Time: 110.04 seconds\n",
      "Episode 949, Total Reward: 10.0, Steps: 10, Elapsed Time: 110.17 seconds\n",
      "Episode 950, Total Reward: 8.0, Steps: 8, Elapsed Time: 110.27 seconds\n",
      "Episode 951, Total Reward: 10.0, Steps: 10, Elapsed Time: 110.39 seconds\n",
      "Episode 952, Total Reward: 9.0, Steps: 9, Elapsed Time: 110.52 seconds\n",
      "Episode 953, Total Reward: 8.0, Steps: 8, Elapsed Time: 110.61 seconds\n",
      "Episode 954, Total Reward: 10.0, Steps: 10, Elapsed Time: 110.74 seconds\n",
      "Episode 955, Total Reward: 10.0, Steps: 10, Elapsed Time: 110.86 seconds\n",
      "Episode 956, Total Reward: 10.0, Steps: 10, Elapsed Time: 110.98 seconds\n",
      "Episode 957, Total Reward: 11.0, Steps: 11, Elapsed Time: 111.11 seconds\n",
      "Episode 958, Total Reward: 9.0, Steps: 9, Elapsed Time: 111.23 seconds\n",
      "Episode 959, Total Reward: 8.0, Steps: 8, Elapsed Time: 111.32 seconds\n",
      "Episode 960, Total Reward: 9.0, Steps: 9, Elapsed Time: 111.43 seconds\n",
      "Episode 961, Total Reward: 9.0, Steps: 9, Elapsed Time: 111.54 seconds\n",
      "Episode 962, Total Reward: 9.0, Steps: 9, Elapsed Time: 111.65 seconds\n",
      "Episode 963, Total Reward: 10.0, Steps: 10, Elapsed Time: 111.77 seconds\n",
      "Episode 964, Total Reward: 10.0, Steps: 10, Elapsed Time: 111.89 seconds\n",
      "Episode 965, Total Reward: 10.0, Steps: 10, Elapsed Time: 112.01 seconds\n",
      "Episode 966, Total Reward: 9.0, Steps: 9, Elapsed Time: 112.12 seconds\n",
      "Episode 967, Total Reward: 9.0, Steps: 9, Elapsed Time: 112.24 seconds\n",
      "Episode 968, Total Reward: 9.0, Steps: 9, Elapsed Time: 112.35 seconds\n",
      "Episode 969, Total Reward: 10.0, Steps: 10, Elapsed Time: 112.48 seconds\n",
      "Episode 970, Total Reward: 9.0, Steps: 9, Elapsed Time: 112.59 seconds\n",
      "Episode 971, Total Reward: 9.0, Steps: 9, Elapsed Time: 112.70 seconds\n",
      "Episode 972, Total Reward: 9.0, Steps: 9, Elapsed Time: 112.81 seconds\n",
      "Episode 973, Total Reward: 9.0, Steps: 9, Elapsed Time: 112.92 seconds\n",
      "Episode 974, Total Reward: 9.0, Steps: 9, Elapsed Time: 113.03 seconds\n",
      "Episode 975, Total Reward: 10.0, Steps: 10, Elapsed Time: 113.15 seconds\n",
      "Episode 976, Total Reward: 9.0, Steps: 9, Elapsed Time: 113.26 seconds\n",
      "Episode 977, Total Reward: 10.0, Steps: 10, Elapsed Time: 113.38 seconds\n",
      "Episode 978, Total Reward: 9.0, Steps: 9, Elapsed Time: 113.49 seconds\n",
      "Episode 979, Total Reward: 9.0, Steps: 9, Elapsed Time: 113.60 seconds\n",
      "Episode 980, Total Reward: 9.0, Steps: 9, Elapsed Time: 113.71 seconds\n",
      "Episode 981, Total Reward: 9.0, Steps: 9, Elapsed Time: 113.82 seconds\n",
      "Episode 982, Total Reward: 10.0, Steps: 10, Elapsed Time: 113.94 seconds\n",
      "Episode 983, Total Reward: 10.0, Steps: 10, Elapsed Time: 114.06 seconds\n",
      "Episode 984, Total Reward: 9.0, Steps: 9, Elapsed Time: 114.17 seconds\n",
      "Episode 985, Total Reward: 10.0, Steps: 10, Elapsed Time: 114.29 seconds\n",
      "Episode 986, Total Reward: 9.0, Steps: 9, Elapsed Time: 114.40 seconds\n",
      "Episode 987, Total Reward: 10.0, Steps: 10, Elapsed Time: 114.53 seconds\n",
      "Episode 988, Total Reward: 9.0, Steps: 9, Elapsed Time: 114.65 seconds\n",
      "Episode 989, Total Reward: 10.0, Steps: 10, Elapsed Time: 114.77 seconds\n",
      "Episode 990, Total Reward: 9.0, Steps: 9, Elapsed Time: 114.88 seconds\n",
      "Episode 991, Total Reward: 10.0, Steps: 10, Elapsed Time: 115.01 seconds\n",
      "Episode 992, Total Reward: 9.0, Steps: 9, Elapsed Time: 115.12 seconds\n",
      "Episode 993, Total Reward: 10.0, Steps: 10, Elapsed Time: 115.25 seconds\n",
      "Episode 994, Total Reward: 9.0, Steps: 9, Elapsed Time: 115.36 seconds\n",
      "Episode 995, Total Reward: 10.0, Steps: 10, Elapsed Time: 115.50 seconds\n",
      "Episode 996, Total Reward: 9.0, Steps: 9, Elapsed Time: 115.62 seconds\n",
      "Episode 997, Total Reward: 10.0, Steps: 10, Elapsed Time: 115.75 seconds\n",
      "Episode 998, Total Reward: 9.0, Steps: 9, Elapsed Time: 115.86 seconds\n",
      "Episode 999, Total Reward: 10.0, Steps: 10, Elapsed Time: 116.00 seconds\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "# CartPole-v1 환경 사용\n",
    "env = gym.make('CartPole-v1', render_mode='rgb_array')\n",
    "\n",
    "def get_image_from_env(env):\n",
    "    frame = env.render()\n",
    "    return frame\n",
    "\n",
    "state, _ = env.reset()\n",
    "image = get_image_from_env(env)\n",
    "\n",
    "cv2.imshow(\"CartPole\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "def preprocess_image(image):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # 흑백으로 변환\n",
    "    image = cv2.resize(image, (64, 64))  # 크기 조정\n",
    "    image = image.astype(np.float32) / 255.0  # 정규화\n",
    "    image = np.expand_dims(image, axis=0)  # 배치 차원 추가\n",
    "    return image\n",
    "\n",
    "class CartPoleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CartPoleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=2)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=2)\n",
    "        self.fc1 = nn.Linear(64*7*7, 256)\n",
    "        self.fc2 = nn.Linear(256, 2)  # 이산적 동작 공간에서의 두 개의 동작\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.relu(self.conv3(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# 모델 초기화\n",
    "model = CartPoleCNN()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for episode in range(1000):\n",
    "    state, _ = env.reset()\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "    step = 0\n",
    "    \n",
    "    while not done:\n",
    "        image = get_image_from_env(env)\n",
    "        image = preprocess_image(image)\n",
    "        image = torch.FloatTensor(image).unsqueeze(0)\n",
    "        \n",
    "        # 이산적 동작 선택\n",
    "        action_probs = model(image).detach().numpy().flatten()\n",
    "        action = np.argmax(action_probs)\n",
    "        \n",
    "        next_state, reward, done, _, _ = env.step(action)\n",
    "        \n",
    "        # 손실 계산 및 역전파\n",
    "        optimizer.zero_grad()\n",
    "        output = model(image)\n",
    "        target = output.clone()\n",
    "        target[0][action] = reward + 0.99 * np.max(model(torch.FloatTensor(preprocess_image(get_image_from_env(env))).unsqueeze(0)).detach().numpy())\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_reward += reward\n",
    "        step += 1\n",
    "        \n",
    "    # 각 에피소드마다 실행 시간과 보상 출력\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"Episode {episode}, Total Reward: {total_reward}, Steps: {step}, Elapsed Time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시각화 코드 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0, Total Reward: 10.0, Steps: 10, Elapsed Time: 0.68 seconds\n",
      "Episode 1, Total Reward: 9.0, Steps: 9, Elapsed Time: 0.79 seconds\n",
      "Episode 2, Total Reward: 10.0, Steps: 10, Elapsed Time: 0.90 seconds\n",
      "Episode 3, Total Reward: 10.0, Steps: 10, Elapsed Time: 1.01 seconds\n",
      "Episode 4, Total Reward: 9.0, Steps: 9, Elapsed Time: 1.11 seconds\n",
      "Episode 5, Total Reward: 10.0, Steps: 10, Elapsed Time: 1.22 seconds\n",
      "Episode 6, Total Reward: 9.0, Steps: 9, Elapsed Time: 1.33 seconds\n",
      "Episode 7, Total Reward: 10.0, Steps: 10, Elapsed Time: 1.44 seconds\n",
      "Episode 8, Total Reward: 9.0, Steps: 9, Elapsed Time: 1.53 seconds\n",
      "Episode 9, Total Reward: 10.0, Steps: 10, Elapsed Time: 1.63 seconds\n",
      "Episode 10, Total Reward: 9.0, Steps: 9, Elapsed Time: 1.73 seconds\n",
      "Episode 11, Total Reward: 9.0, Steps: 9, Elapsed Time: 1.81 seconds\n",
      "Episode 12, Total Reward: 8.0, Steps: 8, Elapsed Time: 1.90 seconds\n",
      "Episode 13, Total Reward: 9.0, Steps: 9, Elapsed Time: 1.99 seconds\n",
      "Episode 14, Total Reward: 10.0, Steps: 10, Elapsed Time: 2.11 seconds\n",
      "Episode 15, Total Reward: 10.0, Steps: 10, Elapsed Time: 2.21 seconds\n",
      "Episode 16, Total Reward: 11.0, Steps: 11, Elapsed Time: 2.33 seconds\n",
      "Episode 17, Total Reward: 9.0, Steps: 9, Elapsed Time: 2.43 seconds\n",
      "Episode 18, Total Reward: 9.0, Steps: 9, Elapsed Time: 2.52 seconds\n",
      "Episode 19, Total Reward: 9.0, Steps: 9, Elapsed Time: 2.61 seconds\n",
      "Episode 20, Total Reward: 10.0, Steps: 10, Elapsed Time: 2.72 seconds\n",
      "Episode 21, Total Reward: 9.0, Steps: 9, Elapsed Time: 2.81 seconds\n",
      "Episode 22, Total Reward: 9.0, Steps: 9, Elapsed Time: 2.91 seconds\n",
      "Episode 23, Total Reward: 10.0, Steps: 10, Elapsed Time: 3.02 seconds\n",
      "Episode 24, Total Reward: 9.0, Steps: 9, Elapsed Time: 3.11 seconds\n",
      "Episode 25, Total Reward: 9.0, Steps: 9, Elapsed Time: 3.21 seconds\n",
      "Episode 26, Total Reward: 10.0, Steps: 10, Elapsed Time: 3.31 seconds\n",
      "Episode 27, Total Reward: 10.0, Steps: 10, Elapsed Time: 3.41 seconds\n",
      "Episode 28, Total Reward: 9.0, Steps: 9, Elapsed Time: 3.51 seconds\n",
      "Episode 29, Total Reward: 10.0, Steps: 10, Elapsed Time: 3.62 seconds\n",
      "Episode 30, Total Reward: 8.0, Steps: 8, Elapsed Time: 3.71 seconds\n",
      "Episode 31, Total Reward: 9.0, Steps: 9, Elapsed Time: 3.80 seconds\n",
      "Episode 32, Total Reward: 9.0, Steps: 9, Elapsed Time: 3.89 seconds\n",
      "Episode 33, Total Reward: 10.0, Steps: 10, Elapsed Time: 4.01 seconds\n",
      "Episode 34, Total Reward: 8.0, Steps: 8, Elapsed Time: 4.10 seconds\n",
      "Episode 35, Total Reward: 8.0, Steps: 8, Elapsed Time: 4.19 seconds\n",
      "Episode 36, Total Reward: 10.0, Steps: 10, Elapsed Time: 4.29 seconds\n",
      "Episode 37, Total Reward: 9.0, Steps: 9, Elapsed Time: 4.38 seconds\n",
      "Episode 38, Total Reward: 10.0, Steps: 10, Elapsed Time: 4.48 seconds\n",
      "Episode 39, Total Reward: 10.0, Steps: 10, Elapsed Time: 4.61 seconds\n",
      "Episode 40, Total Reward: 10.0, Steps: 10, Elapsed Time: 4.72 seconds\n",
      "Episode 41, Total Reward: 10.0, Steps: 10, Elapsed Time: 4.83 seconds\n",
      "Episode 42, Total Reward: 10.0, Steps: 10, Elapsed Time: 4.95 seconds\n",
      "Episode 43, Total Reward: 10.0, Steps: 10, Elapsed Time: 5.07 seconds\n",
      "Episode 44, Total Reward: 10.0, Steps: 10, Elapsed Time: 5.21 seconds\n",
      "Episode 45, Total Reward: 10.0, Steps: 10, Elapsed Time: 5.33 seconds\n",
      "Episode 46, Total Reward: 10.0, Steps: 10, Elapsed Time: 5.46 seconds\n",
      "Episode 47, Total Reward: 9.0, Steps: 9, Elapsed Time: 5.58 seconds\n",
      "Episode 48, Total Reward: 9.0, Steps: 9, Elapsed Time: 5.69 seconds\n",
      "Episode 49, Total Reward: 9.0, Steps: 9, Elapsed Time: 5.80 seconds\n",
      "Episode 50, Total Reward: 9.0, Steps: 9, Elapsed Time: 5.91 seconds\n",
      "Episode 51, Total Reward: 9.0, Steps: 9, Elapsed Time: 6.02 seconds\n",
      "Episode 52, Total Reward: 10.0, Steps: 10, Elapsed Time: 6.14 seconds\n",
      "Episode 53, Total Reward: 9.0, Steps: 9, Elapsed Time: 6.26 seconds\n",
      "Episode 54, Total Reward: 10.0, Steps: 10, Elapsed Time: 6.39 seconds\n",
      "Episode 55, Total Reward: 9.0, Steps: 9, Elapsed Time: 6.50 seconds\n",
      "Episode 56, Total Reward: 10.0, Steps: 10, Elapsed Time: 6.61 seconds\n",
      "Episode 57, Total Reward: 9.0, Steps: 9, Elapsed Time: 6.70 seconds\n",
      "Episode 58, Total Reward: 10.0, Steps: 10, Elapsed Time: 6.80 seconds\n",
      "Episode 59, Total Reward: 9.0, Steps: 9, Elapsed Time: 6.89 seconds\n",
      "Episode 60, Total Reward: 10.0, Steps: 10, Elapsed Time: 6.99 seconds\n",
      "Episode 61, Total Reward: 10.0, Steps: 10, Elapsed Time: 7.10 seconds\n",
      "Episode 62, Total Reward: 8.0, Steps: 8, Elapsed Time: 7.18 seconds\n",
      "Episode 63, Total Reward: 10.0, Steps: 10, Elapsed Time: 7.28 seconds\n",
      "Episode 64, Total Reward: 10.0, Steps: 10, Elapsed Time: 7.39 seconds\n",
      "Episode 65, Total Reward: 10.0, Steps: 10, Elapsed Time: 7.50 seconds\n",
      "Episode 66, Total Reward: 8.0, Steps: 8, Elapsed Time: 7.58 seconds\n",
      "Episode 67, Total Reward: 9.0, Steps: 9, Elapsed Time: 7.68 seconds\n",
      "Episode 68, Total Reward: 10.0, Steps: 10, Elapsed Time: 7.78 seconds\n",
      "Episode 69, Total Reward: 9.0, Steps: 9, Elapsed Time: 7.87 seconds\n",
      "Episode 70, Total Reward: 9.0, Steps: 9, Elapsed Time: 7.96 seconds\n",
      "Episode 71, Total Reward: 10.0, Steps: 10, Elapsed Time: 8.07 seconds\n",
      "Episode 72, Total Reward: 10.0, Steps: 10, Elapsed Time: 8.19 seconds\n",
      "Episode 73, Total Reward: 10.0, Steps: 10, Elapsed Time: 8.30 seconds\n",
      "Episode 74, Total Reward: 10.0, Steps: 10, Elapsed Time: 8.41 seconds\n",
      "Episode 75, Total Reward: 9.0, Steps: 9, Elapsed Time: 8.52 seconds\n",
      "Episode 76, Total Reward: 9.0, Steps: 9, Elapsed Time: 8.62 seconds\n",
      "Episode 77, Total Reward: 9.0, Steps: 9, Elapsed Time: 8.72 seconds\n",
      "Episode 78, Total Reward: 10.0, Steps: 10, Elapsed Time: 8.84 seconds\n",
      "Episode 79, Total Reward: 9.0, Steps: 9, Elapsed Time: 8.95 seconds\n",
      "Episode 80, Total Reward: 9.0, Steps: 9, Elapsed Time: 9.05 seconds\n",
      "Episode 81, Total Reward: 9.0, Steps: 9, Elapsed Time: 9.16 seconds\n",
      "Episode 82, Total Reward: 9.0, Steps: 9, Elapsed Time: 9.27 seconds\n",
      "Episode 83, Total Reward: 10.0, Steps: 10, Elapsed Time: 9.39 seconds\n",
      "Episode 84, Total Reward: 9.0, Steps: 9, Elapsed Time: 9.50 seconds\n",
      "Episode 85, Total Reward: 9.0, Steps: 9, Elapsed Time: 9.61 seconds\n",
      "Episode 86, Total Reward: 10.0, Steps: 10, Elapsed Time: 9.74 seconds\n",
      "Episode 87, Total Reward: 8.0, Steps: 8, Elapsed Time: 9.84 seconds\n",
      "Episode 88, Total Reward: 10.0, Steps: 10, Elapsed Time: 9.96 seconds\n",
      "Episode 89, Total Reward: 8.0, Steps: 8, Elapsed Time: 10.05 seconds\n",
      "Episode 90, Total Reward: 9.0, Steps: 9, Elapsed Time: 10.16 seconds\n",
      "Episode 91, Total Reward: 9.0, Steps: 9, Elapsed Time: 10.26 seconds\n",
      "Episode 92, Total Reward: 9.0, Steps: 9, Elapsed Time: 10.36 seconds\n",
      "Episode 93, Total Reward: 8.0, Steps: 8, Elapsed Time: 10.45 seconds\n",
      "Episode 94, Total Reward: 8.0, Steps: 8, Elapsed Time: 10.54 seconds\n",
      "Episode 95, Total Reward: 8.0, Steps: 8, Elapsed Time: 10.64 seconds\n",
      "Episode 96, Total Reward: 9.0, Steps: 9, Elapsed Time: 10.75 seconds\n",
      "Episode 97, Total Reward: 10.0, Steps: 10, Elapsed Time: 10.87 seconds\n",
      "Episode 98, Total Reward: 8.0, Steps: 8, Elapsed Time: 10.98 seconds\n",
      "Episode 99, Total Reward: 10.0, Steps: 10, Elapsed Time: 11.09 seconds\n",
      "Episode 100, Total Reward: 10.0, Steps: 10, Elapsed Time: 11.22 seconds\n",
      "Episode 101, Total Reward: 10.0, Steps: 10, Elapsed Time: 11.33 seconds\n",
      "Episode 102, Total Reward: 10.0, Steps: 10, Elapsed Time: 11.45 seconds\n",
      "Episode 103, Total Reward: 10.0, Steps: 10, Elapsed Time: 11.56 seconds\n",
      "Episode 104, Total Reward: 9.0, Steps: 9, Elapsed Time: 11.66 seconds\n",
      "Episode 105, Total Reward: 9.0, Steps: 9, Elapsed Time: 11.77 seconds\n",
      "Episode 106, Total Reward: 10.0, Steps: 10, Elapsed Time: 11.88 seconds\n",
      "Episode 107, Total Reward: 10.0, Steps: 10, Elapsed Time: 11.99 seconds\n",
      "Episode 108, Total Reward: 10.0, Steps: 10, Elapsed Time: 12.11 seconds\n",
      "Episode 109, Total Reward: 10.0, Steps: 10, Elapsed Time: 12.23 seconds\n",
      "Episode 110, Total Reward: 9.0, Steps: 9, Elapsed Time: 12.33 seconds\n",
      "Episode 111, Total Reward: 8.0, Steps: 8, Elapsed Time: 12.42 seconds\n",
      "Episode 112, Total Reward: 9.0, Steps: 9, Elapsed Time: 12.52 seconds\n",
      "Episode 113, Total Reward: 10.0, Steps: 10, Elapsed Time: 12.63 seconds\n",
      "Episode 114, Total Reward: 11.0, Steps: 11, Elapsed Time: 12.76 seconds\n",
      "Episode 115, Total Reward: 10.0, Steps: 10, Elapsed Time: 12.89 seconds\n",
      "Episode 116, Total Reward: 10.0, Steps: 10, Elapsed Time: 13.00 seconds\n",
      "Episode 117, Total Reward: 9.0, Steps: 9, Elapsed Time: 13.10 seconds\n",
      "Episode 118, Total Reward: 9.0, Steps: 9, Elapsed Time: 13.21 seconds\n",
      "Episode 119, Total Reward: 9.0, Steps: 9, Elapsed Time: 13.31 seconds\n",
      "Episode 120, Total Reward: 10.0, Steps: 10, Elapsed Time: 13.43 seconds\n",
      "Episode 121, Total Reward: 9.0, Steps: 9, Elapsed Time: 13.53 seconds\n",
      "Episode 122, Total Reward: 10.0, Steps: 10, Elapsed Time: 13.65 seconds\n",
      "Episode 123, Total Reward: 9.0, Steps: 9, Elapsed Time: 13.75 seconds\n",
      "Episode 124, Total Reward: 9.0, Steps: 9, Elapsed Time: 13.86 seconds\n",
      "Episode 125, Total Reward: 9.0, Steps: 9, Elapsed Time: 13.97 seconds\n",
      "Episode 126, Total Reward: 10.0, Steps: 10, Elapsed Time: 14.09 seconds\n",
      "Episode 127, Total Reward: 9.0, Steps: 9, Elapsed Time: 14.19 seconds\n",
      "Episode 128, Total Reward: 9.0, Steps: 9, Elapsed Time: 14.30 seconds\n",
      "Episode 129, Total Reward: 10.0, Steps: 10, Elapsed Time: 14.41 seconds\n",
      "Episode 130, Total Reward: 9.0, Steps: 9, Elapsed Time: 14.52 seconds\n",
      "Episode 131, Total Reward: 9.0, Steps: 9, Elapsed Time: 14.64 seconds\n",
      "Episode 132, Total Reward: 10.0, Steps: 10, Elapsed Time: 14.76 seconds\n",
      "Episode 133, Total Reward: 10.0, Steps: 10, Elapsed Time: 14.87 seconds\n",
      "Episode 134, Total Reward: 10.0, Steps: 10, Elapsed Time: 14.98 seconds\n",
      "Episode 135, Total Reward: 8.0, Steps: 8, Elapsed Time: 15.08 seconds\n",
      "Episode 136, Total Reward: 10.0, Steps: 10, Elapsed Time: 15.20 seconds\n",
      "Episode 137, Total Reward: 8.0, Steps: 8, Elapsed Time: 15.30 seconds\n",
      "Episode 138, Total Reward: 9.0, Steps: 9, Elapsed Time: 15.40 seconds\n",
      "Episode 139, Total Reward: 8.0, Steps: 8, Elapsed Time: 15.49 seconds\n",
      "Episode 140, Total Reward: 10.0, Steps: 10, Elapsed Time: 15.60 seconds\n",
      "Episode 141, Total Reward: 8.0, Steps: 8, Elapsed Time: 15.69 seconds\n",
      "Episode 142, Total Reward: 11.0, Steps: 11, Elapsed Time: 15.81 seconds\n",
      "Episode 143, Total Reward: 10.0, Steps: 10, Elapsed Time: 15.93 seconds\n",
      "Episode 144, Total Reward: 9.0, Steps: 9, Elapsed Time: 16.02 seconds\n",
      "Episode 145, Total Reward: 10.0, Steps: 10, Elapsed Time: 16.14 seconds\n",
      "Episode 146, Total Reward: 9.0, Steps: 9, Elapsed Time: 16.24 seconds\n",
      "Episode 147, Total Reward: 9.0, Steps: 9, Elapsed Time: 16.36 seconds\n",
      "Episode 148, Total Reward: 8.0, Steps: 8, Elapsed Time: 16.44 seconds\n",
      "Episode 149, Total Reward: 10.0, Steps: 10, Elapsed Time: 16.56 seconds\n",
      "Episode 150, Total Reward: 9.0, Steps: 9, Elapsed Time: 16.66 seconds\n",
      "Episode 151, Total Reward: 10.0, Steps: 10, Elapsed Time: 16.78 seconds\n",
      "Episode 152, Total Reward: 8.0, Steps: 8, Elapsed Time: 16.87 seconds\n",
      "Episode 153, Total Reward: 9.0, Steps: 9, Elapsed Time: 16.97 seconds\n",
      "Episode 154, Total Reward: 11.0, Steps: 11, Elapsed Time: 17.10 seconds\n",
      "Episode 155, Total Reward: 9.0, Steps: 9, Elapsed Time: 17.20 seconds\n",
      "Episode 156, Total Reward: 11.0, Steps: 11, Elapsed Time: 17.34 seconds\n",
      "Episode 157, Total Reward: 8.0, Steps: 8, Elapsed Time: 17.43 seconds\n",
      "Episode 158, Total Reward: 10.0, Steps: 10, Elapsed Time: 17.54 seconds\n",
      "Episode 159, Total Reward: 10.0, Steps: 10, Elapsed Time: 17.66 seconds\n",
      "Episode 160, Total Reward: 9.0, Steps: 9, Elapsed Time: 17.76 seconds\n",
      "Episode 161, Total Reward: 9.0, Steps: 9, Elapsed Time: 17.86 seconds\n",
      "Episode 162, Total Reward: 11.0, Steps: 11, Elapsed Time: 17.98 seconds\n",
      "Episode 163, Total Reward: 10.0, Steps: 10, Elapsed Time: 18.10 seconds\n",
      "Episode 164, Total Reward: 10.0, Steps: 10, Elapsed Time: 18.21 seconds\n",
      "Episode 165, Total Reward: 9.0, Steps: 9, Elapsed Time: 18.32 seconds\n",
      "Episode 166, Total Reward: 10.0, Steps: 10, Elapsed Time: 18.43 seconds\n",
      "Episode 167, Total Reward: 10.0, Steps: 10, Elapsed Time: 18.54 seconds\n",
      "Episode 168, Total Reward: 11.0, Steps: 11, Elapsed Time: 18.67 seconds\n",
      "Episode 169, Total Reward: 9.0, Steps: 9, Elapsed Time: 18.78 seconds\n",
      "Episode 170, Total Reward: 11.0, Steps: 11, Elapsed Time: 18.91 seconds\n",
      "Episode 171, Total Reward: 8.0, Steps: 8, Elapsed Time: 19.00 seconds\n",
      "Episode 172, Total Reward: 8.0, Steps: 8, Elapsed Time: 19.09 seconds\n",
      "Episode 173, Total Reward: 10.0, Steps: 10, Elapsed Time: 19.21 seconds\n",
      "Episode 174, Total Reward: 8.0, Steps: 8, Elapsed Time: 19.30 seconds\n",
      "Episode 175, Total Reward: 9.0, Steps: 9, Elapsed Time: 19.40 seconds\n",
      "Episode 176, Total Reward: 10.0, Steps: 10, Elapsed Time: 19.52 seconds\n",
      "Episode 177, Total Reward: 9.0, Steps: 9, Elapsed Time: 19.62 seconds\n",
      "Episode 178, Total Reward: 10.0, Steps: 10, Elapsed Time: 19.74 seconds\n",
      "Episode 179, Total Reward: 10.0, Steps: 10, Elapsed Time: 19.85 seconds\n",
      "Episode 180, Total Reward: 10.0, Steps: 10, Elapsed Time: 19.96 seconds\n",
      "Episode 181, Total Reward: 9.0, Steps: 9, Elapsed Time: 20.07 seconds\n",
      "Episode 182, Total Reward: 8.0, Steps: 8, Elapsed Time: 20.16 seconds\n",
      "Episode 183, Total Reward: 9.0, Steps: 9, Elapsed Time: 20.27 seconds\n",
      "Episode 184, Total Reward: 9.0, Steps: 9, Elapsed Time: 20.37 seconds\n",
      "Episode 185, Total Reward: 10.0, Steps: 10, Elapsed Time: 20.49 seconds\n",
      "Episode 186, Total Reward: 9.0, Steps: 9, Elapsed Time: 20.60 seconds\n",
      "Episode 187, Total Reward: 10.0, Steps: 10, Elapsed Time: 20.71 seconds\n",
      "Episode 188, Total Reward: 10.0, Steps: 10, Elapsed Time: 20.83 seconds\n",
      "Episode 189, Total Reward: 10.0, Steps: 10, Elapsed Time: 20.95 seconds\n",
      "Episode 190, Total Reward: 9.0, Steps: 9, Elapsed Time: 21.05 seconds\n",
      "Episode 191, Total Reward: 10.0, Steps: 10, Elapsed Time: 21.16 seconds\n",
      "Episode 192, Total Reward: 10.0, Steps: 10, Elapsed Time: 21.28 seconds\n",
      "Episode 193, Total Reward: 9.0, Steps: 9, Elapsed Time: 21.40 seconds\n",
      "Episode 194, Total Reward: 10.0, Steps: 10, Elapsed Time: 21.51 seconds\n",
      "Episode 195, Total Reward: 9.0, Steps: 9, Elapsed Time: 21.61 seconds\n",
      "Episode 196, Total Reward: 9.0, Steps: 9, Elapsed Time: 21.72 seconds\n",
      "Episode 197, Total Reward: 10.0, Steps: 10, Elapsed Time: 21.83 seconds\n",
      "Episode 198, Total Reward: 10.0, Steps: 10, Elapsed Time: 21.95 seconds\n",
      "Episode 199, Total Reward: 9.0, Steps: 9, Elapsed Time: 22.05 seconds\n",
      "Episode 200, Total Reward: 10.0, Steps: 10, Elapsed Time: 22.16 seconds\n",
      "Episode 201, Total Reward: 10.0, Steps: 10, Elapsed Time: 22.27 seconds\n",
      "Episode 202, Total Reward: 10.0, Steps: 10, Elapsed Time: 22.39 seconds\n",
      "Episode 203, Total Reward: 9.0, Steps: 9, Elapsed Time: 22.49 seconds\n",
      "Episode 204, Total Reward: 9.0, Steps: 9, Elapsed Time: 22.60 seconds\n",
      "Episode 205, Total Reward: 8.0, Steps: 8, Elapsed Time: 22.69 seconds\n",
      "Episode 206, Total Reward: 10.0, Steps: 10, Elapsed Time: 22.80 seconds\n",
      "Episode 207, Total Reward: 10.0, Steps: 10, Elapsed Time: 22.91 seconds\n",
      "Episode 208, Total Reward: 9.0, Steps: 9, Elapsed Time: 23.01 seconds\n",
      "Episode 209, Total Reward: 9.0, Steps: 9, Elapsed Time: 23.13 seconds\n",
      "Episode 210, Total Reward: 10.0, Steps: 10, Elapsed Time: 23.24 seconds\n",
      "Episode 211, Total Reward: 10.0, Steps: 10, Elapsed Time: 23.36 seconds\n",
      "Episode 212, Total Reward: 10.0, Steps: 10, Elapsed Time: 23.47 seconds\n",
      "Episode 213, Total Reward: 10.0, Steps: 10, Elapsed Time: 23.59 seconds\n",
      "Episode 214, Total Reward: 9.0, Steps: 9, Elapsed Time: 23.70 seconds\n",
      "Episode 215, Total Reward: 9.0, Steps: 9, Elapsed Time: 23.81 seconds\n",
      "Episode 216, Total Reward: 10.0, Steps: 10, Elapsed Time: 23.93 seconds\n",
      "Episode 217, Total Reward: 8.0, Steps: 8, Elapsed Time: 24.02 seconds\n",
      "Episode 218, Total Reward: 9.0, Steps: 9, Elapsed Time: 24.12 seconds\n",
      "Episode 219, Total Reward: 9.0, Steps: 9, Elapsed Time: 24.22 seconds\n",
      "Episode 220, Total Reward: 9.0, Steps: 9, Elapsed Time: 24.32 seconds\n",
      "Episode 221, Total Reward: 9.0, Steps: 9, Elapsed Time: 24.43 seconds\n",
      "Episode 222, Total Reward: 9.0, Steps: 9, Elapsed Time: 24.53 seconds\n",
      "Episode 223, Total Reward: 10.0, Steps: 10, Elapsed Time: 24.64 seconds\n",
      "Episode 224, Total Reward: 10.0, Steps: 10, Elapsed Time: 24.76 seconds\n",
      "Episode 225, Total Reward: 9.0, Steps: 9, Elapsed Time: 24.86 seconds\n",
      "Episode 226, Total Reward: 9.0, Steps: 9, Elapsed Time: 24.97 seconds\n",
      "Episode 227, Total Reward: 9.0, Steps: 9, Elapsed Time: 25.07 seconds\n",
      "Episode 228, Total Reward: 8.0, Steps: 8, Elapsed Time: 25.17 seconds\n",
      "Episode 229, Total Reward: 8.0, Steps: 8, Elapsed Time: 25.26 seconds\n",
      "Episode 230, Total Reward: 10.0, Steps: 10, Elapsed Time: 25.38 seconds\n",
      "Episode 231, Total Reward: 8.0, Steps: 8, Elapsed Time: 25.47 seconds\n",
      "Episode 232, Total Reward: 8.0, Steps: 8, Elapsed Time: 25.56 seconds\n",
      "Episode 233, Total Reward: 9.0, Steps: 9, Elapsed Time: 25.67 seconds\n",
      "Episode 234, Total Reward: 10.0, Steps: 10, Elapsed Time: 25.78 seconds\n",
      "Episode 235, Total Reward: 9.0, Steps: 9, Elapsed Time: 25.88 seconds\n",
      "Episode 236, Total Reward: 10.0, Steps: 10, Elapsed Time: 25.99 seconds\n",
      "Episode 237, Total Reward: 8.0, Steps: 8, Elapsed Time: 26.09 seconds\n",
      "Episode 238, Total Reward: 10.0, Steps: 10, Elapsed Time: 26.21 seconds\n",
      "Episode 239, Total Reward: 9.0, Steps: 9, Elapsed Time: 26.32 seconds\n",
      "Episode 240, Total Reward: 8.0, Steps: 8, Elapsed Time: 26.43 seconds\n",
      "Episode 241, Total Reward: 9.0, Steps: 9, Elapsed Time: 26.55 seconds\n",
      "Episode 242, Total Reward: 9.0, Steps: 9, Elapsed Time: 26.66 seconds\n",
      "Episode 243, Total Reward: 8.0, Steps: 8, Elapsed Time: 26.76 seconds\n",
      "Episode 244, Total Reward: 9.0, Steps: 9, Elapsed Time: 26.89 seconds\n",
      "Episode 245, Total Reward: 10.0, Steps: 10, Elapsed Time: 27.02 seconds\n",
      "Episode 246, Total Reward: 9.0, Steps: 9, Elapsed Time: 27.13 seconds\n",
      "Episode 247, Total Reward: 10.0, Steps: 10, Elapsed Time: 27.25 seconds\n",
      "Episode 248, Total Reward: 9.0, Steps: 9, Elapsed Time: 27.35 seconds\n",
      "Episode 249, Total Reward: 9.0, Steps: 9, Elapsed Time: 27.46 seconds\n",
      "Episode 250, Total Reward: 9.0, Steps: 9, Elapsed Time: 27.57 seconds\n",
      "Episode 251, Total Reward: 10.0, Steps: 10, Elapsed Time: 27.70 seconds\n",
      "Episode 252, Total Reward: 9.0, Steps: 9, Elapsed Time: 27.81 seconds\n",
      "Episode 253, Total Reward: 10.0, Steps: 10, Elapsed Time: 27.93 seconds\n",
      "Episode 254, Total Reward: 10.0, Steps: 10, Elapsed Time: 28.05 seconds\n",
      "Episode 255, Total Reward: 10.0, Steps: 10, Elapsed Time: 28.16 seconds\n",
      "Episode 256, Total Reward: 8.0, Steps: 8, Elapsed Time: 28.26 seconds\n",
      "Episode 257, Total Reward: 10.0, Steps: 10, Elapsed Time: 28.37 seconds\n",
      "Episode 258, Total Reward: 9.0, Steps: 9, Elapsed Time: 28.48 seconds\n",
      "Episode 259, Total Reward: 10.0, Steps: 10, Elapsed Time: 28.59 seconds\n",
      "Episode 260, Total Reward: 10.0, Steps: 10, Elapsed Time: 28.70 seconds\n",
      "Episode 261, Total Reward: 8.0, Steps: 8, Elapsed Time: 28.80 seconds\n",
      "Episode 262, Total Reward: 9.0, Steps: 9, Elapsed Time: 28.90 seconds\n",
      "Episode 263, Total Reward: 9.0, Steps: 9, Elapsed Time: 29.01 seconds\n",
      "Episode 264, Total Reward: 10.0, Steps: 10, Elapsed Time: 29.15 seconds\n",
      "Episode 265, Total Reward: 8.0, Steps: 8, Elapsed Time: 29.24 seconds\n",
      "Episode 266, Total Reward: 9.0, Steps: 9, Elapsed Time: 29.35 seconds\n",
      "Episode 267, Total Reward: 10.0, Steps: 10, Elapsed Time: 29.47 seconds\n",
      "Episode 268, Total Reward: 10.0, Steps: 10, Elapsed Time: 29.59 seconds\n",
      "Episode 269, Total Reward: 10.0, Steps: 10, Elapsed Time: 29.72 seconds\n",
      "Episode 270, Total Reward: 8.0, Steps: 8, Elapsed Time: 29.83 seconds\n",
      "Episode 271, Total Reward: 9.0, Steps: 9, Elapsed Time: 29.94 seconds\n",
      "Episode 272, Total Reward: 8.0, Steps: 8, Elapsed Time: 30.04 seconds\n",
      "Episode 273, Total Reward: 9.0, Steps: 9, Elapsed Time: 30.14 seconds\n",
      "Episode 274, Total Reward: 9.0, Steps: 9, Elapsed Time: 30.25 seconds\n",
      "Episode 275, Total Reward: 10.0, Steps: 10, Elapsed Time: 30.37 seconds\n",
      "Episode 276, Total Reward: 9.0, Steps: 9, Elapsed Time: 30.47 seconds\n",
      "Episode 277, Total Reward: 9.0, Steps: 9, Elapsed Time: 30.58 seconds\n",
      "Episode 278, Total Reward: 10.0, Steps: 10, Elapsed Time: 30.69 seconds\n",
      "Episode 279, Total Reward: 9.0, Steps: 9, Elapsed Time: 30.80 seconds\n",
      "Episode 280, Total Reward: 9.0, Steps: 9, Elapsed Time: 30.90 seconds\n",
      "Episode 281, Total Reward: 10.0, Steps: 10, Elapsed Time: 31.03 seconds\n",
      "Episode 282, Total Reward: 11.0, Steps: 11, Elapsed Time: 31.17 seconds\n",
      "Episode 283, Total Reward: 10.0, Steps: 10, Elapsed Time: 31.28 seconds\n",
      "Episode 284, Total Reward: 9.0, Steps: 9, Elapsed Time: 31.39 seconds\n",
      "Episode 285, Total Reward: 8.0, Steps: 8, Elapsed Time: 31.50 seconds\n",
      "Episode 286, Total Reward: 10.0, Steps: 10, Elapsed Time: 31.62 seconds\n",
      "Episode 287, Total Reward: 9.0, Steps: 9, Elapsed Time: 31.73 seconds\n",
      "Episode 288, Total Reward: 10.0, Steps: 10, Elapsed Time: 31.84 seconds\n",
      "Episode 289, Total Reward: 11.0, Steps: 11, Elapsed Time: 31.98 seconds\n",
      "Episode 290, Total Reward: 9.0, Steps: 9, Elapsed Time: 32.09 seconds\n",
      "Episode 291, Total Reward: 10.0, Steps: 10, Elapsed Time: 32.23 seconds\n",
      "Episode 292, Total Reward: 10.0, Steps: 10, Elapsed Time: 32.34 seconds\n",
      "Episode 293, Total Reward: 10.0, Steps: 10, Elapsed Time: 32.46 seconds\n",
      "Episode 294, Total Reward: 9.0, Steps: 9, Elapsed Time: 32.56 seconds\n",
      "Episode 295, Total Reward: 9.0, Steps: 9, Elapsed Time: 32.66 seconds\n",
      "Episode 296, Total Reward: 8.0, Steps: 8, Elapsed Time: 32.76 seconds\n",
      "Episode 297, Total Reward: 11.0, Steps: 11, Elapsed Time: 32.89 seconds\n",
      "Episode 298, Total Reward: 10.0, Steps: 10, Elapsed Time: 33.01 seconds\n",
      "Episode 299, Total Reward: 10.0, Steps: 10, Elapsed Time: 33.13 seconds\n",
      "Episode 300, Total Reward: 8.0, Steps: 8, Elapsed Time: 33.23 seconds\n",
      "Episode 301, Total Reward: 10.0, Steps: 10, Elapsed Time: 33.35 seconds\n",
      "Episode 302, Total Reward: 9.0, Steps: 9, Elapsed Time: 33.46 seconds\n",
      "Episode 303, Total Reward: 8.0, Steps: 8, Elapsed Time: 33.57 seconds\n",
      "Episode 304, Total Reward: 8.0, Steps: 8, Elapsed Time: 33.68 seconds\n",
      "Episode 305, Total Reward: 10.0, Steps: 10, Elapsed Time: 33.80 seconds\n",
      "Episode 306, Total Reward: 10.0, Steps: 10, Elapsed Time: 33.91 seconds\n",
      "Episode 307, Total Reward: 10.0, Steps: 10, Elapsed Time: 34.04 seconds\n",
      "Episode 308, Total Reward: 8.0, Steps: 8, Elapsed Time: 34.14 seconds\n",
      "Episode 309, Total Reward: 10.0, Steps: 10, Elapsed Time: 34.26 seconds\n",
      "Episode 310, Total Reward: 9.0, Steps: 9, Elapsed Time: 34.37 seconds\n",
      "Episode 311, Total Reward: 9.0, Steps: 9, Elapsed Time: 34.48 seconds\n",
      "Episode 312, Total Reward: 9.0, Steps: 9, Elapsed Time: 34.59 seconds\n",
      "Episode 313, Total Reward: 9.0, Steps: 9, Elapsed Time: 34.69 seconds\n",
      "Episode 314, Total Reward: 8.0, Steps: 8, Elapsed Time: 34.79 seconds\n",
      "Episode 315, Total Reward: 10.0, Steps: 10, Elapsed Time: 34.91 seconds\n",
      "Episode 316, Total Reward: 8.0, Steps: 8, Elapsed Time: 35.00 seconds\n",
      "Episode 317, Total Reward: 10.0, Steps: 10, Elapsed Time: 35.12 seconds\n",
      "Episode 318, Total Reward: 8.0, Steps: 8, Elapsed Time: 35.22 seconds\n",
      "Episode 319, Total Reward: 9.0, Steps: 9, Elapsed Time: 35.32 seconds\n",
      "Episode 320, Total Reward: 9.0, Steps: 9, Elapsed Time: 35.43 seconds\n",
      "Episode 321, Total Reward: 9.0, Steps: 9, Elapsed Time: 35.53 seconds\n",
      "Episode 322, Total Reward: 9.0, Steps: 9, Elapsed Time: 35.64 seconds\n",
      "Episode 323, Total Reward: 9.0, Steps: 9, Elapsed Time: 35.74 seconds\n",
      "Episode 324, Total Reward: 10.0, Steps: 10, Elapsed Time: 35.85 seconds\n",
      "Episode 325, Total Reward: 9.0, Steps: 9, Elapsed Time: 35.96 seconds\n",
      "Episode 326, Total Reward: 10.0, Steps: 10, Elapsed Time: 36.08 seconds\n",
      "Episode 327, Total Reward: 9.0, Steps: 9, Elapsed Time: 36.18 seconds\n",
      "Episode 328, Total Reward: 9.0, Steps: 9, Elapsed Time: 36.29 seconds\n",
      "Episode 329, Total Reward: 9.0, Steps: 9, Elapsed Time: 36.40 seconds\n",
      "Episode 330, Total Reward: 8.0, Steps: 8, Elapsed Time: 36.50 seconds\n",
      "Episode 331, Total Reward: 9.0, Steps: 9, Elapsed Time: 36.61 seconds\n",
      "Episode 332, Total Reward: 9.0, Steps: 9, Elapsed Time: 36.72 seconds\n",
      "Episode 333, Total Reward: 9.0, Steps: 9, Elapsed Time: 36.84 seconds\n",
      "Episode 334, Total Reward: 9.0, Steps: 9, Elapsed Time: 36.95 seconds\n",
      "Episode 335, Total Reward: 9.0, Steps: 9, Elapsed Time: 37.07 seconds\n",
      "Episode 336, Total Reward: 10.0, Steps: 10, Elapsed Time: 37.19 seconds\n",
      "Episode 337, Total Reward: 8.0, Steps: 8, Elapsed Time: 37.28 seconds\n",
      "Episode 338, Total Reward: 9.0, Steps: 9, Elapsed Time: 37.38 seconds\n",
      "Episode 339, Total Reward: 10.0, Steps: 10, Elapsed Time: 37.50 seconds\n",
      "Episode 340, Total Reward: 8.0, Steps: 8, Elapsed Time: 37.60 seconds\n",
      "Episode 341, Total Reward: 10.0, Steps: 10, Elapsed Time: 37.73 seconds\n",
      "Episode 342, Total Reward: 10.0, Steps: 10, Elapsed Time: 37.85 seconds\n",
      "Episode 343, Total Reward: 9.0, Steps: 9, Elapsed Time: 37.95 seconds\n",
      "Episode 344, Total Reward: 10.0, Steps: 10, Elapsed Time: 38.07 seconds\n",
      "Episode 345, Total Reward: 10.0, Steps: 10, Elapsed Time: 38.19 seconds\n",
      "Episode 346, Total Reward: 10.0, Steps: 10, Elapsed Time: 38.31 seconds\n",
      "Episode 347, Total Reward: 10.0, Steps: 10, Elapsed Time: 38.47 seconds\n",
      "Episode 348, Total Reward: 9.0, Steps: 9, Elapsed Time: 38.58 seconds\n",
      "Episode 349, Total Reward: 10.0, Steps: 10, Elapsed Time: 38.69 seconds\n",
      "Episode 350, Total Reward: 9.0, Steps: 9, Elapsed Time: 38.80 seconds\n",
      "Episode 351, Total Reward: 11.0, Steps: 11, Elapsed Time: 38.93 seconds\n",
      "Episode 352, Total Reward: 10.0, Steps: 10, Elapsed Time: 39.06 seconds\n",
      "Episode 353, Total Reward: 9.0, Steps: 9, Elapsed Time: 39.17 seconds\n",
      "Episode 354, Total Reward: 10.0, Steps: 10, Elapsed Time: 39.28 seconds\n",
      "Episode 355, Total Reward: 10.0, Steps: 10, Elapsed Time: 39.40 seconds\n",
      "Episode 356, Total Reward: 10.0, Steps: 10, Elapsed Time: 39.54 seconds\n",
      "Episode 357, Total Reward: 8.0, Steps: 8, Elapsed Time: 39.63 seconds\n",
      "Episode 358, Total Reward: 10.0, Steps: 10, Elapsed Time: 39.75 seconds\n",
      "Episode 359, Total Reward: 10.0, Steps: 10, Elapsed Time: 39.87 seconds\n",
      "Episode 360, Total Reward: 10.0, Steps: 10, Elapsed Time: 40.00 seconds\n",
      "Episode 361, Total Reward: 8.0, Steps: 8, Elapsed Time: 40.10 seconds\n",
      "Episode 362, Total Reward: 9.0, Steps: 9, Elapsed Time: 40.22 seconds\n",
      "Episode 363, Total Reward: 8.0, Steps: 8, Elapsed Time: 40.33 seconds\n",
      "Episode 364, Total Reward: 9.0, Steps: 9, Elapsed Time: 40.44 seconds\n",
      "Episode 365, Total Reward: 10.0, Steps: 10, Elapsed Time: 40.57 seconds\n",
      "Episode 366, Total Reward: 10.0, Steps: 10, Elapsed Time: 40.70 seconds\n",
      "Episode 367, Total Reward: 10.0, Steps: 10, Elapsed Time: 40.82 seconds\n",
      "Episode 368, Total Reward: 10.0, Steps: 10, Elapsed Time: 40.94 seconds\n",
      "Episode 369, Total Reward: 10.0, Steps: 10, Elapsed Time: 41.07 seconds\n",
      "Episode 370, Total Reward: 10.0, Steps: 10, Elapsed Time: 41.20 seconds\n",
      "Episode 371, Total Reward: 10.0, Steps: 10, Elapsed Time: 41.32 seconds\n",
      "Episode 372, Total Reward: 10.0, Steps: 10, Elapsed Time: 41.44 seconds\n",
      "Episode 373, Total Reward: 10.0, Steps: 10, Elapsed Time: 41.58 seconds\n",
      "Episode 374, Total Reward: 9.0, Steps: 9, Elapsed Time: 41.69 seconds\n",
      "Episode 375, Total Reward: 10.0, Steps: 10, Elapsed Time: 41.81 seconds\n",
      "Episode 376, Total Reward: 11.0, Steps: 11, Elapsed Time: 41.95 seconds\n",
      "Episode 377, Total Reward: 10.0, Steps: 10, Elapsed Time: 42.08 seconds\n",
      "Episode 378, Total Reward: 8.0, Steps: 8, Elapsed Time: 42.18 seconds\n",
      "Episode 379, Total Reward: 10.0, Steps: 10, Elapsed Time: 42.30 seconds\n",
      "Episode 380, Total Reward: 10.0, Steps: 10, Elapsed Time: 42.43 seconds\n",
      "Episode 381, Total Reward: 9.0, Steps: 9, Elapsed Time: 42.54 seconds\n",
      "Episode 382, Total Reward: 9.0, Steps: 9, Elapsed Time: 42.64 seconds\n",
      "Episode 383, Total Reward: 9.0, Steps: 9, Elapsed Time: 42.75 seconds\n",
      "Episode 384, Total Reward: 9.0, Steps: 9, Elapsed Time: 42.85 seconds\n",
      "Episode 385, Total Reward: 9.0, Steps: 9, Elapsed Time: 42.97 seconds\n",
      "Episode 386, Total Reward: 10.0, Steps: 10, Elapsed Time: 43.08 seconds\n",
      "Episode 387, Total Reward: 10.0, Steps: 10, Elapsed Time: 43.21 seconds\n",
      "Episode 388, Total Reward: 9.0, Steps: 9, Elapsed Time: 43.32 seconds\n",
      "Episode 389, Total Reward: 9.0, Steps: 9, Elapsed Time: 43.44 seconds\n",
      "Episode 390, Total Reward: 9.0, Steps: 9, Elapsed Time: 43.55 seconds\n",
      "Episode 391, Total Reward: 8.0, Steps: 8, Elapsed Time: 43.64 seconds\n",
      "Episode 392, Total Reward: 10.0, Steps: 10, Elapsed Time: 43.76 seconds\n",
      "Episode 393, Total Reward: 10.0, Steps: 10, Elapsed Time: 43.89 seconds\n",
      "Episode 394, Total Reward: 9.0, Steps: 9, Elapsed Time: 44.00 seconds\n",
      "Episode 395, Total Reward: 10.0, Steps: 10, Elapsed Time: 44.11 seconds\n",
      "Episode 396, Total Reward: 10.0, Steps: 10, Elapsed Time: 44.24 seconds\n",
      "Episode 397, Total Reward: 8.0, Steps: 8, Elapsed Time: 44.33 seconds\n",
      "Episode 398, Total Reward: 9.0, Steps: 9, Elapsed Time: 44.44 seconds\n",
      "Episode 399, Total Reward: 9.0, Steps: 9, Elapsed Time: 44.55 seconds\n",
      "Episode 400, Total Reward: 8.0, Steps: 8, Elapsed Time: 44.65 seconds\n",
      "Episode 401, Total Reward: 9.0, Steps: 9, Elapsed Time: 44.76 seconds\n",
      "Episode 402, Total Reward: 9.0, Steps: 9, Elapsed Time: 44.87 seconds\n",
      "Episode 403, Total Reward: 9.0, Steps: 9, Elapsed Time: 44.99 seconds\n",
      "Episode 404, Total Reward: 9.0, Steps: 9, Elapsed Time: 45.10 seconds\n",
      "Episode 405, Total Reward: 11.0, Steps: 11, Elapsed Time: 45.25 seconds\n",
      "Episode 406, Total Reward: 8.0, Steps: 8, Elapsed Time: 45.35 seconds\n",
      "Episode 407, Total Reward: 9.0, Steps: 9, Elapsed Time: 45.46 seconds\n",
      "Episode 408, Total Reward: 8.0, Steps: 8, Elapsed Time: 45.56 seconds\n",
      "Episode 409, Total Reward: 8.0, Steps: 8, Elapsed Time: 45.65 seconds\n",
      "Episode 410, Total Reward: 9.0, Steps: 9, Elapsed Time: 45.76 seconds\n",
      "Episode 411, Total Reward: 10.0, Steps: 10, Elapsed Time: 45.88 seconds\n",
      "Episode 412, Total Reward: 10.0, Steps: 10, Elapsed Time: 46.00 seconds\n",
      "Episode 413, Total Reward: 10.0, Steps: 10, Elapsed Time: 46.12 seconds\n",
      "Episode 414, Total Reward: 9.0, Steps: 9, Elapsed Time: 46.23 seconds\n",
      "Episode 415, Total Reward: 10.0, Steps: 10, Elapsed Time: 46.34 seconds\n",
      "Episode 416, Total Reward: 9.0, Steps: 9, Elapsed Time: 46.45 seconds\n",
      "Episode 417, Total Reward: 10.0, Steps: 10, Elapsed Time: 46.57 seconds\n",
      "Episode 418, Total Reward: 10.0, Steps: 10, Elapsed Time: 46.70 seconds\n",
      "Episode 419, Total Reward: 9.0, Steps: 9, Elapsed Time: 46.81 seconds\n",
      "Episode 420, Total Reward: 10.0, Steps: 10, Elapsed Time: 46.94 seconds\n",
      "Episode 421, Total Reward: 9.0, Steps: 9, Elapsed Time: 47.05 seconds\n",
      "Episode 422, Total Reward: 10.0, Steps: 10, Elapsed Time: 47.17 seconds\n",
      "Episode 423, Total Reward: 9.0, Steps: 9, Elapsed Time: 47.27 seconds\n",
      "Episode 424, Total Reward: 10.0, Steps: 10, Elapsed Time: 47.40 seconds\n",
      "Episode 425, Total Reward: 9.0, Steps: 9, Elapsed Time: 47.50 seconds\n",
      "Episode 426, Total Reward: 10.0, Steps: 10, Elapsed Time: 47.62 seconds\n",
      "Episode 427, Total Reward: 9.0, Steps: 9, Elapsed Time: 47.73 seconds\n",
      "Episode 428, Total Reward: 10.0, Steps: 10, Elapsed Time: 47.85 seconds\n",
      "Episode 429, Total Reward: 9.0, Steps: 9, Elapsed Time: 47.95 seconds\n",
      "Episode 430, Total Reward: 9.0, Steps: 9, Elapsed Time: 48.05 seconds\n",
      "Episode 431, Total Reward: 10.0, Steps: 10, Elapsed Time: 48.17 seconds\n",
      "Episode 432, Total Reward: 11.0, Steps: 11, Elapsed Time: 48.30 seconds\n",
      "Episode 433, Total Reward: 10.0, Steps: 10, Elapsed Time: 48.42 seconds\n",
      "Episode 434, Total Reward: 10.0, Steps: 10, Elapsed Time: 48.55 seconds\n",
      "Episode 435, Total Reward: 10.0, Steps: 10, Elapsed Time: 48.69 seconds\n",
      "Episode 436, Total Reward: 10.0, Steps: 10, Elapsed Time: 48.81 seconds\n",
      "Episode 437, Total Reward: 9.0, Steps: 9, Elapsed Time: 48.91 seconds\n",
      "Episode 438, Total Reward: 10.0, Steps: 10, Elapsed Time: 49.03 seconds\n",
      "Episode 439, Total Reward: 11.0, Steps: 11, Elapsed Time: 49.16 seconds\n",
      "Episode 440, Total Reward: 9.0, Steps: 9, Elapsed Time: 49.26 seconds\n",
      "Episode 441, Total Reward: 9.0, Steps: 9, Elapsed Time: 49.37 seconds\n",
      "Episode 442, Total Reward: 10.0, Steps: 10, Elapsed Time: 49.49 seconds\n",
      "Episode 443, Total Reward: 9.0, Steps: 9, Elapsed Time: 49.61 seconds\n",
      "Episode 444, Total Reward: 9.0, Steps: 9, Elapsed Time: 49.74 seconds\n",
      "Episode 445, Total Reward: 10.0, Steps: 10, Elapsed Time: 49.87 seconds\n",
      "Episode 446, Total Reward: 10.0, Steps: 10, Elapsed Time: 49.99 seconds\n",
      "Episode 447, Total Reward: 8.0, Steps: 8, Elapsed Time: 50.10 seconds\n",
      "Episode 448, Total Reward: 10.0, Steps: 10, Elapsed Time: 50.22 seconds\n",
      "Episode 449, Total Reward: 9.0, Steps: 9, Elapsed Time: 50.33 seconds\n",
      "Episode 450, Total Reward: 8.0, Steps: 8, Elapsed Time: 50.42 seconds\n",
      "Episode 451, Total Reward: 10.0, Steps: 10, Elapsed Time: 50.54 seconds\n",
      "Episode 452, Total Reward: 10.0, Steps: 10, Elapsed Time: 50.65 seconds\n",
      "Episode 453, Total Reward: 9.0, Steps: 9, Elapsed Time: 50.75 seconds\n",
      "Episode 454, Total Reward: 10.0, Steps: 10, Elapsed Time: 50.87 seconds\n",
      "Episode 455, Total Reward: 10.0, Steps: 10, Elapsed Time: 50.99 seconds\n",
      "Episode 456, Total Reward: 9.0, Steps: 9, Elapsed Time: 51.09 seconds\n",
      "Episode 457, Total Reward: 9.0, Steps: 9, Elapsed Time: 51.19 seconds\n",
      "Episode 458, Total Reward: 9.0, Steps: 9, Elapsed Time: 51.30 seconds\n",
      "Episode 459, Total Reward: 9.0, Steps: 9, Elapsed Time: 51.40 seconds\n",
      "Episode 460, Total Reward: 10.0, Steps: 10, Elapsed Time: 51.51 seconds\n",
      "Episode 461, Total Reward: 9.0, Steps: 9, Elapsed Time: 51.63 seconds\n",
      "Episode 462, Total Reward: 9.0, Steps: 9, Elapsed Time: 51.74 seconds\n",
      "Episode 463, Total Reward: 9.0, Steps: 9, Elapsed Time: 51.85 seconds\n",
      "Episode 464, Total Reward: 8.0, Steps: 8, Elapsed Time: 51.95 seconds\n",
      "Episode 465, Total Reward: 9.0, Steps: 9, Elapsed Time: 52.05 seconds\n",
      "Episode 466, Total Reward: 9.0, Steps: 9, Elapsed Time: 52.16 seconds\n",
      "Episode 467, Total Reward: 8.0, Steps: 8, Elapsed Time: 52.26 seconds\n",
      "Episode 468, Total Reward: 10.0, Steps: 10, Elapsed Time: 52.38 seconds\n",
      "Episode 469, Total Reward: 10.0, Steps: 10, Elapsed Time: 52.50 seconds\n",
      "Episode 470, Total Reward: 10.0, Steps: 10, Elapsed Time: 52.62 seconds\n",
      "Episode 471, Total Reward: 11.0, Steps: 11, Elapsed Time: 52.76 seconds\n",
      "Episode 472, Total Reward: 10.0, Steps: 10, Elapsed Time: 52.88 seconds\n",
      "Episode 473, Total Reward: 9.0, Steps: 9, Elapsed Time: 52.99 seconds\n",
      "Episode 474, Total Reward: 9.0, Steps: 9, Elapsed Time: 53.10 seconds\n",
      "Episode 475, Total Reward: 11.0, Steps: 11, Elapsed Time: 53.24 seconds\n",
      "Episode 476, Total Reward: 10.0, Steps: 10, Elapsed Time: 53.37 seconds\n",
      "Episode 477, Total Reward: 9.0, Steps: 9, Elapsed Time: 53.48 seconds\n",
      "Episode 478, Total Reward: 9.0, Steps: 9, Elapsed Time: 53.59 seconds\n",
      "Episode 479, Total Reward: 9.0, Steps: 9, Elapsed Time: 53.70 seconds\n",
      "Episode 480, Total Reward: 9.0, Steps: 9, Elapsed Time: 53.81 seconds\n",
      "Episode 481, Total Reward: 9.0, Steps: 9, Elapsed Time: 53.92 seconds\n",
      "Episode 482, Total Reward: 9.0, Steps: 9, Elapsed Time: 54.04 seconds\n",
      "Episode 483, Total Reward: 10.0, Steps: 10, Elapsed Time: 54.16 seconds\n",
      "Episode 484, Total Reward: 9.0, Steps: 9, Elapsed Time: 54.27 seconds\n",
      "Episode 485, Total Reward: 9.0, Steps: 9, Elapsed Time: 54.39 seconds\n",
      "Episode 486, Total Reward: 10.0, Steps: 10, Elapsed Time: 54.52 seconds\n",
      "Episode 487, Total Reward: 10.0, Steps: 10, Elapsed Time: 54.64 seconds\n",
      "Episode 488, Total Reward: 9.0, Steps: 9, Elapsed Time: 54.75 seconds\n",
      "Episode 489, Total Reward: 9.0, Steps: 9, Elapsed Time: 54.88 seconds\n",
      "Episode 490, Total Reward: 8.0, Steps: 8, Elapsed Time: 54.99 seconds\n",
      "Episode 491, Total Reward: 10.0, Steps: 10, Elapsed Time: 55.12 seconds\n",
      "Episode 492, Total Reward: 9.0, Steps: 9, Elapsed Time: 55.23 seconds\n",
      "Episode 493, Total Reward: 10.0, Steps: 10, Elapsed Time: 55.35 seconds\n",
      "Episode 494, Total Reward: 10.0, Steps: 10, Elapsed Time: 55.48 seconds\n",
      "Episode 495, Total Reward: 9.0, Steps: 9, Elapsed Time: 55.59 seconds\n",
      "Episode 496, Total Reward: 9.0, Steps: 9, Elapsed Time: 55.70 seconds\n",
      "Episode 497, Total Reward: 9.0, Steps: 9, Elapsed Time: 55.81 seconds\n",
      "Episode 498, Total Reward: 9.0, Steps: 9, Elapsed Time: 55.92 seconds\n",
      "Episode 499, Total Reward: 9.0, Steps: 9, Elapsed Time: 56.02 seconds\n",
      "Episode 500, Total Reward: 8.0, Steps: 8, Elapsed Time: 56.13 seconds\n",
      "Episode 501, Total Reward: 10.0, Steps: 10, Elapsed Time: 56.25 seconds\n",
      "Episode 502, Total Reward: 10.0, Steps: 10, Elapsed Time: 56.37 seconds\n",
      "Episode 503, Total Reward: 9.0, Steps: 9, Elapsed Time: 56.48 seconds\n",
      "Episode 504, Total Reward: 10.0, Steps: 10, Elapsed Time: 56.61 seconds\n",
      "Episode 505, Total Reward: 9.0, Steps: 9, Elapsed Time: 56.74 seconds\n",
      "Episode 506, Total Reward: 9.0, Steps: 9, Elapsed Time: 56.85 seconds\n",
      "Episode 507, Total Reward: 10.0, Steps: 10, Elapsed Time: 56.97 seconds\n",
      "Episode 508, Total Reward: 9.0, Steps: 9, Elapsed Time: 57.08 seconds\n",
      "Episode 509, Total Reward: 10.0, Steps: 10, Elapsed Time: 57.20 seconds\n",
      "Episode 510, Total Reward: 9.0, Steps: 9, Elapsed Time: 57.31 seconds\n",
      "Episode 511, Total Reward: 10.0, Steps: 10, Elapsed Time: 57.42 seconds\n",
      "Episode 512, Total Reward: 10.0, Steps: 10, Elapsed Time: 57.54 seconds\n",
      "Episode 513, Total Reward: 9.0, Steps: 9, Elapsed Time: 57.64 seconds\n",
      "Episode 514, Total Reward: 9.0, Steps: 9, Elapsed Time: 57.75 seconds\n",
      "Episode 515, Total Reward: 10.0, Steps: 10, Elapsed Time: 57.88 seconds\n",
      "Episode 516, Total Reward: 10.0, Steps: 10, Elapsed Time: 57.99 seconds\n",
      "Episode 517, Total Reward: 8.0, Steps: 8, Elapsed Time: 58.09 seconds\n",
      "Episode 518, Total Reward: 9.0, Steps: 9, Elapsed Time: 58.20 seconds\n",
      "Episode 519, Total Reward: 9.0, Steps: 9, Elapsed Time: 58.31 seconds\n",
      "Episode 520, Total Reward: 9.0, Steps: 9, Elapsed Time: 58.42 seconds\n",
      "Episode 521, Total Reward: 9.0, Steps: 9, Elapsed Time: 58.54 seconds\n",
      "Episode 522, Total Reward: 9.0, Steps: 9, Elapsed Time: 58.64 seconds\n",
      "Episode 523, Total Reward: 8.0, Steps: 8, Elapsed Time: 58.73 seconds\n",
      "Episode 524, Total Reward: 10.0, Steps: 10, Elapsed Time: 58.85 seconds\n",
      "Episode 525, Total Reward: 10.0, Steps: 10, Elapsed Time: 58.97 seconds\n",
      "Episode 526, Total Reward: 8.0, Steps: 8, Elapsed Time: 59.06 seconds\n",
      "Episode 527, Total Reward: 10.0, Steps: 10, Elapsed Time: 59.18 seconds\n",
      "Episode 528, Total Reward: 9.0, Steps: 9, Elapsed Time: 59.28 seconds\n",
      "Episode 529, Total Reward: 9.0, Steps: 9, Elapsed Time: 59.38 seconds\n",
      "Episode 530, Total Reward: 10.0, Steps: 10, Elapsed Time: 59.50 seconds\n",
      "Episode 531, Total Reward: 10.0, Steps: 10, Elapsed Time: 59.62 seconds\n",
      "Episode 532, Total Reward: 10.0, Steps: 10, Elapsed Time: 59.74 seconds\n",
      "Episode 533, Total Reward: 10.0, Steps: 10, Elapsed Time: 59.88 seconds\n",
      "Episode 534, Total Reward: 10.0, Steps: 10, Elapsed Time: 60.01 seconds\n",
      "Episode 535, Total Reward: 8.0, Steps: 8, Elapsed Time: 60.11 seconds\n",
      "Episode 536, Total Reward: 9.0, Steps: 9, Elapsed Time: 60.22 seconds\n",
      "Episode 537, Total Reward: 8.0, Steps: 8, Elapsed Time: 60.32 seconds\n",
      "Episode 538, Total Reward: 10.0, Steps: 10, Elapsed Time: 60.44 seconds\n",
      "Episode 539, Total Reward: 9.0, Steps: 9, Elapsed Time: 60.56 seconds\n",
      "Episode 540, Total Reward: 10.0, Steps: 10, Elapsed Time: 60.69 seconds\n",
      "Episode 541, Total Reward: 10.0, Steps: 10, Elapsed Time: 60.82 seconds\n",
      "Episode 542, Total Reward: 11.0, Steps: 11, Elapsed Time: 60.96 seconds\n",
      "Episode 543, Total Reward: 10.0, Steps: 10, Elapsed Time: 61.08 seconds\n",
      "Episode 544, Total Reward: 10.0, Steps: 10, Elapsed Time: 61.20 seconds\n",
      "Episode 545, Total Reward: 10.0, Steps: 10, Elapsed Time: 61.32 seconds\n",
      "Episode 546, Total Reward: 9.0, Steps: 9, Elapsed Time: 61.43 seconds\n",
      "Episode 547, Total Reward: 8.0, Steps: 8, Elapsed Time: 61.52 seconds\n",
      "Episode 548, Total Reward: 8.0, Steps: 8, Elapsed Time: 61.62 seconds\n",
      "Episode 549, Total Reward: 10.0, Steps: 10, Elapsed Time: 61.75 seconds\n",
      "Episode 550, Total Reward: 9.0, Steps: 9, Elapsed Time: 61.86 seconds\n",
      "Episode 551, Total Reward: 9.0, Steps: 9, Elapsed Time: 61.97 seconds\n",
      "Episode 552, Total Reward: 10.0, Steps: 10, Elapsed Time: 62.08 seconds\n",
      "Episode 553, Total Reward: 9.0, Steps: 9, Elapsed Time: 62.19 seconds\n",
      "Episode 554, Total Reward: 10.0, Steps: 10, Elapsed Time: 62.31 seconds\n",
      "Episode 555, Total Reward: 10.0, Steps: 10, Elapsed Time: 62.42 seconds\n",
      "Episode 556, Total Reward: 10.0, Steps: 10, Elapsed Time: 62.55 seconds\n",
      "Episode 557, Total Reward: 9.0, Steps: 9, Elapsed Time: 62.68 seconds\n",
      "Episode 558, Total Reward: 10.0, Steps: 10, Elapsed Time: 62.81 seconds\n",
      "Episode 559, Total Reward: 10.0, Steps: 10, Elapsed Time: 62.93 seconds\n",
      "Episode 560, Total Reward: 8.0, Steps: 8, Elapsed Time: 63.03 seconds\n",
      "Episode 561, Total Reward: 10.0, Steps: 10, Elapsed Time: 63.18 seconds\n",
      "Episode 562, Total Reward: 10.0, Steps: 10, Elapsed Time: 63.31 seconds\n",
      "Episode 563, Total Reward: 11.0, Steps: 11, Elapsed Time: 63.44 seconds\n",
      "Episode 564, Total Reward: 11.0, Steps: 11, Elapsed Time: 63.57 seconds\n",
      "Episode 565, Total Reward: 10.0, Steps: 10, Elapsed Time: 63.69 seconds\n",
      "Episode 566, Total Reward: 10.0, Steps: 10, Elapsed Time: 63.82 seconds\n",
      "Episode 567, Total Reward: 9.0, Steps: 9, Elapsed Time: 63.93 seconds\n",
      "Episode 568, Total Reward: 9.0, Steps: 9, Elapsed Time: 64.04 seconds\n",
      "Episode 569, Total Reward: 10.0, Steps: 10, Elapsed Time: 64.16 seconds\n",
      "Episode 570, Total Reward: 9.0, Steps: 9, Elapsed Time: 64.26 seconds\n",
      "Episode 571, Total Reward: 9.0, Steps: 9, Elapsed Time: 64.40 seconds\n",
      "Episode 572, Total Reward: 10.0, Steps: 10, Elapsed Time: 64.52 seconds\n",
      "Episode 573, Total Reward: 10.0, Steps: 10, Elapsed Time: 64.64 seconds\n",
      "Episode 574, Total Reward: 9.0, Steps: 9, Elapsed Time: 64.74 seconds\n",
      "Episode 575, Total Reward: 9.0, Steps: 9, Elapsed Time: 64.86 seconds\n",
      "Episode 576, Total Reward: 9.0, Steps: 9, Elapsed Time: 64.99 seconds\n",
      "Episode 577, Total Reward: 10.0, Steps: 10, Elapsed Time: 65.11 seconds\n",
      "Episode 578, Total Reward: 8.0, Steps: 8, Elapsed Time: 65.20 seconds\n",
      "Episode 579, Total Reward: 10.0, Steps: 10, Elapsed Time: 65.32 seconds\n",
      "Episode 580, Total Reward: 10.0, Steps: 10, Elapsed Time: 65.44 seconds\n",
      "Episode 581, Total Reward: 8.0, Steps: 8, Elapsed Time: 65.54 seconds\n",
      "Episode 582, Total Reward: 10.0, Steps: 10, Elapsed Time: 65.65 seconds\n",
      "Episode 583, Total Reward: 10.0, Steps: 10, Elapsed Time: 65.78 seconds\n",
      "Episode 584, Total Reward: 8.0, Steps: 8, Elapsed Time: 65.89 seconds\n",
      "Episode 585, Total Reward: 9.0, Steps: 9, Elapsed Time: 65.99 seconds\n",
      "Episode 586, Total Reward: 9.0, Steps: 9, Elapsed Time: 66.11 seconds\n",
      "Episode 587, Total Reward: 10.0, Steps: 10, Elapsed Time: 66.24 seconds\n",
      "Episode 588, Total Reward: 9.0, Steps: 9, Elapsed Time: 66.34 seconds\n",
      "Episode 589, Total Reward: 9.0, Steps: 9, Elapsed Time: 66.45 seconds\n",
      "Episode 590, Total Reward: 10.0, Steps: 10, Elapsed Time: 66.58 seconds\n",
      "Episode 591, Total Reward: 10.0, Steps: 10, Elapsed Time: 66.70 seconds\n",
      "Episode 592, Total Reward: 9.0, Steps: 9, Elapsed Time: 66.82 seconds\n",
      "Episode 593, Total Reward: 9.0, Steps: 9, Elapsed Time: 66.92 seconds\n",
      "Episode 594, Total Reward: 10.0, Steps: 10, Elapsed Time: 67.04 seconds\n",
      "Episode 595, Total Reward: 9.0, Steps: 9, Elapsed Time: 67.16 seconds\n",
      "Episode 596, Total Reward: 9.0, Steps: 9, Elapsed Time: 67.26 seconds\n",
      "Episode 597, Total Reward: 9.0, Steps: 9, Elapsed Time: 67.37 seconds\n",
      "Episode 598, Total Reward: 9.0, Steps: 9, Elapsed Time: 67.49 seconds\n",
      "Episode 599, Total Reward: 10.0, Steps: 10, Elapsed Time: 67.62 seconds\n",
      "Episode 600, Total Reward: 10.0, Steps: 10, Elapsed Time: 67.74 seconds\n",
      "Episode 601, Total Reward: 8.0, Steps: 8, Elapsed Time: 67.84 seconds\n",
      "Episode 602, Total Reward: 10.0, Steps: 10, Elapsed Time: 67.96 seconds\n",
      "Episode 603, Total Reward: 10.0, Steps: 10, Elapsed Time: 68.07 seconds\n",
      "Episode 604, Total Reward: 10.0, Steps: 10, Elapsed Time: 68.19 seconds\n",
      "Episode 605, Total Reward: 10.0, Steps: 10, Elapsed Time: 68.31 seconds\n",
      "Episode 606, Total Reward: 9.0, Steps: 9, Elapsed Time: 68.41 seconds\n",
      "Episode 607, Total Reward: 9.0, Steps: 9, Elapsed Time: 68.52 seconds\n",
      "Episode 608, Total Reward: 10.0, Steps: 10, Elapsed Time: 68.63 seconds\n",
      "Episode 609, Total Reward: 10.0, Steps: 10, Elapsed Time: 68.76 seconds\n",
      "Episode 610, Total Reward: 9.0, Steps: 9, Elapsed Time: 68.87 seconds\n",
      "Episode 611, Total Reward: 9.0, Steps: 9, Elapsed Time: 68.97 seconds\n",
      "Episode 612, Total Reward: 11.0, Steps: 11, Elapsed Time: 69.11 seconds\n",
      "Episode 613, Total Reward: 9.0, Steps: 9, Elapsed Time: 69.22 seconds\n",
      "Episode 614, Total Reward: 8.0, Steps: 8, Elapsed Time: 69.31 seconds\n",
      "Episode 615, Total Reward: 10.0, Steps: 10, Elapsed Time: 69.44 seconds\n",
      "Episode 616, Total Reward: 10.0, Steps: 10, Elapsed Time: 69.57 seconds\n",
      "Episode 617, Total Reward: 9.0, Steps: 9, Elapsed Time: 69.68 seconds\n",
      "Episode 618, Total Reward: 10.0, Steps: 10, Elapsed Time: 69.80 seconds\n",
      "Episode 619, Total Reward: 10.0, Steps: 10, Elapsed Time: 69.92 seconds\n",
      "Episode 620, Total Reward: 10.0, Steps: 10, Elapsed Time: 70.04 seconds\n",
      "Episode 621, Total Reward: 10.0, Steps: 10, Elapsed Time: 70.16 seconds\n",
      "Episode 622, Total Reward: 9.0, Steps: 9, Elapsed Time: 70.27 seconds\n",
      "Episode 623, Total Reward: 9.0, Steps: 9, Elapsed Time: 70.37 seconds\n",
      "Episode 624, Total Reward: 8.0, Steps: 8, Elapsed Time: 70.47 seconds\n",
      "Episode 625, Total Reward: 11.0, Steps: 11, Elapsed Time: 70.59 seconds\n",
      "Episode 626, Total Reward: 10.0, Steps: 10, Elapsed Time: 70.72 seconds\n",
      "Episode 627, Total Reward: 9.0, Steps: 9, Elapsed Time: 70.83 seconds\n",
      "Episode 628, Total Reward: 10.0, Steps: 10, Elapsed Time: 70.95 seconds\n",
      "Episode 629, Total Reward: 9.0, Steps: 9, Elapsed Time: 71.06 seconds\n",
      "Episode 630, Total Reward: 9.0, Steps: 9, Elapsed Time: 71.17 seconds\n",
      "Episode 631, Total Reward: 11.0, Steps: 11, Elapsed Time: 71.34 seconds\n",
      "Episode 632, Total Reward: 10.0, Steps: 10, Elapsed Time: 71.47 seconds\n",
      "Episode 633, Total Reward: 10.0, Steps: 10, Elapsed Time: 71.61 seconds\n",
      "Episode 634, Total Reward: 8.0, Steps: 8, Elapsed Time: 71.71 seconds\n",
      "Episode 635, Total Reward: 10.0, Steps: 10, Elapsed Time: 71.84 seconds\n",
      "Episode 636, Total Reward: 9.0, Steps: 9, Elapsed Time: 71.95 seconds\n",
      "Episode 637, Total Reward: 9.0, Steps: 9, Elapsed Time: 72.06 seconds\n",
      "Episode 638, Total Reward: 10.0, Steps: 10, Elapsed Time: 72.18 seconds\n",
      "Episode 639, Total Reward: 10.0, Steps: 10, Elapsed Time: 72.30 seconds\n",
      "Episode 640, Total Reward: 10.0, Steps: 10, Elapsed Time: 72.44 seconds\n",
      "Episode 641, Total Reward: 10.0, Steps: 10, Elapsed Time: 72.57 seconds\n",
      "Episode 642, Total Reward: 10.0, Steps: 10, Elapsed Time: 72.70 seconds\n",
      "Episode 643, Total Reward: 11.0, Steps: 11, Elapsed Time: 72.83 seconds\n",
      "Episode 644, Total Reward: 10.0, Steps: 10, Elapsed Time: 72.97 seconds\n",
      "Episode 645, Total Reward: 10.0, Steps: 10, Elapsed Time: 73.11 seconds\n",
      "Episode 646, Total Reward: 9.0, Steps: 9, Elapsed Time: 73.22 seconds\n",
      "Episode 647, Total Reward: 9.0, Steps: 9, Elapsed Time: 73.33 seconds\n",
      "Episode 648, Total Reward: 10.0, Steps: 10, Elapsed Time: 73.46 seconds\n",
      "Episode 649, Total Reward: 9.0, Steps: 9, Elapsed Time: 73.57 seconds\n",
      "Episode 650, Total Reward: 10.0, Steps: 10, Elapsed Time: 73.71 seconds\n",
      "Episode 651, Total Reward: 10.0, Steps: 10, Elapsed Time: 73.85 seconds\n",
      "Episode 652, Total Reward: 10.0, Steps: 10, Elapsed Time: 73.99 seconds\n",
      "Episode 653, Total Reward: 8.0, Steps: 8, Elapsed Time: 74.10 seconds\n",
      "Episode 654, Total Reward: 8.0, Steps: 8, Elapsed Time: 74.22 seconds\n",
      "Episode 655, Total Reward: 8.0, Steps: 8, Elapsed Time: 74.33 seconds\n",
      "Episode 656, Total Reward: 8.0, Steps: 8, Elapsed Time: 74.45 seconds\n",
      "Episode 657, Total Reward: 9.0, Steps: 9, Elapsed Time: 74.59 seconds\n",
      "Episode 658, Total Reward: 10.0, Steps: 10, Elapsed Time: 74.71 seconds\n",
      "Episode 659, Total Reward: 10.0, Steps: 10, Elapsed Time: 74.84 seconds\n",
      "Episode 660, Total Reward: 10.0, Steps: 10, Elapsed Time: 74.96 seconds\n",
      "Episode 661, Total Reward: 10.0, Steps: 10, Elapsed Time: 75.07 seconds\n",
      "Episode 662, Total Reward: 10.0, Steps: 10, Elapsed Time: 75.20 seconds\n",
      "Episode 663, Total Reward: 10.0, Steps: 10, Elapsed Time: 75.32 seconds\n",
      "Episode 664, Total Reward: 10.0, Steps: 10, Elapsed Time: 75.44 seconds\n",
      "Episode 665, Total Reward: 10.0, Steps: 10, Elapsed Time: 75.56 seconds\n",
      "Episode 666, Total Reward: 9.0, Steps: 9, Elapsed Time: 75.67 seconds\n",
      "Episode 667, Total Reward: 10.0, Steps: 10, Elapsed Time: 75.80 seconds\n",
      "Episode 668, Total Reward: 8.0, Steps: 8, Elapsed Time: 75.89 seconds\n",
      "Episode 669, Total Reward: 10.0, Steps: 10, Elapsed Time: 76.02 seconds\n",
      "Episode 670, Total Reward: 9.0, Steps: 9, Elapsed Time: 76.13 seconds\n",
      "Episode 671, Total Reward: 9.0, Steps: 9, Elapsed Time: 76.24 seconds\n",
      "Episode 672, Total Reward: 9.0, Steps: 9, Elapsed Time: 76.36 seconds\n",
      "Episode 673, Total Reward: 9.0, Steps: 9, Elapsed Time: 76.48 seconds\n",
      "Episode 674, Total Reward: 10.0, Steps: 10, Elapsed Time: 76.60 seconds\n",
      "Episode 675, Total Reward: 10.0, Steps: 10, Elapsed Time: 76.73 seconds\n",
      "Episode 676, Total Reward: 9.0, Steps: 9, Elapsed Time: 76.84 seconds\n",
      "Episode 677, Total Reward: 8.0, Steps: 8, Elapsed Time: 76.94 seconds\n",
      "Episode 678, Total Reward: 9.0, Steps: 9, Elapsed Time: 77.05 seconds\n",
      "Episode 679, Total Reward: 9.0, Steps: 9, Elapsed Time: 77.16 seconds\n",
      "Episode 680, Total Reward: 9.0, Steps: 9, Elapsed Time: 77.26 seconds\n",
      "Episode 681, Total Reward: 8.0, Steps: 8, Elapsed Time: 77.36 seconds\n",
      "Episode 682, Total Reward: 11.0, Steps: 11, Elapsed Time: 77.50 seconds\n",
      "Episode 683, Total Reward: 10.0, Steps: 10, Elapsed Time: 77.62 seconds\n",
      "Episode 684, Total Reward: 9.0, Steps: 9, Elapsed Time: 77.73 seconds\n",
      "Episode 685, Total Reward: 9.0, Steps: 9, Elapsed Time: 77.83 seconds\n",
      "Episode 686, Total Reward: 10.0, Steps: 10, Elapsed Time: 77.96 seconds\n",
      "Episode 687, Total Reward: 11.0, Steps: 11, Elapsed Time: 78.10 seconds\n",
      "Episode 688, Total Reward: 10.0, Steps: 10, Elapsed Time: 78.23 seconds\n",
      "Episode 689, Total Reward: 8.0, Steps: 8, Elapsed Time: 78.33 seconds\n",
      "Episode 690, Total Reward: 9.0, Steps: 9, Elapsed Time: 78.44 seconds\n",
      "Episode 691, Total Reward: 10.0, Steps: 10, Elapsed Time: 78.56 seconds\n",
      "Episode 692, Total Reward: 10.0, Steps: 10, Elapsed Time: 78.69 seconds\n",
      "Episode 693, Total Reward: 8.0, Steps: 8, Elapsed Time: 78.79 seconds\n",
      "Episode 694, Total Reward: 9.0, Steps: 9, Elapsed Time: 78.90 seconds\n",
      "Episode 695, Total Reward: 9.0, Steps: 9, Elapsed Time: 79.01 seconds\n",
      "Episode 696, Total Reward: 10.0, Steps: 10, Elapsed Time: 79.14 seconds\n",
      "Episode 697, Total Reward: 9.0, Steps: 9, Elapsed Time: 79.26 seconds\n",
      "Episode 698, Total Reward: 8.0, Steps: 8, Elapsed Time: 79.36 seconds\n",
      "Episode 699, Total Reward: 9.0, Steps: 9, Elapsed Time: 79.47 seconds\n",
      "Episode 700, Total Reward: 9.0, Steps: 9, Elapsed Time: 79.59 seconds\n",
      "Episode 701, Total Reward: 11.0, Steps: 11, Elapsed Time: 79.73 seconds\n",
      "Episode 702, Total Reward: 10.0, Steps: 10, Elapsed Time: 79.86 seconds\n",
      "Episode 703, Total Reward: 8.0, Steps: 8, Elapsed Time: 79.96 seconds\n",
      "Episode 704, Total Reward: 9.0, Steps: 9, Elapsed Time: 80.07 seconds\n",
      "Episode 705, Total Reward: 9.0, Steps: 9, Elapsed Time: 80.18 seconds\n",
      "Episode 706, Total Reward: 9.0, Steps: 9, Elapsed Time: 80.29 seconds\n",
      "Episode 707, Total Reward: 9.0, Steps: 9, Elapsed Time: 80.42 seconds\n",
      "Episode 708, Total Reward: 10.0, Steps: 10, Elapsed Time: 80.55 seconds\n",
      "Episode 709, Total Reward: 10.0, Steps: 10, Elapsed Time: 80.67 seconds\n",
      "Episode 710, Total Reward: 10.0, Steps: 10, Elapsed Time: 80.79 seconds\n",
      "Episode 711, Total Reward: 10.0, Steps: 10, Elapsed Time: 80.92 seconds\n",
      "Episode 712, Total Reward: 9.0, Steps: 9, Elapsed Time: 81.03 seconds\n",
      "Episode 713, Total Reward: 9.0, Steps: 9, Elapsed Time: 81.14 seconds\n",
      "Episode 714, Total Reward: 10.0, Steps: 10, Elapsed Time: 81.27 seconds\n",
      "Episode 715, Total Reward: 10.0, Steps: 10, Elapsed Time: 81.39 seconds\n",
      "Episode 716, Total Reward: 8.0, Steps: 8, Elapsed Time: 81.49 seconds\n",
      "Episode 717, Total Reward: 10.0, Steps: 10, Elapsed Time: 81.61 seconds\n",
      "Episode 718, Total Reward: 10.0, Steps: 10, Elapsed Time: 81.74 seconds\n",
      "Episode 719, Total Reward: 10.0, Steps: 10, Elapsed Time: 81.87 seconds\n",
      "Episode 720, Total Reward: 9.0, Steps: 9, Elapsed Time: 81.99 seconds\n",
      "Episode 721, Total Reward: 10.0, Steps: 10, Elapsed Time: 82.12 seconds\n",
      "Episode 722, Total Reward: 9.0, Steps: 9, Elapsed Time: 82.23 seconds\n",
      "Episode 723, Total Reward: 10.0, Steps: 10, Elapsed Time: 82.35 seconds\n",
      "Episode 724, Total Reward: 9.0, Steps: 9, Elapsed Time: 82.46 seconds\n",
      "Episode 725, Total Reward: 9.0, Steps: 9, Elapsed Time: 82.57 seconds\n",
      "Episode 726, Total Reward: 10.0, Steps: 10, Elapsed Time: 82.70 seconds\n",
      "Episode 727, Total Reward: 10.0, Steps: 10, Elapsed Time: 82.83 seconds\n",
      "Episode 728, Total Reward: 8.0, Steps: 8, Elapsed Time: 82.94 seconds\n",
      "Episode 729, Total Reward: 10.0, Steps: 10, Elapsed Time: 83.07 seconds\n",
      "Episode 730, Total Reward: 10.0, Steps: 10, Elapsed Time: 83.19 seconds\n",
      "Episode 731, Total Reward: 9.0, Steps: 9, Elapsed Time: 83.30 seconds\n",
      "Episode 732, Total Reward: 8.0, Steps: 8, Elapsed Time: 83.41 seconds\n",
      "Episode 733, Total Reward: 9.0, Steps: 9, Elapsed Time: 83.52 seconds\n",
      "Episode 734, Total Reward: 9.0, Steps: 9, Elapsed Time: 83.63 seconds\n",
      "Episode 735, Total Reward: 10.0, Steps: 10, Elapsed Time: 83.76 seconds\n",
      "Episode 736, Total Reward: 10.0, Steps: 10, Elapsed Time: 83.88 seconds\n",
      "Episode 737, Total Reward: 10.0, Steps: 10, Elapsed Time: 84.01 seconds\n",
      "Episode 738, Total Reward: 10.0, Steps: 10, Elapsed Time: 84.13 seconds\n",
      "Episode 739, Total Reward: 8.0, Steps: 8, Elapsed Time: 84.22 seconds\n",
      "Episode 740, Total Reward: 9.0, Steps: 9, Elapsed Time: 84.34 seconds\n",
      "Episode 741, Total Reward: 10.0, Steps: 10, Elapsed Time: 84.46 seconds\n",
      "Episode 742, Total Reward: 9.0, Steps: 9, Elapsed Time: 84.58 seconds\n",
      "Episode 743, Total Reward: 9.0, Steps: 9, Elapsed Time: 84.69 seconds\n",
      "Episode 744, Total Reward: 10.0, Steps: 10, Elapsed Time: 84.83 seconds\n",
      "Episode 745, Total Reward: 9.0, Steps: 9, Elapsed Time: 84.94 seconds\n",
      "Episode 746, Total Reward: 10.0, Steps: 10, Elapsed Time: 85.06 seconds\n",
      "Episode 747, Total Reward: 8.0, Steps: 8, Elapsed Time: 85.16 seconds\n",
      "Episode 748, Total Reward: 9.0, Steps: 9, Elapsed Time: 85.27 seconds\n",
      "Episode 749, Total Reward: 9.0, Steps: 9, Elapsed Time: 85.38 seconds\n",
      "Episode 750, Total Reward: 10.0, Steps: 10, Elapsed Time: 85.51 seconds\n",
      "Episode 751, Total Reward: 10.0, Steps: 10, Elapsed Time: 85.63 seconds\n",
      "Episode 752, Total Reward: 10.0, Steps: 10, Elapsed Time: 85.76 seconds\n",
      "Episode 753, Total Reward: 9.0, Steps: 9, Elapsed Time: 85.88 seconds\n",
      "Episode 754, Total Reward: 9.0, Steps: 9, Elapsed Time: 85.99 seconds\n",
      "Episode 755, Total Reward: 8.0, Steps: 8, Elapsed Time: 86.09 seconds\n",
      "Episode 756, Total Reward: 10.0, Steps: 10, Elapsed Time: 86.22 seconds\n",
      "Episode 757, Total Reward: 9.0, Steps: 9, Elapsed Time: 86.34 seconds\n",
      "Episode 758, Total Reward: 9.0, Steps: 9, Elapsed Time: 86.44 seconds\n",
      "Episode 759, Total Reward: 10.0, Steps: 10, Elapsed Time: 86.57 seconds\n",
      "Episode 760, Total Reward: 10.0, Steps: 10, Elapsed Time: 86.69 seconds\n",
      "Episode 761, Total Reward: 10.0, Steps: 10, Elapsed Time: 86.82 seconds\n",
      "Episode 762, Total Reward: 10.0, Steps: 10, Elapsed Time: 86.94 seconds\n",
      "Episode 763, Total Reward: 10.0, Steps: 10, Elapsed Time: 87.09 seconds\n",
      "Episode 764, Total Reward: 9.0, Steps: 9, Elapsed Time: 87.21 seconds\n",
      "Episode 765, Total Reward: 10.0, Steps: 10, Elapsed Time: 87.35 seconds\n",
      "Episode 766, Total Reward: 9.0, Steps: 9, Elapsed Time: 87.47 seconds\n",
      "Episode 767, Total Reward: 8.0, Steps: 8, Elapsed Time: 87.57 seconds\n",
      "Episode 768, Total Reward: 9.0, Steps: 9, Elapsed Time: 87.69 seconds\n",
      "Episode 769, Total Reward: 9.0, Steps: 9, Elapsed Time: 87.80 seconds\n",
      "Episode 770, Total Reward: 8.0, Steps: 8, Elapsed Time: 87.90 seconds\n",
      "Episode 771, Total Reward: 10.0, Steps: 10, Elapsed Time: 88.03 seconds\n",
      "Episode 772, Total Reward: 9.0, Steps: 9, Elapsed Time: 88.14 seconds\n",
      "Episode 773, Total Reward: 10.0, Steps: 10, Elapsed Time: 88.27 seconds\n",
      "Episode 774, Total Reward: 10.0, Steps: 10, Elapsed Time: 88.39 seconds\n",
      "Episode 775, Total Reward: 9.0, Steps: 9, Elapsed Time: 88.51 seconds\n",
      "Episode 776, Total Reward: 9.0, Steps: 9, Elapsed Time: 88.62 seconds\n",
      "Episode 777, Total Reward: 9.0, Steps: 9, Elapsed Time: 88.73 seconds\n",
      "Episode 778, Total Reward: 10.0, Steps: 10, Elapsed Time: 88.85 seconds\n",
      "Episode 779, Total Reward: 10.0, Steps: 10, Elapsed Time: 88.98 seconds\n",
      "Episode 780, Total Reward: 10.0, Steps: 10, Elapsed Time: 89.10 seconds\n",
      "Episode 781, Total Reward: 8.0, Steps: 8, Elapsed Time: 89.20 seconds\n",
      "Episode 782, Total Reward: 10.0, Steps: 10, Elapsed Time: 89.33 seconds\n",
      "Episode 783, Total Reward: 9.0, Steps: 9, Elapsed Time: 89.45 seconds\n",
      "Episode 784, Total Reward: 9.0, Steps: 9, Elapsed Time: 89.56 seconds\n",
      "Episode 785, Total Reward: 9.0, Steps: 9, Elapsed Time: 89.68 seconds\n",
      "Episode 786, Total Reward: 9.0, Steps: 9, Elapsed Time: 89.79 seconds\n",
      "Episode 787, Total Reward: 8.0, Steps: 8, Elapsed Time: 89.90 seconds\n",
      "Episode 788, Total Reward: 9.0, Steps: 9, Elapsed Time: 90.00 seconds\n",
      "Episode 789, Total Reward: 8.0, Steps: 8, Elapsed Time: 90.11 seconds\n",
      "Episode 790, Total Reward: 9.0, Steps: 9, Elapsed Time: 90.22 seconds\n",
      "Episode 791, Total Reward: 10.0, Steps: 10, Elapsed Time: 90.34 seconds\n",
      "Episode 792, Total Reward: 10.0, Steps: 10, Elapsed Time: 90.47 seconds\n",
      "Episode 793, Total Reward: 9.0, Steps: 9, Elapsed Time: 90.58 seconds\n",
      "Episode 794, Total Reward: 10.0, Steps: 10, Elapsed Time: 90.71 seconds\n",
      "Episode 795, Total Reward: 9.0, Steps: 9, Elapsed Time: 90.82 seconds\n",
      "Episode 796, Total Reward: 10.0, Steps: 10, Elapsed Time: 90.94 seconds\n",
      "Episode 797, Total Reward: 8.0, Steps: 8, Elapsed Time: 91.04 seconds\n",
      "Episode 798, Total Reward: 10.0, Steps: 10, Elapsed Time: 91.17 seconds\n",
      "Episode 799, Total Reward: 10.0, Steps: 10, Elapsed Time: 91.29 seconds\n",
      "Episode 800, Total Reward: 9.0, Steps: 9, Elapsed Time: 91.40 seconds\n",
      "Episode 801, Total Reward: 9.0, Steps: 9, Elapsed Time: 91.52 seconds\n",
      "Episode 802, Total Reward: 10.0, Steps: 10, Elapsed Time: 91.65 seconds\n",
      "Episode 803, Total Reward: 10.0, Steps: 10, Elapsed Time: 91.78 seconds\n",
      "Episode 804, Total Reward: 10.0, Steps: 10, Elapsed Time: 91.90 seconds\n",
      "Episode 805, Total Reward: 10.0, Steps: 10, Elapsed Time: 92.03 seconds\n",
      "Episode 806, Total Reward: 10.0, Steps: 10, Elapsed Time: 92.15 seconds\n",
      "Episode 807, Total Reward: 10.0, Steps: 10, Elapsed Time: 92.27 seconds\n",
      "Episode 808, Total Reward: 9.0, Steps: 9, Elapsed Time: 92.38 seconds\n",
      "Episode 809, Total Reward: 10.0, Steps: 10, Elapsed Time: 92.51 seconds\n",
      "Episode 810, Total Reward: 10.0, Steps: 10, Elapsed Time: 92.63 seconds\n",
      "Episode 811, Total Reward: 10.0, Steps: 10, Elapsed Time: 92.76 seconds\n",
      "Episode 812, Total Reward: 9.0, Steps: 9, Elapsed Time: 92.88 seconds\n",
      "Episode 813, Total Reward: 9.0, Steps: 9, Elapsed Time: 92.99 seconds\n",
      "Episode 814, Total Reward: 9.0, Steps: 9, Elapsed Time: 93.11 seconds\n",
      "Episode 815, Total Reward: 11.0, Steps: 11, Elapsed Time: 93.24 seconds\n",
      "Episode 816, Total Reward: 9.0, Steps: 9, Elapsed Time: 93.35 seconds\n",
      "Episode 817, Total Reward: 9.0, Steps: 9, Elapsed Time: 93.46 seconds\n",
      "Episode 818, Total Reward: 10.0, Steps: 10, Elapsed Time: 93.59 seconds\n",
      "Episode 819, Total Reward: 9.0, Steps: 9, Elapsed Time: 93.72 seconds\n",
      "Episode 820, Total Reward: 9.0, Steps: 9, Elapsed Time: 93.83 seconds\n",
      "Episode 821, Total Reward: 8.0, Steps: 8, Elapsed Time: 93.93 seconds\n",
      "Episode 822, Total Reward: 10.0, Steps: 10, Elapsed Time: 94.06 seconds\n",
      "Episode 823, Total Reward: 9.0, Steps: 9, Elapsed Time: 94.17 seconds\n",
      "Episode 824, Total Reward: 10.0, Steps: 10, Elapsed Time: 94.29 seconds\n",
      "Episode 825, Total Reward: 10.0, Steps: 10, Elapsed Time: 94.42 seconds\n",
      "Episode 826, Total Reward: 9.0, Steps: 9, Elapsed Time: 94.54 seconds\n",
      "Episode 827, Total Reward: 10.0, Steps: 10, Elapsed Time: 94.68 seconds\n",
      "Episode 828, Total Reward: 10.0, Steps: 10, Elapsed Time: 94.82 seconds\n",
      "Episode 829, Total Reward: 11.0, Steps: 11, Elapsed Time: 94.98 seconds\n",
      "Episode 830, Total Reward: 10.0, Steps: 10, Elapsed Time: 95.11 seconds\n",
      "Episode 831, Total Reward: 8.0, Steps: 8, Elapsed Time: 95.22 seconds\n",
      "Episode 832, Total Reward: 8.0, Steps: 8, Elapsed Time: 95.32 seconds\n",
      "Episode 833, Total Reward: 11.0, Steps: 11, Elapsed Time: 95.46 seconds\n",
      "Episode 834, Total Reward: 8.0, Steps: 8, Elapsed Time: 95.56 seconds\n",
      "Episode 835, Total Reward: 10.0, Steps: 10, Elapsed Time: 95.69 seconds\n",
      "Episode 836, Total Reward: 10.0, Steps: 10, Elapsed Time: 95.81 seconds\n",
      "Episode 837, Total Reward: 8.0, Steps: 8, Elapsed Time: 95.93 seconds\n",
      "Episode 838, Total Reward: 10.0, Steps: 10, Elapsed Time: 96.07 seconds\n",
      "Episode 839, Total Reward: 8.0, Steps: 8, Elapsed Time: 96.18 seconds\n",
      "Episode 840, Total Reward: 8.0, Steps: 8, Elapsed Time: 96.28 seconds\n",
      "Episode 841, Total Reward: 9.0, Steps: 9, Elapsed Time: 96.39 seconds\n",
      "Episode 842, Total Reward: 10.0, Steps: 10, Elapsed Time: 96.52 seconds\n",
      "Episode 843, Total Reward: 10.0, Steps: 10, Elapsed Time: 96.64 seconds\n",
      "Episode 844, Total Reward: 9.0, Steps: 9, Elapsed Time: 96.76 seconds\n",
      "Episode 845, Total Reward: 10.0, Steps: 10, Elapsed Time: 96.89 seconds\n",
      "Episode 846, Total Reward: 10.0, Steps: 10, Elapsed Time: 97.02 seconds\n",
      "Episode 847, Total Reward: 8.0, Steps: 8, Elapsed Time: 97.13 seconds\n",
      "Episode 848, Total Reward: 9.0, Steps: 9, Elapsed Time: 97.25 seconds\n",
      "Episode 849, Total Reward: 9.0, Steps: 9, Elapsed Time: 97.37 seconds\n",
      "Episode 850, Total Reward: 10.0, Steps: 10, Elapsed Time: 97.50 seconds\n",
      "Episode 851, Total Reward: 8.0, Steps: 8, Elapsed Time: 97.60 seconds\n",
      "Episode 852, Total Reward: 9.0, Steps: 9, Elapsed Time: 97.72 seconds\n",
      "Episode 853, Total Reward: 10.0, Steps: 10, Elapsed Time: 97.86 seconds\n",
      "Episode 854, Total Reward: 9.0, Steps: 9, Elapsed Time: 97.98 seconds\n",
      "Episode 855, Total Reward: 10.0, Steps: 10, Elapsed Time: 98.12 seconds\n",
      "Episode 856, Total Reward: 9.0, Steps: 9, Elapsed Time: 98.24 seconds\n",
      "Episode 857, Total Reward: 9.0, Steps: 9, Elapsed Time: 98.37 seconds\n",
      "Episode 858, Total Reward: 10.0, Steps: 10, Elapsed Time: 98.52 seconds\n",
      "Episode 859, Total Reward: 10.0, Steps: 10, Elapsed Time: 98.65 seconds\n",
      "Episode 860, Total Reward: 10.0, Steps: 10, Elapsed Time: 98.78 seconds\n",
      "Episode 861, Total Reward: 8.0, Steps: 8, Elapsed Time: 98.89 seconds\n",
      "Episode 862, Total Reward: 9.0, Steps: 9, Elapsed Time: 99.01 seconds\n",
      "Episode 863, Total Reward: 8.0, Steps: 8, Elapsed Time: 99.11 seconds\n",
      "Episode 864, Total Reward: 10.0, Steps: 10, Elapsed Time: 99.24 seconds\n",
      "Episode 865, Total Reward: 9.0, Steps: 9, Elapsed Time: 99.37 seconds\n",
      "Episode 866, Total Reward: 10.0, Steps: 10, Elapsed Time: 99.51 seconds\n",
      "Episode 867, Total Reward: 10.0, Steps: 10, Elapsed Time: 99.63 seconds\n",
      "Episode 868, Total Reward: 10.0, Steps: 10, Elapsed Time: 99.77 seconds\n",
      "Episode 869, Total Reward: 10.0, Steps: 10, Elapsed Time: 99.90 seconds\n",
      "Episode 870, Total Reward: 9.0, Steps: 9, Elapsed Time: 100.01 seconds\n",
      "Episode 871, Total Reward: 10.0, Steps: 10, Elapsed Time: 100.15 seconds\n",
      "Episode 872, Total Reward: 10.0, Steps: 10, Elapsed Time: 100.27 seconds\n",
      "Episode 873, Total Reward: 9.0, Steps: 9, Elapsed Time: 100.39 seconds\n",
      "Episode 874, Total Reward: 9.0, Steps: 9, Elapsed Time: 100.51 seconds\n",
      "Episode 875, Total Reward: 10.0, Steps: 10, Elapsed Time: 100.67 seconds\n",
      "Episode 876, Total Reward: 9.0, Steps: 9, Elapsed Time: 100.78 seconds\n",
      "Episode 877, Total Reward: 9.0, Steps: 9, Elapsed Time: 100.90 seconds\n",
      "Episode 878, Total Reward: 8.0, Steps: 8, Elapsed Time: 101.00 seconds\n",
      "Episode 879, Total Reward: 10.0, Steps: 10, Elapsed Time: 101.13 seconds\n",
      "Episode 880, Total Reward: 9.0, Steps: 9, Elapsed Time: 101.25 seconds\n",
      "Episode 881, Total Reward: 10.0, Steps: 10, Elapsed Time: 101.38 seconds\n",
      "Episode 882, Total Reward: 9.0, Steps: 9, Elapsed Time: 101.50 seconds\n",
      "Episode 883, Total Reward: 9.0, Steps: 9, Elapsed Time: 101.61 seconds\n",
      "Episode 884, Total Reward: 10.0, Steps: 10, Elapsed Time: 101.74 seconds\n",
      "Episode 885, Total Reward: 9.0, Steps: 9, Elapsed Time: 101.85 seconds\n",
      "Episode 886, Total Reward: 10.0, Steps: 10, Elapsed Time: 101.98 seconds\n",
      "Episode 887, Total Reward: 10.0, Steps: 10, Elapsed Time: 102.11 seconds\n",
      "Episode 888, Total Reward: 9.0, Steps: 9, Elapsed Time: 102.24 seconds\n",
      "Episode 889, Total Reward: 10.0, Steps: 10, Elapsed Time: 102.36 seconds\n",
      "Episode 890, Total Reward: 9.0, Steps: 9, Elapsed Time: 102.49 seconds\n",
      "Episode 891, Total Reward: 10.0, Steps: 10, Elapsed Time: 102.62 seconds\n",
      "Episode 892, Total Reward: 10.0, Steps: 10, Elapsed Time: 102.76 seconds\n",
      "Episode 893, Total Reward: 10.0, Steps: 10, Elapsed Time: 102.89 seconds\n",
      "Episode 894, Total Reward: 10.0, Steps: 10, Elapsed Time: 103.02 seconds\n",
      "Episode 895, Total Reward: 10.0, Steps: 10, Elapsed Time: 103.15 seconds\n",
      "Episode 896, Total Reward: 10.0, Steps: 10, Elapsed Time: 103.28 seconds\n",
      "Episode 897, Total Reward: 9.0, Steps: 9, Elapsed Time: 103.39 seconds\n",
      "Episode 898, Total Reward: 8.0, Steps: 8, Elapsed Time: 103.49 seconds\n",
      "Episode 899, Total Reward: 9.0, Steps: 9, Elapsed Time: 103.62 seconds\n",
      "Episode 900, Total Reward: 9.0, Steps: 9, Elapsed Time: 103.74 seconds\n",
      "Episode 901, Total Reward: 9.0, Steps: 9, Elapsed Time: 103.86 seconds\n",
      "Episode 902, Total Reward: 8.0, Steps: 8, Elapsed Time: 103.97 seconds\n",
      "Episode 903, Total Reward: 10.0, Steps: 10, Elapsed Time: 104.12 seconds\n",
      "Episode 904, Total Reward: 10.0, Steps: 10, Elapsed Time: 104.27 seconds\n",
      "Episode 905, Total Reward: 9.0, Steps: 9, Elapsed Time: 104.41 seconds\n",
      "Episode 906, Total Reward: 8.0, Steps: 8, Elapsed Time: 104.55 seconds\n",
      "Episode 907, Total Reward: 9.0, Steps: 9, Elapsed Time: 104.70 seconds\n",
      "Episode 908, Total Reward: 8.0, Steps: 8, Elapsed Time: 104.82 seconds\n",
      "Episode 909, Total Reward: 9.0, Steps: 9, Elapsed Time: 104.95 seconds\n",
      "Episode 910, Total Reward: 9.0, Steps: 9, Elapsed Time: 105.07 seconds\n",
      "Episode 911, Total Reward: 8.0, Steps: 8, Elapsed Time: 105.18 seconds\n",
      "Episode 912, Total Reward: 10.0, Steps: 10, Elapsed Time: 105.30 seconds\n",
      "Episode 913, Total Reward: 10.0, Steps: 10, Elapsed Time: 105.44 seconds\n",
      "Episode 914, Total Reward: 10.0, Steps: 10, Elapsed Time: 105.56 seconds\n",
      "Episode 915, Total Reward: 10.0, Steps: 10, Elapsed Time: 105.69 seconds\n",
      "Episode 916, Total Reward: 10.0, Steps: 10, Elapsed Time: 105.82 seconds\n",
      "Episode 917, Total Reward: 8.0, Steps: 8, Elapsed Time: 105.93 seconds\n",
      "Episode 918, Total Reward: 10.0, Steps: 10, Elapsed Time: 106.07 seconds\n",
      "Episode 919, Total Reward: 10.0, Steps: 10, Elapsed Time: 106.20 seconds\n",
      "Episode 920, Total Reward: 9.0, Steps: 9, Elapsed Time: 106.31 seconds\n",
      "Episode 921, Total Reward: 10.0, Steps: 10, Elapsed Time: 106.44 seconds\n",
      "Episode 922, Total Reward: 10.0, Steps: 10, Elapsed Time: 106.57 seconds\n",
      "Episode 923, Total Reward: 10.0, Steps: 10, Elapsed Time: 106.70 seconds\n",
      "Episode 924, Total Reward: 9.0, Steps: 9, Elapsed Time: 106.81 seconds\n",
      "Episode 925, Total Reward: 10.0, Steps: 10, Elapsed Time: 106.95 seconds\n",
      "Episode 926, Total Reward: 8.0, Steps: 8, Elapsed Time: 107.06 seconds\n",
      "Episode 927, Total Reward: 10.0, Steps: 10, Elapsed Time: 107.21 seconds\n",
      "Episode 928, Total Reward: 10.0, Steps: 10, Elapsed Time: 107.34 seconds\n",
      "Episode 929, Total Reward: 10.0, Steps: 10, Elapsed Time: 107.47 seconds\n",
      "Episode 930, Total Reward: 10.0, Steps: 10, Elapsed Time: 107.60 seconds\n",
      "Episode 931, Total Reward: 10.0, Steps: 10, Elapsed Time: 107.73 seconds\n",
      "Episode 932, Total Reward: 9.0, Steps: 9, Elapsed Time: 107.84 seconds\n",
      "Episode 933, Total Reward: 10.0, Steps: 10, Elapsed Time: 107.97 seconds\n",
      "Episode 934, Total Reward: 9.0, Steps: 9, Elapsed Time: 108.09 seconds\n",
      "Episode 935, Total Reward: 10.0, Steps: 10, Elapsed Time: 108.22 seconds\n",
      "Episode 936, Total Reward: 10.0, Steps: 10, Elapsed Time: 108.34 seconds\n",
      "Episode 937, Total Reward: 10.0, Steps: 10, Elapsed Time: 108.47 seconds\n",
      "Episode 938, Total Reward: 9.0, Steps: 9, Elapsed Time: 108.60 seconds\n",
      "Episode 939, Total Reward: 9.0, Steps: 9, Elapsed Time: 108.72 seconds\n",
      "Episode 940, Total Reward: 9.0, Steps: 9, Elapsed Time: 108.84 seconds\n",
      "Episode 941, Total Reward: 10.0, Steps: 10, Elapsed Time: 108.97 seconds\n",
      "Episode 942, Total Reward: 8.0, Steps: 8, Elapsed Time: 109.08 seconds\n",
      "Episode 943, Total Reward: 11.0, Steps: 11, Elapsed Time: 109.25 seconds\n",
      "Episode 944, Total Reward: 10.0, Steps: 10, Elapsed Time: 109.39 seconds\n",
      "Episode 945, Total Reward: 10.0, Steps: 10, Elapsed Time: 109.52 seconds\n",
      "Episode 946, Total Reward: 10.0, Steps: 10, Elapsed Time: 109.65 seconds\n",
      "Episode 947, Total Reward: 10.0, Steps: 10, Elapsed Time: 109.79 seconds\n",
      "Episode 948, Total Reward: 9.0, Steps: 9, Elapsed Time: 109.90 seconds\n",
      "Episode 949, Total Reward: 9.0, Steps: 9, Elapsed Time: 110.03 seconds\n",
      "Episode 950, Total Reward: 9.0, Steps: 9, Elapsed Time: 110.15 seconds\n",
      "Episode 951, Total Reward: 9.0, Steps: 9, Elapsed Time: 110.27 seconds\n",
      "Episode 952, Total Reward: 9.0, Steps: 9, Elapsed Time: 110.39 seconds\n",
      "Episode 953, Total Reward: 8.0, Steps: 8, Elapsed Time: 110.50 seconds\n",
      "Episode 954, Total Reward: 10.0, Steps: 10, Elapsed Time: 110.63 seconds\n",
      "Episode 955, Total Reward: 9.0, Steps: 9, Elapsed Time: 110.76 seconds\n",
      "Episode 956, Total Reward: 9.0, Steps: 9, Elapsed Time: 110.87 seconds\n",
      "Episode 957, Total Reward: 10.0, Steps: 10, Elapsed Time: 111.01 seconds\n",
      "Episode 958, Total Reward: 9.0, Steps: 9, Elapsed Time: 111.12 seconds\n",
      "Episode 959, Total Reward: 9.0, Steps: 9, Elapsed Time: 111.24 seconds\n",
      "Episode 960, Total Reward: 10.0, Steps: 10, Elapsed Time: 111.37 seconds\n",
      "Episode 961, Total Reward: 10.0, Steps: 10, Elapsed Time: 111.51 seconds\n",
      "Episode 962, Total Reward: 9.0, Steps: 9, Elapsed Time: 111.63 seconds\n",
      "Episode 963, Total Reward: 9.0, Steps: 9, Elapsed Time: 111.75 seconds\n",
      "Episode 964, Total Reward: 10.0, Steps: 10, Elapsed Time: 111.89 seconds\n",
      "Episode 965, Total Reward: 10.0, Steps: 10, Elapsed Time: 112.02 seconds\n",
      "Episode 966, Total Reward: 9.0, Steps: 9, Elapsed Time: 112.15 seconds\n",
      "Episode 967, Total Reward: 10.0, Steps: 10, Elapsed Time: 112.29 seconds\n",
      "Episode 968, Total Reward: 9.0, Steps: 9, Elapsed Time: 112.43 seconds\n",
      "Episode 969, Total Reward: 10.0, Steps: 10, Elapsed Time: 112.59 seconds\n",
      "Episode 970, Total Reward: 10.0, Steps: 10, Elapsed Time: 112.72 seconds\n",
      "Episode 971, Total Reward: 10.0, Steps: 10, Elapsed Time: 112.86 seconds\n",
      "Episode 972, Total Reward: 9.0, Steps: 9, Elapsed Time: 113.00 seconds\n",
      "Episode 973, Total Reward: 11.0, Steps: 11, Elapsed Time: 113.19 seconds\n",
      "Episode 974, Total Reward: 8.0, Steps: 8, Elapsed Time: 113.32 seconds\n",
      "Episode 975, Total Reward: 8.0, Steps: 8, Elapsed Time: 113.45 seconds\n",
      "Episode 976, Total Reward: 9.0, Steps: 9, Elapsed Time: 113.59 seconds\n",
      "Episode 977, Total Reward: 8.0, Steps: 8, Elapsed Time: 113.72 seconds\n",
      "Episode 978, Total Reward: 8.0, Steps: 8, Elapsed Time: 113.84 seconds\n",
      "Episode 979, Total Reward: 9.0, Steps: 9, Elapsed Time: 113.98 seconds\n",
      "Episode 980, Total Reward: 9.0, Steps: 9, Elapsed Time: 114.11 seconds\n",
      "Episode 981, Total Reward: 9.0, Steps: 9, Elapsed Time: 114.23 seconds\n",
      "Episode 982, Total Reward: 9.0, Steps: 9, Elapsed Time: 114.35 seconds\n",
      "Episode 983, Total Reward: 10.0, Steps: 10, Elapsed Time: 114.50 seconds\n",
      "Episode 984, Total Reward: 10.0, Steps: 10, Elapsed Time: 114.63 seconds\n",
      "Episode 985, Total Reward: 9.0, Steps: 9, Elapsed Time: 114.76 seconds\n",
      "Episode 986, Total Reward: 9.0, Steps: 9, Elapsed Time: 114.89 seconds\n",
      "Episode 987, Total Reward: 9.0, Steps: 9, Elapsed Time: 115.00 seconds\n",
      "Episode 988, Total Reward: 9.0, Steps: 9, Elapsed Time: 115.12 seconds\n",
      "Episode 989, Total Reward: 8.0, Steps: 8, Elapsed Time: 115.24 seconds\n",
      "Episode 990, Total Reward: 10.0, Steps: 10, Elapsed Time: 115.37 seconds\n",
      "Episode 991, Total Reward: 10.0, Steps: 10, Elapsed Time: 115.50 seconds\n",
      "Episode 992, Total Reward: 10.0, Steps: 10, Elapsed Time: 115.64 seconds\n",
      "Episode 993, Total Reward: 9.0, Steps: 9, Elapsed Time: 115.76 seconds\n",
      "Episode 994, Total Reward: 10.0, Steps: 10, Elapsed Time: 115.93 seconds\n",
      "Episode 995, Total Reward: 8.0, Steps: 8, Elapsed Time: 116.05 seconds\n",
      "Episode 996, Total Reward: 8.0, Steps: 8, Elapsed Time: 116.16 seconds\n",
      "Episode 997, Total Reward: 10.0, Steps: 10, Elapsed Time: 116.30 seconds\n",
      "Episode 998, Total Reward: 9.0, Steps: 9, Elapsed Time: 116.42 seconds\n",
      "Episode 999, Total Reward: 10.0, Steps: 10, Elapsed Time: 116.59 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# CartPole-v1 환경 사용\n",
    "env = gym.make('CartPole-v1', render_mode='rgb_array')\n",
    "\n",
    "def get_image_from_env(env):\n",
    "    frame = env.render()\n",
    "    return frame\n",
    "\n",
    "def preprocess_image(image):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # 흑백으로 변환\n",
    "    image = cv2.resize(image, (64, 64))  # 크기 조정\n",
    "    image = image.astype(np.float32) / 255.0  # 정규화\n",
    "    image = np.expand_dims(image, axis=0)  # 배치 차원 추가\n",
    "    return image\n",
    "\n",
    "class CartPoleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CartPoleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=2)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=2)\n",
    "        self.fc1 = nn.Linear(64*7*7, 256)\n",
    "        self.fc2 = nn.Linear(256, 2)  # 이산적 동작 공간에서의 두 개의 동작\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.relu(self.conv3(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# 모델 초기화\n",
    "model = CartPoleCNN()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# 그래프를 그리기 위한 데이터 리스트\n",
    "episode_rewards = []\n",
    "episode_steps = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for episode in range(1000):\n",
    "    state, _ = env.reset()\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "    step = 0\n",
    "    \n",
    "    while not done:\n",
    "        image = get_image_from_env(env)\n",
    "        image = preprocess_image(image)\n",
    "        image = torch.FloatTensor(image).unsqueeze(0)\n",
    "        \n",
    "        # 이산적 동작 선택\n",
    "        action_probs = model(image).detach().numpy().flatten()\n",
    "        action = np.argmax(action_probs)\n",
    "        \n",
    "        next_state, reward, done, _, _ = env.step(action)\n",
    "        \n",
    "        # 손실 계산 및 역전파\n",
    "        optimizer.zero_grad()\n",
    "        output = model(image)\n",
    "        target = output.clone()\n",
    "        target[0][action] = reward + 0.99 * np.max(model(torch.FloatTensor(preprocess_image(get_image_from_env(env))).unsqueeze(0)).detach().numpy())\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_reward += reward\n",
    "        step += 1\n",
    "        \n",
    "    # 각 에피소드마다 보상과 스텝 수 저장\n",
    "    episode_rewards.append(total_reward)\n",
    "    episode_steps.append(step)\n",
    "    \n",
    "    # 각 에피소드마다 실행 시간과 보상 출력\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"Episode {episode}, Total Reward: {total_reward}, Steps: {step}, Elapsed Time: {elapsed_time:.2f} seconds\")\n",
    "\n",
    "env.close()\n",
    "\n",
    "# 결과 그래프 출력\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# 보상 그래프\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(episode_rewards, label='Total Reward')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total Reward')\n",
    "plt.title('Episode vs Total Reward')\n",
    "plt.legend()\n",
    "\n",
    "# 스텝 수 그래프\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(episode_steps, label='Steps')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Steps')\n",
    "plt.title('Episode vs Steps')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gym-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
